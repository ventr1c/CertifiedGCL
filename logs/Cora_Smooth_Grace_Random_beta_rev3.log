nohup: ignoring input
run_smooth_node.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Namespace(add_edge_rate_1=0, add_edge_rate_2=0, attack='random', base_model='GCN', cl_activation='relu', cl_base_model='GCNConv', cl_lr=0.0005, cl_num_epochs=200, cl_num_layers=2, cl_num_proj_hidden=128, cl_weight_decay=1e-05, clf_weight=1, config='config.yaml', cont_batch_size=0, cont_weight=1, cuda=True, dataset='Cora', debug=True, device_id=0, drop_edge_rate_1=0.2, drop_edge_rate_2=0, drop_feat_rate_1=0.3, drop_feat_rate_2=0.2, dropout=0.5, encoder_model='Grace', hidden=128, if_smoothed=True, inv_weight=1, no_cuda=False, noisy_level=0.3, num_hidden=128, num_proj_hidden=128, num_repeat=5, num_sample=20, prob=0.8, seed=10, select_target_ratio=0.1, tau=0.1, test_model='GCN', train_lr=0.01, weight_decay=0.0005)
beta 0.1
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596604347229004
Epoch 10, training loss: 8.592703819274902
Epoch 20, training loss: 8.556774139404297
Epoch 30, training loss: 8.393590927124023
Epoch 40, training loss: 8.168986320495605
Epoch 50, training loss: 7.76633882522583
Epoch 60, training loss: 7.460155010223389
Epoch 70, training loss: 7.392526626586914
Epoch 80, training loss: 7.289383888244629
Epoch 90, training loss: 7.165267467498779
Epoch 100, training loss: 7.373138904571533
Epoch 110, training loss: 7.046724796295166
Epoch 120, training loss: 6.902115821838379
Epoch 130, training loss: 6.95683479309082
Epoch 140, training loss: 6.988247394561768
Epoch 150, training loss: 6.890275955200195
Epoch 160, training loss: 6.778881072998047
Epoch 170, training loss: 6.658015251159668
Epoch 180, training loss: 6.593446254730225
Epoch 190, training loss: 6.537327766418457
Epoch 200, training loss: 6.563547611236572
Epoch 210, training loss: 6.586213111877441
Epoch 220, training loss: 6.479030609130859
Epoch 230, training loss: 6.462673187255859
Epoch 240, training loss: 6.393876075744629
Epoch 250, training loss: 6.459441661834717
Epoch 260, training loss: 6.342710018157959
Epoch 270, training loss: 6.401264667510986
Epoch 280, training loss: 6.399718284606934
Epoch 290, training loss: 6.2652435302734375
Epoch 300, training loss: 6.1963582038879395
Epoch 310, training loss: 6.258640289306641
Epoch 320, training loss: 6.146875381469727
Epoch 330, training loss: 6.176866054534912
Epoch 340, training loss: 6.170969009399414
Epoch 350, training loss: 6.139530658721924
Epoch 360, training loss: 6.131467819213867
Epoch 370, training loss: 6.1167144775390625
Epoch 380, training loss: 6.175716876983643
Epoch 390, training loss: 5.985696315765381
Epoch 400, training loss: 6.010735034942627
Epoch 410, training loss: 6.002890110015869
Epoch 420, training loss: 6.0546369552612305
Epoch 430, training loss: 6.050077438354492
Epoch 440, training loss: 5.842916011810303
Epoch 450, training loss: 5.911227703094482
Epoch 460, training loss: 5.878473281860352
Epoch 470, training loss: 5.8577189445495605
Epoch 480, training loss: 5.864142417907715
Epoch 490, training loss: 5.85939884185791
random
Accuracy: 0.794
Accuracy: 0.787
Accuracy: 0.783
Accuracy: 0.772
Accuracy: 0.773
Accuracy: 0.761
Accuracy: 0.759
Accuracy: 0.757
Accuracy: 0.76
Accuracy: 0.757
Accuracy: 0.751
Accuracy: 0.751
Accuracy: 0.752
Accuracy: 0.744
Accuracy: 0.741
Accuracy: 0.743
Accuracy: 0.75
Accuracy: 0.745
Accuracy: 0.745
Accuracy: 0.748
Accuracy: 0.739
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.5966157913208
Epoch 10, training loss: 8.594613075256348
Epoch 20, training loss: 8.576956748962402
Epoch 30, training loss: 8.425631523132324
Epoch 40, training loss: 8.209257125854492
Epoch 50, training loss: 7.920721054077148
Epoch 60, training loss: 7.716406345367432
Epoch 70, training loss: 7.589095592498779
Epoch 80, training loss: 7.352168083190918
Epoch 90, training loss: 7.491658687591553
Epoch 100, training loss: 7.429782390594482
Epoch 110, training loss: 7.143948554992676
Epoch 120, training loss: 7.221781253814697
Epoch 130, training loss: 7.203897476196289
Epoch 140, training loss: 6.979683876037598
Epoch 150, training loss: 6.928788185119629
Epoch 160, training loss: 6.881815433502197
Epoch 170, training loss: 6.853222846984863
Epoch 180, training loss: 6.777821063995361
Epoch 190, training loss: 6.751603126525879
Epoch 200, training loss: 6.643675804138184
Epoch 210, training loss: 6.556349277496338
Epoch 220, training loss: 6.4933624267578125
Epoch 230, training loss: 6.603776454925537
Epoch 240, training loss: 6.543803691864014
Epoch 250, training loss: 6.496358871459961
Epoch 260, training loss: 6.422024726867676
Epoch 270, training loss: 6.393587112426758
Epoch 280, training loss: 6.243497371673584
Epoch 290, training loss: 6.402663707733154
Epoch 300, training loss: 6.358419895172119
Epoch 310, training loss: 6.30514669418335
Epoch 320, training loss: 6.317004203796387
Epoch 330, training loss: 6.116384029388428
Epoch 340, training loss: 6.262775897979736
Epoch 350, training loss: 6.159512996673584
Epoch 360, training loss: 6.189840793609619
Epoch 370, training loss: 6.134745121002197
Epoch 380, training loss: 6.225298881530762
Epoch 390, training loss: 5.970829963684082
Epoch 400, training loss: 6.006338119506836
Epoch 410, training loss: 6.05513334274292
Epoch 420, training loss: 6.009265899658203
Epoch 430, training loss: 6.017569541931152
Epoch 440, training loss: 5.937034606933594
Epoch 450, training loss: 5.968480587005615
Epoch 460, training loss: 5.951509952545166
Epoch 470, training loss: 5.910626411437988
Epoch 480, training loss: 5.817197322845459
Epoch 490, training loss: 5.842534065246582
random
Accuracy: 0.786
Accuracy: 0.781
Accuracy: 0.778
Accuracy: 0.748
Accuracy: 0.75
Accuracy: 0.723
Accuracy: 0.718
Accuracy: 0.716
Accuracy: 0.716
Accuracy: 0.708
Accuracy: 0.708
Accuracy: 0.713
Accuracy: 0.705
Accuracy: 0.7
Accuracy: 0.7
Accuracy: 0.702
Accuracy: 0.698
Accuracy: 0.689
Accuracy: 0.68
Accuracy: 0.684
Accuracy: 0.682
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596705436706543
Epoch 10, training loss: 8.592741966247559
Epoch 20, training loss: 8.563310623168945
Epoch 30, training loss: 8.382861137390137
Epoch 40, training loss: 8.103304862976074
Epoch 50, training loss: 7.924856662750244
Epoch 60, training loss: 7.754652500152588
Epoch 70, training loss: 7.420948028564453
Epoch 80, training loss: 7.621416091918945
Epoch 90, training loss: 7.361799716949463
Epoch 100, training loss: 7.234320640563965
Epoch 110, training loss: 7.160844326019287
Epoch 120, training loss: 7.063379764556885
Epoch 130, training loss: 6.953946590423584
Epoch 140, training loss: 7.007541179656982
Epoch 150, training loss: 6.873022079467773
Epoch 160, training loss: 6.876165390014648
Epoch 170, training loss: 6.805509567260742
Epoch 180, training loss: 6.915316581726074
Epoch 190, training loss: 6.723098278045654
Epoch 200, training loss: 6.760468006134033
Epoch 210, training loss: 6.535408020019531
Epoch 220, training loss: 6.529322147369385
Epoch 230, training loss: 6.564426422119141
Epoch 240, training loss: 6.539391994476318
Epoch 250, training loss: 6.511919021606445
Epoch 260, training loss: 6.498477935791016
Epoch 270, training loss: 6.499510288238525
Epoch 280, training loss: 6.485532283782959
Epoch 290, training loss: 6.40222692489624
Epoch 300, training loss: 6.311273574829102
Epoch 310, training loss: 6.281982421875
Epoch 320, training loss: 6.295070171356201
Epoch 330, training loss: 6.344221591949463
Epoch 340, training loss: 6.267948627471924
Epoch 350, training loss: 6.28235387802124
Epoch 360, training loss: 6.260082721710205
Epoch 370, training loss: 6.229557037353516
Epoch 380, training loss: 6.0741658210754395
Epoch 390, training loss: 6.081322193145752
Epoch 400, training loss: 6.07809591293335
Epoch 410, training loss: 6.036579132080078
Epoch 420, training loss: 6.007034778594971
Epoch 430, training loss: 6.057343482971191
Epoch 440, training loss: 5.971540451049805
Epoch 450, training loss: 5.913923740386963
Epoch 460, training loss: 5.973813533782959
Epoch 470, training loss: 5.967843532562256
Epoch 480, training loss: 6.009817600250244
Epoch 490, training loss: 5.964764595031738
random
Accuracy: 0.802
Accuracy: 0.793
Accuracy: 0.793
Accuracy: 0.785
Accuracy: 0.782
Accuracy: 0.76
Accuracy: 0.751
Accuracy: 0.747
Accuracy: 0.726
Accuracy: 0.73
Accuracy: 0.721
Accuracy: 0.716
Accuracy: 0.715
Accuracy: 0.717
Accuracy: 0.711
Accuracy: 0.71
Accuracy: 0.704
Accuracy: 0.706
Accuracy: 0.711
Accuracy: 0.692
Accuracy: 0.685
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596445083618164
Epoch 10, training loss: 8.591693878173828
Epoch 20, training loss: 8.56373405456543
Epoch 30, training loss: 8.323681831359863
Epoch 40, training loss: 8.111907958984375
Epoch 50, training loss: 7.820243835449219
Epoch 60, training loss: 7.615746974945068
Epoch 70, training loss: 7.578970909118652
Epoch 80, training loss: 7.430889129638672
Epoch 90, training loss: 7.222234725952148
Epoch 100, training loss: 7.226396560668945
Epoch 110, training loss: 7.125539302825928
Epoch 120, training loss: 7.043720245361328
Epoch 130, training loss: 7.047454833984375
Epoch 140, training loss: 6.935366630554199
Epoch 150, training loss: 6.887802600860596
Epoch 160, training loss: 6.736031532287598
Epoch 170, training loss: 6.784492015838623
Epoch 180, training loss: 6.661095142364502
Epoch 190, training loss: 6.575679302215576
Epoch 200, training loss: 6.624079704284668
Epoch 210, training loss: 6.449745178222656
Epoch 220, training loss: 6.38300085067749
Epoch 230, training loss: 6.408145427703857
Epoch 240, training loss: 6.507673740386963
Epoch 250, training loss: 6.382076740264893
Epoch 260, training loss: 6.2587995529174805
Epoch 270, training loss: 6.209266185760498
Epoch 280, training loss: 6.263791561126709
Epoch 290, training loss: 6.187124729156494
Epoch 300, training loss: 6.088964939117432
Epoch 310, training loss: 6.063145160675049
Epoch 320, training loss: 6.121792316436768
Epoch 330, training loss: 6.141409397125244
Epoch 340, training loss: 6.01632022857666
Epoch 350, training loss: 5.997527599334717
Epoch 360, training loss: 5.9941086769104
Epoch 370, training loss: 6.059288024902344
Epoch 380, training loss: 5.930496692657471
Epoch 390, training loss: 5.915807247161865
Epoch 400, training loss: 5.953602313995361
Epoch 410, training loss: 5.882537364959717
Epoch 420, training loss: 5.879010200500488
Epoch 430, training loss: 5.919155120849609
Epoch 440, training loss: 5.8796234130859375
Epoch 450, training loss: 5.856369972229004
Epoch 460, training loss: 5.800065040588379
Epoch 470, training loss: 5.733555316925049
Epoch 480, training loss: 5.75368595123291
Epoch 490, training loss: 5.773033618927002
random
Accuracy: 0.779
Accuracy: 0.778
Accuracy: 0.776
Accuracy: 0.773
Accuracy: 0.762
Accuracy: 0.753
Accuracy: 0.748
Accuracy: 0.739
Accuracy: 0.748
Accuracy: 0.732
Accuracy: 0.73
Accuracy: 0.728
Accuracy: 0.727
Accuracy: 0.722
Accuracy: 0.721
Accuracy: 0.721
Accuracy: 0.718
Accuracy: 0.731
Accuracy: 0.712
Accuracy: 0.688
Accuracy: 0.688
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596653938293457
Epoch 10, training loss: 8.590676307678223
Epoch 20, training loss: 8.571247100830078
Epoch 30, training loss: 8.439786911010742
Epoch 40, training loss: 8.171548843383789
Epoch 50, training loss: 7.934037685394287
Epoch 60, training loss: 7.680826187133789
Epoch 70, training loss: 7.471062183380127
Epoch 80, training loss: 7.4242634773254395
Epoch 90, training loss: 7.277866363525391
Epoch 100, training loss: 7.17998743057251
Epoch 110, training loss: 7.1202216148376465
Epoch 120, training loss: 6.935410499572754
Epoch 130, training loss: 7.138680458068848
Epoch 140, training loss: 6.813587665557861
Epoch 150, training loss: 6.81020975112915
Epoch 160, training loss: 6.678668975830078
Epoch 170, training loss: 6.696803092956543
Epoch 180, training loss: 6.641711235046387
Epoch 190, training loss: 6.661584377288818
Epoch 200, training loss: 6.485709190368652
Epoch 210, training loss: 6.448435306549072
Epoch 220, training loss: 6.457407474517822
Epoch 230, training loss: 6.343811988830566
Epoch 240, training loss: 6.292394638061523
Epoch 250, training loss: 6.445899486541748
Epoch 260, training loss: 6.29902982711792
Epoch 270, training loss: 6.271234035491943
Epoch 280, training loss: 6.217891693115234
Epoch 290, training loss: 6.199732303619385
Epoch 300, training loss: 6.214555263519287
Epoch 310, training loss: 6.076167583465576
Epoch 320, training loss: 6.103912353515625
Epoch 330, training loss: 6.023930549621582
Epoch 340, training loss: 5.986326694488525
Epoch 350, training loss: 6.0280022621154785
Epoch 360, training loss: 6.051632881164551
Epoch 370, training loss: 5.931859970092773
Epoch 380, training loss: 5.876763820648193
Epoch 390, training loss: 6.012417793273926
Epoch 400, training loss: 5.964044570922852
Epoch 410, training loss: 5.972980499267578
Epoch 420, training loss: 5.822286605834961
Epoch 430, training loss: 5.861660957336426
Epoch 440, training loss: 5.911620140075684
Epoch 450, training loss: 5.900343894958496
Epoch 460, training loss: 5.850928783416748
Epoch 470, training loss: 5.7550950050354
Epoch 480, training loss: 5.791581630706787
Epoch 490, training loss: 5.723751068115234
random
Accuracy: 0.768
Accuracy: 0.774
Accuracy: 0.774
Accuracy: 0.771
Accuracy: 0.765
Accuracy: 0.765
Accuracy: 0.755
Accuracy: 0.751
Accuracy: 0.748
Accuracy: 0.747
Accuracy: 0.744
Accuracy: 0.743
Accuracy: 0.742
Accuracy: 0.736
Accuracy: 0.744
Accuracy: 0.745
Accuracy: 0.742
Accuracy: 0.738
Accuracy: 0.735
Accuracy: 0.736
Accuracy: 0.735
Beta:0.1 Ptb size:0 Accuracy:0.7858+-0.0118
Beta:0.1 Ptb size:1 Accuracy:0.7826+-0.0067
Beta:0.1 Ptb size:2 Accuracy:0.7808+-0.0068
Beta:0.1 Ptb size:3 Accuracy:0.7698+-0.0120
Beta:0.1 Ptb size:4 Accuracy:0.7664+-0.0107
Beta:0.1 Ptb size:5 Accuracy:0.7524+-0.0152
Beta:0.1 Ptb size:6 Accuracy:0.7462+-0.0146
Beta:0.1 Ptb size:7 Accuracy:0.7420+-0.0143
Beta:0.1 Ptb size:8 Accuracy:0.7396+-0.0161
Beta:0.1 Ptb size:9 Accuracy:0.7348+-0.0167
Beta:0.1 Ptb size:10 Accuracy:0.7308+-0.0155
Beta:0.1 Ptb size:11 Accuracy:0.7302+-0.0148
Beta:0.1 Ptb size:12 Accuracy:0.7282+-0.0172
Beta:0.1 Ptb size:13 Accuracy:0.7238+-0.0153
Beta:0.1 Ptb size:14 Accuracy:0.7234+-0.0170
Beta:0.1 Ptb size:15 Accuracy:0.7242+-0.0173
Beta:0.1 Ptb size:16 Accuracy:0.7224+-0.0205
Beta:0.1 Ptb size:17 Accuracy:0.7218+-0.0210
Beta:0.1 Ptb size:18 Accuracy:0.7166+-0.0225
Beta:0.1 Ptb size:19 Accuracy:0.7096+-0.0268
Beta:0.1 Ptb size:20 Accuracy:0.7058+-0.0256
beta 0.2
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596563339233398
Epoch 10, training loss: 8.591590881347656
Epoch 20, training loss: 8.539996147155762
Epoch 30, training loss: 8.346061706542969
Epoch 40, training loss: 8.142212867736816
Epoch 50, training loss: 7.698904037475586
Epoch 60, training loss: 7.378020286560059
Epoch 70, training loss: 7.3590922355651855
Epoch 80, training loss: 7.228890419006348
Epoch 90, training loss: 7.104875564575195
Epoch 100, training loss: 7.3044586181640625
Epoch 110, training loss: 7.006103038787842
Epoch 120, training loss: 6.822018623352051
Epoch 130, training loss: 6.90436315536499
Epoch 140, training loss: 6.9216814041137695
Epoch 150, training loss: 6.817112445831299
Epoch 160, training loss: 6.708788871765137
Epoch 170, training loss: 6.57695198059082
Epoch 180, training loss: 6.503336429595947
Epoch 190, training loss: 6.4871602058410645
Epoch 200, training loss: 6.506842136383057
Epoch 210, training loss: 6.53566312789917
Epoch 220, training loss: 6.439605236053467
Epoch 230, training loss: 6.413393020629883
Epoch 240, training loss: 6.330458641052246
Epoch 250, training loss: 6.43134069442749
Epoch 260, training loss: 6.286158561706543
Epoch 270, training loss: 6.355859756469727
Epoch 280, training loss: 6.373737812042236
Epoch 290, training loss: 6.220087051391602
Epoch 300, training loss: 6.176418781280518
Epoch 310, training loss: 6.212423801422119
Epoch 320, training loss: 6.127780914306641
Epoch 330, training loss: 6.119167327880859
Epoch 340, training loss: 6.1020355224609375
Epoch 350, training loss: 6.097975730895996
Epoch 360, training loss: 6.093769550323486
Epoch 370, training loss: 6.0651044845581055
Epoch 380, training loss: 6.1523637771606445
Epoch 390, training loss: 5.9443464279174805
Epoch 400, training loss: 5.961498737335205
Epoch 410, training loss: 5.9889140129089355
Epoch 420, training loss: 5.989536285400391
Epoch 430, training loss: 6.021453380584717
Epoch 440, training loss: 5.797178745269775
Epoch 450, training loss: 5.863815784454346
Epoch 460, training loss: 5.850334644317627
Epoch 470, training loss: 5.816529273986816
Epoch 480, training loss: 5.8217082023620605
Epoch 490, training loss: 5.844379901885986
random
Accuracy: 0.791
Accuracy: 0.785
Accuracy: 0.788
Accuracy: 0.776
Accuracy: 0.773
Accuracy: 0.76
Accuracy: 0.759
Accuracy: 0.755
Accuracy: 0.756
Accuracy: 0.752
Accuracy: 0.744
Accuracy: 0.747
Accuracy: 0.744
Accuracy: 0.735
Accuracy: 0.729
Accuracy: 0.729
Accuracy: 0.737
Accuracy: 0.726
Accuracy: 0.727
Accuracy: 0.731
Accuracy: 0.723
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.596564292907715
Epoch 10, training loss: 8.593531608581543
Epoch 20, training loss: 8.569014549255371
Epoch 30, training loss: 8.397191047668457
Epoch 40, training loss: 8.17167854309082
Epoch 50, training loss: 7.872077465057373
Epoch 60, training loss: 7.686868190765381
Epoch 70, training loss: 7.56425666809082
Epoch 80, training loss: 7.310659408569336
Epoch 90, training loss: 7.442850112915039
Epoch 100, training loss: 7.364097595214844
Epoch 110, training loss: 7.069130897521973
Epoch 120, training loss: 7.173430442810059
Epoch 130, training loss: 7.147372245788574
Epoch 140, training loss: 6.946970462799072
Epoch 150, training loss: 6.8581414222717285
Epoch 160, training loss: 6.814868450164795
Epoch 170, training loss: 6.794050693511963
Epoch 180, training loss: 6.698958873748779
Epoch 190, training loss: 6.664620399475098
Epoch 200, training loss: 6.537119388580322
Epoch 210, training loss: 6.534994602203369
Epoch 220, training loss: 6.4487996101379395
Epoch 230, training loss: 6.499675273895264
Epoch 240, training loss: 6.469779014587402
Epoch 250, training loss: 6.423511505126953
Epoch 260, training loss: 6.3628411293029785
Epoch 270, training loss: 6.3336639404296875
Epoch 280, training loss: 6.163263320922852
Epoch 290, training loss: 6.306260585784912
Epoch 300, training loss: 6.278778076171875
Epoch 310, training loss: 6.225709915161133
Epoch 320, training loss: 6.231148719787598
Epoch 330, training loss: 6.0634965896606445
Epoch 340, training loss: 6.131228446960449
Epoch 350, training loss: 6.127191543579102
Epoch 360, training loss: 6.096378803253174
Epoch 370, training loss: 6.025552749633789
Epoch 380, training loss: 6.1054511070251465
Epoch 390, training loss: 5.912180423736572
Epoch 400, training loss: 5.935726165771484
Epoch 410, training loss: 5.961430549621582
Epoch 420, training loss: 5.9238810539245605
Epoch 430, training loss: 5.919814109802246
Epoch 440, training loss: 5.892148017883301
Epoch 450, training loss: 5.904680252075195
Epoch 460, training loss: 5.874682903289795
Epoch 470, training loss: 5.832282066345215
Epoch 480, training loss: 5.743771076202393
Epoch 490, training loss: 5.736249923706055
random
Accuracy: 0.789
Accuracy: 0.783
Accuracy: 0.773
Accuracy: 0.747
Accuracy: 0.745
Accuracy: 0.72
Accuracy: 0.714
Accuracy: 0.713
Accuracy: 0.708
Accuracy: 0.708
Accuracy: 0.707
Accuracy: 0.707
Accuracy: 0.701
Accuracy: 0.699
Accuracy: 0.693
Accuracy: 0.696
Accuracy: 0.707
Accuracy: 0.7
Accuracy: 0.686
Accuracy: 0.688
Accuracy: 0.685
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596654891967773
Epoch 10, training loss: 8.59132194519043
Epoch 20, training loss: 8.557158470153809
Epoch 30, training loss: 8.368685722351074
Epoch 40, training loss: 8.071290016174316
Epoch 50, training loss: 7.891249656677246
Epoch 60, training loss: 7.732253074645996
Epoch 70, training loss: 7.36651086807251
Epoch 80, training loss: 7.574851989746094
Epoch 90, training loss: 7.298806190490723
Epoch 100, training loss: 7.185794830322266
Epoch 110, training loss: 7.116100311279297
Epoch 120, training loss: 7.024618148803711
Epoch 130, training loss: 6.8967814445495605
Epoch 140, training loss: 6.968289852142334
Epoch 150, training loss: 6.779360294342041
Epoch 160, training loss: 6.812870502471924
Epoch 170, training loss: 6.7029337882995605
Epoch 180, training loss: 6.789319038391113
Epoch 190, training loss: 6.591442108154297
Epoch 200, training loss: 6.622495651245117
Epoch 210, training loss: 6.393218994140625
Epoch 220, training loss: 6.370787620544434
Epoch 230, training loss: 6.436944484710693
Epoch 240, training loss: 6.376272201538086
Epoch 250, training loss: 6.326211929321289
Epoch 260, training loss: 6.334324836730957
Epoch 270, training loss: 6.357243061065674
Epoch 280, training loss: 6.326623439788818
Epoch 290, training loss: 6.184864521026611
Epoch 300, training loss: 6.175331115722656
Epoch 310, training loss: 6.144656658172607
Epoch 320, training loss: 6.171480178833008
Epoch 330, training loss: 6.175289154052734
Epoch 340, training loss: 6.146458148956299
Epoch 350, training loss: 6.093502998352051
Epoch 360, training loss: 6.1059675216674805
Epoch 370, training loss: 6.06587553024292
Epoch 380, training loss: 5.89866828918457
Epoch 390, training loss: 5.8864054679870605
Epoch 400, training loss: 5.946490287780762
Epoch 410, training loss: 5.9155778884887695
Epoch 420, training loss: 5.825146675109863
Epoch 430, training loss: 5.876262187957764
Epoch 440, training loss: 5.80470085144043
Epoch 450, training loss: 5.801487445831299
Epoch 460, training loss: 5.853679180145264
Epoch 470, training loss: 5.845895767211914
Epoch 480, training loss: 5.862831115722656
Epoch 490, training loss: 5.844436168670654
random
Accuracy: 0.81
Accuracy: 0.805
Accuracy: 0.801
Accuracy: 0.794
Accuracy: 0.786
Accuracy: 0.77
Accuracy: 0.765
Accuracy: 0.761
Accuracy: 0.766
Accuracy: 0.766
Accuracy: 0.758
Accuracy: 0.756
Accuracy: 0.76
Accuracy: 0.755
Accuracy: 0.76
Accuracy: 0.751
Accuracy: 0.749
Accuracy: 0.748
Accuracy: 0.733
Accuracy: 0.711
Accuracy: 0.721
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596389770507812
Epoch 10, training loss: 8.590141296386719
Epoch 20, training loss: 8.55606460571289
Epoch 30, training loss: 8.300654411315918
Epoch 40, training loss: 8.064282417297363
Epoch 50, training loss: 7.7639946937561035
Epoch 60, training loss: 7.544154167175293
Epoch 70, training loss: 7.501006603240967
Epoch 80, training loss: 7.368708610534668
Epoch 90, training loss: 7.138678073883057
Epoch 100, training loss: 7.187975883483887
Epoch 110, training loss: 7.038778781890869
Epoch 120, training loss: 6.963089466094971
Epoch 130, training loss: 6.953165054321289
Epoch 140, training loss: 6.84639310836792
Epoch 150, training loss: 6.7885212898254395
Epoch 160, training loss: 6.680443286895752
Epoch 170, training loss: 6.715362071990967
Epoch 180, training loss: 6.590211391448975
Epoch 190, training loss: 6.51703405380249
Epoch 200, training loss: 6.57183837890625
Epoch 210, training loss: 6.3884782791137695
Epoch 220, training loss: 6.305255889892578
Epoch 230, training loss: 6.352572917938232
Epoch 240, training loss: 6.453078746795654
Epoch 250, training loss: 6.300571441650391
Epoch 260, training loss: 6.165790557861328
Epoch 270, training loss: 6.152112007141113
Epoch 280, training loss: 6.215117931365967
Epoch 290, training loss: 6.122916221618652
Epoch 300, training loss: 5.9928975105285645
Epoch 310, training loss: 6.035221099853516
Epoch 320, training loss: 6.089062690734863
Epoch 330, training loss: 6.067042350769043
Epoch 340, training loss: 5.948630332946777
Epoch 350, training loss: 5.957131385803223
Epoch 360, training loss: 5.93454122543335
Epoch 370, training loss: 6.039546489715576
Epoch 380, training loss: 5.85925817489624
Epoch 390, training loss: 5.842584133148193
Epoch 400, training loss: 5.881695747375488
Epoch 410, training loss: 5.85577392578125
Epoch 420, training loss: 5.819863319396973
Epoch 430, training loss: 5.87099027633667
Epoch 440, training loss: 5.816551685333252
Epoch 450, training loss: 5.792677402496338
Epoch 460, training loss: 5.738578796386719
Epoch 470, training loss: 5.706223964691162
Epoch 480, training loss: 5.7241644859313965
Epoch 490, training loss: 5.726994514465332
random
Accuracy: 0.774
Accuracy: 0.771
Accuracy: 0.776
Accuracy: 0.772
Accuracy: 0.771
Accuracy: 0.765
Accuracy: 0.75
Accuracy: 0.745
Accuracy: 0.749
Accuracy: 0.744
Accuracy: 0.734
Accuracy: 0.735
Accuracy: 0.734
Accuracy: 0.724
Accuracy: 0.73
Accuracy: 0.728
Accuracy: 0.735
Accuracy: 0.736
Accuracy: 0.741
Accuracy: 0.732
Accuracy: 0.727
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596578598022461
Epoch 10, training loss: 8.589119911193848
Epoch 20, training loss: 8.563241958618164
Epoch 30, training loss: 8.401524543762207
Epoch 40, training loss: 8.099761009216309
Epoch 50, training loss: 7.8859124183654785
Epoch 60, training loss: 7.657973766326904
Epoch 70, training loss: 7.418567180633545
Epoch 80, training loss: 7.374846935272217
Epoch 90, training loss: 7.241065979003906
Epoch 100, training loss: 7.109568119049072
Epoch 110, training loss: 7.078437328338623
Epoch 120, training loss: 6.883852481842041
Epoch 130, training loss: 7.045555114746094
Epoch 140, training loss: 6.740711688995361
Epoch 150, training loss: 6.755951404571533
Epoch 160, training loss: 6.627544403076172
Epoch 170, training loss: 6.659985065460205
Epoch 180, training loss: 6.570361614227295
Epoch 190, training loss: 6.588682651519775
Epoch 200, training loss: 6.430540084838867
Epoch 210, training loss: 6.40277624130249
Epoch 220, training loss: 6.410895347595215
Epoch 230, training loss: 6.300647735595703
Epoch 240, training loss: 6.2628984451293945
Epoch 250, training loss: 6.407172203063965
Epoch 260, training loss: 6.22911262512207
Epoch 270, training loss: 6.221724510192871
Epoch 280, training loss: 6.180210113525391
Epoch 290, training loss: 6.148685455322266
Epoch 300, training loss: 6.188537120819092
Epoch 310, training loss: 6.011856555938721
Epoch 320, training loss: 6.086199760437012
Epoch 330, training loss: 5.957045555114746
Epoch 340, training loss: 5.953929901123047
Epoch 350, training loss: 5.9855194091796875
Epoch 360, training loss: 5.9915595054626465
Epoch 370, training loss: 5.892721652984619
Epoch 380, training loss: 5.852896690368652
Epoch 390, training loss: 5.9522881507873535
Epoch 400, training loss: 5.916346549987793
Epoch 410, training loss: 5.916338920593262
Epoch 420, training loss: 5.813496112823486
Epoch 430, training loss: 5.801911354064941
Epoch 440, training loss: 5.82240629196167
Epoch 450, training loss: 5.797885417938232
Epoch 460, training loss: 5.813024044036865
Epoch 470, training loss: 5.7002763748168945
Epoch 480, training loss: 5.719025611877441
Epoch 490, training loss: 5.628358364105225
random
Accuracy: 0.766
Accuracy: 0.76
Accuracy: 0.764
Accuracy: 0.765
Accuracy: 0.766
Accuracy: 0.759
Accuracy: 0.745
Accuracy: 0.745
Accuracy: 0.745
Accuracy: 0.742
Accuracy: 0.735
Accuracy: 0.734
Accuracy: 0.729
Accuracy: 0.726
Accuracy: 0.722
Accuracy: 0.729
Accuracy: 0.731
Accuracy: 0.729
Accuracy: 0.729
Accuracy: 0.725
Accuracy: 0.724
Beta:0.2 Ptb size:0 Accuracy:0.7860+-0.0152
Beta:0.2 Ptb size:1 Accuracy:0.7808+-0.0151
Beta:0.2 Ptb size:2 Accuracy:0.7804+-0.0128
Beta:0.2 Ptb size:3 Accuracy:0.7708+-0.0153
Beta:0.2 Ptb size:4 Accuracy:0.7682+-0.0133
Beta:0.2 Ptb size:5 Accuracy:0.7548+-0.0178
Beta:0.2 Ptb size:6 Accuracy:0.7466+-0.0177
Beta:0.2 Ptb size:7 Accuracy:0.7438+-0.0166
Beta:0.2 Ptb size:8 Accuracy:0.7448+-0.0197
Beta:0.2 Ptb size:9 Accuracy:0.7424+-0.0192
Beta:0.2 Ptb size:10 Accuracy:0.7356+-0.0167
Beta:0.2 Ptb size:11 Accuracy:0.7358+-0.0165
Beta:0.2 Ptb size:12 Accuracy:0.7336+-0.0194
Beta:0.2 Ptb size:13 Accuracy:0.7278+-0.0181
Beta:0.2 Ptb size:14 Accuracy:0.7268+-0.0214
Beta:0.2 Ptb size:15 Accuracy:0.7266+-0.0176
Beta:0.2 Ptb size:16 Accuracy:0.7318+-0.0138
Beta:0.2 Ptb size:17 Accuracy:0.7278+-0.0158
Beta:0.2 Ptb size:18 Accuracy:0.7232+-0.0192
Beta:0.2 Ptb size:19 Accuracy:0.7174+-0.0165
Beta:0.2 Ptb size:20 Accuracy:0.7160+-0.0156
beta 0.3
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596513748168945
Epoch 10, training loss: 8.590322494506836
Epoch 20, training loss: 8.525104522705078
Epoch 30, training loss: 8.321078300476074
Epoch 40, training loss: 8.110328674316406
Epoch 50, training loss: 7.61769962310791
Epoch 60, training loss: 7.3174848556518555
Epoch 70, training loss: 7.289376735687256
Epoch 80, training loss: 7.140432834625244
Epoch 90, training loss: 7.005655765533447
Epoch 100, training loss: 7.233870029449463
Epoch 110, training loss: 6.923250198364258
Epoch 120, training loss: 6.750916004180908
Epoch 130, training loss: 6.812834739685059
Epoch 140, training loss: 6.836590766906738
Epoch 150, training loss: 6.748819351196289
Epoch 160, training loss: 6.632866382598877
Epoch 170, training loss: 6.483750343322754
Epoch 180, training loss: 6.412294387817383
Epoch 190, training loss: 6.3787970542907715
Epoch 200, training loss: 6.428207874298096
Epoch 210, training loss: 6.4229841232299805
Epoch 220, training loss: 6.3542094230651855
Epoch 230, training loss: 6.338754653930664
Epoch 240, training loss: 6.24661922454834
Epoch 250, training loss: 6.357938289642334
Epoch 260, training loss: 6.209901809692383
Epoch 270, training loss: 6.289161682128906
Epoch 280, training loss: 6.288778305053711
Epoch 290, training loss: 6.136186122894287
Epoch 300, training loss: 6.112456798553467
Epoch 310, training loss: 6.127073287963867
Epoch 320, training loss: 6.054462432861328
Epoch 330, training loss: 6.064823627471924
Epoch 340, training loss: 6.062117576599121
Epoch 350, training loss: 6.02334451675415
Epoch 360, training loss: 6.012368679046631
Epoch 370, training loss: 5.995585918426514
Epoch 380, training loss: 6.116113662719727
Epoch 390, training loss: 5.894299507141113
Epoch 400, training loss: 5.89631986618042
Epoch 410, training loss: 5.944397449493408
Epoch 420, training loss: 5.946029186248779
Epoch 430, training loss: 5.97083854675293
Epoch 440, training loss: 5.750100612640381
Epoch 450, training loss: 5.833899021148682
Epoch 460, training loss: 5.767345428466797
Epoch 470, training loss: 5.741649150848389
Epoch 480, training loss: 5.786618232727051
Epoch 490, training loss: 5.774035453796387
random
Accuracy: 0.797
Accuracy: 0.8
Accuracy: 0.792
Accuracy: 0.786
Accuracy: 0.786
Accuracy: 0.768
Accuracy: 0.76
Accuracy: 0.762
Accuracy: 0.763
Accuracy: 0.755
Accuracy: 0.749
Accuracy: 0.751
Accuracy: 0.746
Accuracy: 0.727
Accuracy: 0.726
Accuracy: 0.724
Accuracy: 0.732
Accuracy: 0.729
Accuracy: 0.73
Accuracy: 0.72
Accuracy: 0.719
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.59652328491211
Epoch 10, training loss: 8.592130661010742
Epoch 20, training loss: 8.556940078735352
Epoch 30, training loss: 8.397757530212402
Epoch 40, training loss: 8.172186851501465
Epoch 50, training loss: 7.866781234741211
Epoch 60, training loss: 7.670034885406494
Epoch 70, training loss: 7.519048690795898
Epoch 80, training loss: 7.283834934234619
Epoch 90, training loss: 7.405148029327393
Epoch 100, training loss: 7.298666477203369
Epoch 110, training loss: 7.015981674194336
Epoch 120, training loss: 7.092002868652344
Epoch 130, training loss: 7.089572429656982
Epoch 140, training loss: 6.877053737640381
Epoch 150, training loss: 6.80142879486084
Epoch 160, training loss: 6.738455772399902
Epoch 170, training loss: 6.735654354095459
Epoch 180, training loss: 6.610899448394775
Epoch 190, training loss: 6.594500541687012
Epoch 200, training loss: 6.4479522705078125
Epoch 210, training loss: 6.445244789123535
Epoch 220, training loss: 6.35713529586792
Epoch 230, training loss: 6.404816627502441
Epoch 240, training loss: 6.380889415740967
Epoch 250, training loss: 6.334965229034424
Epoch 260, training loss: 6.2513933181762695
Epoch 270, training loss: 6.226459980010986
Epoch 280, training loss: 6.045803070068359
Epoch 290, training loss: 6.195284366607666
Epoch 300, training loss: 6.175204277038574
Epoch 310, training loss: 6.125431060791016
Epoch 320, training loss: 6.123728275299072
Epoch 330, training loss: 5.953057765960693
Epoch 340, training loss: 6.014374256134033
Epoch 350, training loss: 6.025920391082764
Epoch 360, training loss: 5.99406099319458
Epoch 370, training loss: 5.906516075134277
Epoch 380, training loss: 5.976184368133545
Epoch 390, training loss: 5.851452350616455
Epoch 400, training loss: 5.8460164070129395
Epoch 410, training loss: 5.845808506011963
Epoch 420, training loss: 5.797328948974609
Epoch 430, training loss: 5.827224254608154
Epoch 440, training loss: 5.801380157470703
Epoch 450, training loss: 5.825806140899658
Epoch 460, training loss: 5.756613254547119
Epoch 470, training loss: 5.762608528137207
Epoch 480, training loss: 5.6430792808532715
Epoch 490, training loss: 5.6414289474487305
random
Accuracy: 0.798
Accuracy: 0.788
Accuracy: 0.779
Accuracy: 0.766
Accuracy: 0.753
Accuracy: 0.723
Accuracy: 0.714
Accuracy: 0.707
Accuracy: 0.711
Accuracy: 0.7
Accuracy: 0.699
Accuracy: 0.688
Accuracy: 0.683
Accuracy: 0.683
Accuracy: 0.679
Accuracy: 0.676
Accuracy: 0.685
Accuracy: 0.685
Accuracy: 0.681
Accuracy: 0.673
Accuracy: 0.666
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596610069274902
Epoch 10, training loss: 8.588396072387695
Epoch 20, training loss: 8.54849910736084
Epoch 30, training loss: 8.360849380493164
Epoch 40, training loss: 8.032716751098633
Epoch 50, training loss: 7.847753524780273
Epoch 60, training loss: 7.683874130249023
Epoch 70, training loss: 7.294210433959961
Epoch 80, training loss: 7.496237754821777
Epoch 90, training loss: 7.237939834594727
Epoch 100, training loss: 7.083985805511475
Epoch 110, training loss: 7.016410827636719
Epoch 120, training loss: 6.944368362426758
Epoch 130, training loss: 6.797959804534912
Epoch 140, training loss: 6.892045497894287
Epoch 150, training loss: 6.624670028686523
Epoch 160, training loss: 6.655876159667969
Epoch 170, training loss: 6.561853408813477
Epoch 180, training loss: 6.63401985168457
Epoch 190, training loss: 6.467869758605957
Epoch 200, training loss: 6.478587627410889
Epoch 210, training loss: 6.260622501373291
Epoch 220, training loss: 6.220877647399902
Epoch 230, training loss: 6.309148788452148
Epoch 240, training loss: 6.253847122192383
Epoch 250, training loss: 6.2093000411987305
Epoch 260, training loss: 6.229693412780762
Epoch 270, training loss: 6.232468128204346
Epoch 280, training loss: 6.197722911834717
Epoch 290, training loss: 6.061717987060547
Epoch 300, training loss: 6.056332588195801
Epoch 310, training loss: 6.027857303619385
Epoch 320, training loss: 6.060925483703613
Epoch 330, training loss: 6.043076038360596
Epoch 340, training loss: 6.0200347900390625
Epoch 350, training loss: 5.999188423156738
Epoch 360, training loss: 5.971903324127197
Epoch 370, training loss: 5.956113815307617
Epoch 380, training loss: 5.782562732696533
Epoch 390, training loss: 5.78326416015625
Epoch 400, training loss: 5.819517612457275
Epoch 410, training loss: 5.795811176300049
Epoch 420, training loss: 5.7336955070495605
Epoch 430, training loss: 5.760823726654053
Epoch 440, training loss: 5.707043170928955
Epoch 450, training loss: 5.684185981750488
Epoch 460, training loss: 5.721752166748047
Epoch 470, training loss: 5.732340335845947
Epoch 480, training loss: 5.731833457946777
Epoch 490, training loss: 5.7289719581604
random
Accuracy: 0.805
Accuracy: 0.8
Accuracy: 0.794
Accuracy: 0.784
Accuracy: 0.778
Accuracy: 0.759
Accuracy: 0.759
Accuracy: 0.759
Accuracy: 0.758
Accuracy: 0.744
Accuracy: 0.747
Accuracy: 0.737
Accuracy: 0.733
Accuracy: 0.732
Accuracy: 0.723
Accuracy: 0.754
Accuracy: 0.741
Accuracy: 0.724
Accuracy: 0.738
Accuracy: 0.718
Accuracy: 0.729
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596327781677246
Epoch 10, training loss: 8.587976455688477
Epoch 20, training loss: 8.552777290344238
Epoch 30, training loss: 8.309673309326172
Epoch 40, training loss: 8.064374923706055
Epoch 50, training loss: 7.75137186050415
Epoch 60, training loss: 7.46555757522583
Epoch 70, training loss: 7.440756797790527
Epoch 80, training loss: 7.284841537475586
Epoch 90, training loss: 7.050968647003174
Epoch 100, training loss: 7.120553970336914
Epoch 110, training loss: 6.968912124633789
Epoch 120, training loss: 6.865172386169434
Epoch 130, training loss: 6.884596824645996
Epoch 140, training loss: 6.765777587890625
Epoch 150, training loss: 6.701464653015137
Epoch 160, training loss: 6.621655464172363
Epoch 170, training loss: 6.631069183349609
Epoch 180, training loss: 6.521289348602295
Epoch 190, training loss: 6.469078063964844
Epoch 200, training loss: 6.5295281410217285
Epoch 210, training loss: 6.33579158782959
Epoch 220, training loss: 6.292920112609863
Epoch 230, training loss: 6.300929069519043
Epoch 240, training loss: 6.354442119598389
Epoch 250, training loss: 6.291384696960449
Epoch 260, training loss: 6.130544662475586
Epoch 270, training loss: 6.107051849365234
Epoch 280, training loss: 6.177203178405762
Epoch 290, training loss: 6.070925235748291
Epoch 300, training loss: 5.975209712982178
Epoch 310, training loss: 6.010408401489258
Epoch 320, training loss: 6.008610248565674
Epoch 330, training loss: 5.986025333404541
Epoch 340, training loss: 5.90952730178833
Epoch 350, training loss: 5.910797119140625
Epoch 360, training loss: 5.9107866287231445
Epoch 370, training loss: 6.009140968322754
Epoch 380, training loss: 5.807394027709961
Epoch 390, training loss: 5.809286117553711
Epoch 400, training loss: 5.8667778968811035
Epoch 410, training loss: 5.8139872550964355
Epoch 420, training loss: 5.778448581695557
Epoch 430, training loss: 5.83463716506958
Epoch 440, training loss: 5.7772064208984375
Epoch 450, training loss: 5.739384174346924
Epoch 460, training loss: 5.668315410614014
Epoch 470, training loss: 5.6493096351623535
Epoch 480, training loss: 5.684739112854004
Epoch 490, training loss: 5.656431674957275
random
Accuracy: 0.781
Accuracy: 0.781
Accuracy: 0.777
Accuracy: 0.772
Accuracy: 0.773
Accuracy: 0.771
Accuracy: 0.756
Accuracy: 0.753
Accuracy: 0.746
Accuracy: 0.746
Accuracy: 0.735
Accuracy: 0.741
Accuracy: 0.731
Accuracy: 0.729
Accuracy: 0.73
Accuracy: 0.719
Accuracy: 0.727
Accuracy: 0.735
Accuracy: 0.721
Accuracy: 0.716
Accuracy: 0.719
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596494674682617
Epoch 10, training loss: 8.586835861206055
Epoch 20, training loss: 8.556207656860352
Epoch 30, training loss: 8.387264251708984
Epoch 40, training loss: 8.045025825500488
Epoch 50, training loss: 7.859382152557373
Epoch 60, training loss: 7.634151458740234
Epoch 70, training loss: 7.363238334655762
Epoch 80, training loss: 7.2929887771606445
Epoch 90, training loss: 7.153789043426514
Epoch 100, training loss: 7.006260871887207
Epoch 110, training loss: 6.959014415740967
Epoch 120, training loss: 6.768247127532959
Epoch 130, training loss: 6.946536540985107
Epoch 140, training loss: 6.619953155517578
Epoch 150, training loss: 6.623717308044434
Epoch 160, training loss: 6.49367094039917
Epoch 170, training loss: 6.5361433029174805
Epoch 180, training loss: 6.456726551055908
Epoch 190, training loss: 6.484906196594238
Epoch 200, training loss: 6.311324119567871
Epoch 210, training loss: 6.268470287322998
Epoch 220, training loss: 6.266911506652832
Epoch 230, training loss: 6.176945209503174
Epoch 240, training loss: 6.169732570648193
Epoch 250, training loss: 6.2761549949646
Epoch 260, training loss: 6.125680923461914
Epoch 270, training loss: 6.10561990737915
Epoch 280, training loss: 6.071715354919434
Epoch 290, training loss: 6.035084247589111
Epoch 300, training loss: 6.079412460327148
Epoch 310, training loss: 5.910304069519043
Epoch 320, training loss: 5.969188213348389
Epoch 330, training loss: 5.850071907043457
Epoch 340, training loss: 5.846806526184082
Epoch 350, training loss: 5.905176639556885
Epoch 360, training loss: 5.875920295715332
Epoch 370, training loss: 5.784438610076904
Epoch 380, training loss: 5.737955093383789
Epoch 390, training loss: 5.867014408111572
Epoch 400, training loss: 5.823875427246094
Epoch 410, training loss: 5.83755350112915
Epoch 420, training loss: 5.6974053382873535
Epoch 430, training loss: 5.671112060546875
Epoch 440, training loss: 5.715442180633545
Epoch 450, training loss: 5.683322906494141
Epoch 460, training loss: 5.715639114379883
Epoch 470, training loss: 5.605088710784912
Epoch 480, training loss: 5.616594314575195
Epoch 490, training loss: 5.505156993865967
random
Accuracy: 0.78
Accuracy: 0.778
Accuracy: 0.78
Accuracy: 0.767
Accuracy: 0.763
Accuracy: 0.757
Accuracy: 0.744
Accuracy: 0.746
Accuracy: 0.748
Accuracy: 0.733
Accuracy: 0.732
Accuracy: 0.73
Accuracy: 0.729
Accuracy: 0.723
Accuracy: 0.722
Accuracy: 0.727
Accuracy: 0.715
Accuracy: 0.72
Accuracy: 0.714
Accuracy: 0.715
Accuracy: 0.714
Beta:0.3 Ptb size:0 Accuracy:0.7922+-0.0099
Beta:0.3 Ptb size:1 Accuracy:0.7894+-0.0092
Beta:0.3 Ptb size:2 Accuracy:0.7844+-0.0071
Beta:0.3 Ptb size:3 Accuracy:0.7750+-0.0084
Beta:0.3 Ptb size:4 Accuracy:0.7706+-0.0115
Beta:0.3 Ptb size:5 Accuracy:0.7556+-0.0171
Beta:0.3 Ptb size:6 Accuracy:0.7466+-0.0173
Beta:0.3 Ptb size:7 Accuracy:0.7454+-0.0200
Beta:0.3 Ptb size:8 Accuracy:0.7452+-0.0182
Beta:0.3 Ptb size:9 Accuracy:0.7356+-0.0191
Beta:0.3 Ptb size:10 Accuracy:0.7324+-0.0180
Beta:0.3 Ptb size:11 Accuracy:0.7294+-0.0218
Beta:0.3 Ptb size:12 Accuracy:0.7244+-0.0215
Beta:0.3 Ptb size:13 Accuracy:0.7188+-0.0181
Beta:0.3 Ptb size:14 Accuracy:0.7160+-0.0187
Beta:0.3 Ptb size:15 Accuracy:0.7200+-0.0251
Beta:0.3 Ptb size:16 Accuracy:0.7200+-0.0194
Beta:0.3 Ptb size:17 Accuracy:0.7186+-0.0175
Beta:0.3 Ptb size:18 Accuracy:0.7168+-0.0197
Beta:0.3 Ptb size:19 Accuracy:0.7084+-0.0178
Beta:0.3 Ptb size:20 Accuracy:0.7094+-0.0222
beta 0.4
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596488952636719
Epoch 10, training loss: 8.588082313537598
Epoch 20, training loss: 8.513216018676758
Epoch 30, training loss: 8.296517372131348
Epoch 40, training loss: 8.103577613830566
Epoch 50, training loss: 7.572339057922363
Epoch 60, training loss: 7.2660040855407715
Epoch 70, training loss: 7.275381088256836
Epoch 80, training loss: 7.093356132507324
Epoch 90, training loss: 6.925669193267822
Epoch 100, training loss: 7.15401554107666
Epoch 110, training loss: 6.840156555175781
Epoch 120, training loss: 6.656423568725586
Epoch 130, training loss: 6.754720211029053
Epoch 140, training loss: 6.756878852844238
Epoch 150, training loss: 6.667446613311768
Epoch 160, training loss: 6.5443620681762695
Epoch 170, training loss: 6.399163722991943
Epoch 180, training loss: 6.333389759063721
Epoch 190, training loss: 6.296929836273193
Epoch 200, training loss: 6.347530841827393
Epoch 210, training loss: 6.330623149871826
Epoch 220, training loss: 6.2344136238098145
Epoch 230, training loss: 6.242728233337402
Epoch 240, training loss: 6.148961544036865
Epoch 250, training loss: 6.262208938598633
Epoch 260, training loss: 6.103943824768066
Epoch 270, training loss: 6.216206073760986
Epoch 280, training loss: 6.181211948394775
Epoch 290, training loss: 6.029239654541016
Epoch 300, training loss: 6.004183769226074
Epoch 310, training loss: 6.040261745452881
Epoch 320, training loss: 5.967016220092773
Epoch 330, training loss: 5.958624839782715
Epoch 340, training loss: 5.966269016265869
Epoch 350, training loss: 5.899883270263672
Epoch 360, training loss: 5.908527374267578
Epoch 370, training loss: 5.868755340576172
Epoch 380, training loss: 5.968242645263672
Epoch 390, training loss: 5.784280776977539
Epoch 400, training loss: 5.787750720977783
Epoch 410, training loss: 5.784658432006836
Epoch 420, training loss: 5.847288131713867
Epoch 430, training loss: 5.886787414550781
Epoch 440, training loss: 5.6626410484313965
Epoch 450, training loss: 5.726452827453613
Epoch 460, training loss: 5.640833377838135
Epoch 470, training loss: 5.644679546356201
Epoch 480, training loss: 5.676375389099121
Epoch 490, training loss: 5.651333332061768
random
Accuracy: 0.799
Accuracy: 0.796
Accuracy: 0.791
Accuracy: 0.787
Accuracy: 0.786
Accuracy: 0.767
Accuracy: 0.757
Accuracy: 0.761
Accuracy: 0.76
Accuracy: 0.76
Accuracy: 0.748
Accuracy: 0.743
Accuracy: 0.739
Accuracy: 0.728
Accuracy: 0.724
Accuracy: 0.727
Accuracy: 0.731
Accuracy: 0.721
Accuracy: 0.707
Accuracy: 0.716
Accuracy: 0.717
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.596508979797363
Epoch 10, training loss: 8.589892387390137
Epoch 20, training loss: 8.540875434875488
Epoch 30, training loss: 8.400217056274414
Epoch 40, training loss: 8.173572540283203
Epoch 50, training loss: 7.889484405517578
Epoch 60, training loss: 7.674417018890381
Epoch 70, training loss: 7.516982078552246
Epoch 80, training loss: 7.312442779541016
Epoch 90, training loss: 7.352672576904297
Epoch 100, training loss: 7.246078968048096
Epoch 110, training loss: 6.965999603271484
Epoch 120, training loss: 7.011822700500488
Epoch 130, training loss: 6.9978837966918945
Epoch 140, training loss: 6.798608779907227
Epoch 150, training loss: 6.75952672958374
Epoch 160, training loss: 6.675148010253906
Epoch 170, training loss: 6.639191627502441
Epoch 180, training loss: 6.5259857177734375
Epoch 190, training loss: 6.514410495758057
Epoch 200, training loss: 6.3646039962768555
Epoch 210, training loss: 6.380439281463623
Epoch 220, training loss: 6.251201629638672
Epoch 230, training loss: 6.254684925079346
Epoch 240, training loss: 6.265236854553223
Epoch 250, training loss: 6.237873554229736
Epoch 260, training loss: 6.11444616317749
Epoch 270, training loss: 6.081739902496338
Epoch 280, training loss: 5.928571701049805
Epoch 290, training loss: 6.048591136932373
Epoch 300, training loss: 6.04071044921875
Epoch 310, training loss: 5.989735126495361
Epoch 320, training loss: 5.9863505363464355
Epoch 330, training loss: 5.804069519042969
Epoch 340, training loss: 5.871331691741943
Epoch 350, training loss: 5.8912553787231445
Epoch 360, training loss: 5.832744598388672
Epoch 370, training loss: 5.801157474517822
Epoch 380, training loss: 5.866901874542236
Epoch 390, training loss: 5.732422351837158
Epoch 400, training loss: 5.6968488693237305
Epoch 410, training loss: 5.678779125213623
Epoch 420, training loss: 5.677097320556641
Epoch 430, training loss: 5.695450305938721
Epoch 440, training loss: 5.663464546203613
Epoch 450, training loss: 5.666616439819336
Epoch 460, training loss: 5.625636577606201
Epoch 470, training loss: 5.598150730133057
Epoch 480, training loss: 5.5186381340026855
Epoch 490, training loss: 5.5306477546691895
random
Accuracy: 0.8
Accuracy: 0.788
Accuracy: 0.788
Accuracy: 0.775
Accuracy: 0.771
Accuracy: 0.763
Accuracy: 0.747
Accuracy: 0.735
Accuracy: 0.735
Accuracy: 0.726
Accuracy: 0.729
Accuracy: 0.723
Accuracy: 0.699
Accuracy: 0.704
Accuracy: 0.697
Accuracy: 0.697
Accuracy: 0.712
Accuracy: 0.716
Accuracy: 0.699
Accuracy: 0.694
Accuracy: 0.699
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596574783325195
Epoch 10, training loss: 8.585512161254883
Epoch 20, training loss: 8.536781311035156
Epoch 30, training loss: 8.3513822555542
Epoch 40, training loss: 7.972998142242432
Epoch 50, training loss: 7.826412677764893
Epoch 60, training loss: 7.617239475250244
Epoch 70, training loss: 7.222993850708008
Epoch 80, training loss: 7.440535068511963
Epoch 90, training loss: 7.167341709136963
Epoch 100, training loss: 6.997794151306152
Epoch 110, training loss: 6.897782325744629
Epoch 120, training loss: 6.873763561248779
Epoch 130, training loss: 6.704160690307617
Epoch 140, training loss: 6.811208724975586
Epoch 150, training loss: 6.521797180175781
Epoch 160, training loss: 6.539072513580322
Epoch 170, training loss: 6.459529399871826
Epoch 180, training loss: 6.5114922523498535
Epoch 190, training loss: 6.34473991394043
Epoch 200, training loss: 6.419228553771973
Epoch 210, training loss: 6.17147970199585
Epoch 220, training loss: 6.094821453094482
Epoch 230, training loss: 6.167142868041992
Epoch 240, training loss: 6.134839057922363
Epoch 250, training loss: 6.1045966148376465
Epoch 260, training loss: 6.116759777069092
Epoch 270, training loss: 6.082940578460693
Epoch 280, training loss: 6.073179244995117
Epoch 290, training loss: 5.9268083572387695
Epoch 300, training loss: 5.892444610595703
Epoch 310, training loss: 5.9306135177612305
Epoch 320, training loss: 5.94858980178833
Epoch 330, training loss: 5.911034107208252
Epoch 340, training loss: 5.897385120391846
Epoch 350, training loss: 5.837461948394775
Epoch 360, training loss: 5.839597702026367
Epoch 370, training loss: 5.875210285186768
Epoch 380, training loss: 5.686692237854004
Epoch 390, training loss: 5.667031288146973
Epoch 400, training loss: 5.685794830322266
Epoch 410, training loss: 5.6734185218811035
Epoch 420, training loss: 5.60915470123291
Epoch 430, training loss: 5.621362686157227
Epoch 440, training loss: 5.590944766998291
Epoch 450, training loss: 5.55259370803833
Epoch 460, training loss: 5.611349582672119
Epoch 470, training loss: 5.581447601318359
Epoch 480, training loss: 5.594593048095703
Epoch 490, training loss: 5.618391990661621
random
Accuracy: 0.8
Accuracy: 0.791
Accuracy: 0.779
Accuracy: 0.775
Accuracy: 0.779
Accuracy: 0.763
Accuracy: 0.764
Accuracy: 0.76
Accuracy: 0.764
Accuracy: 0.761
Accuracy: 0.75
Accuracy: 0.754
Accuracy: 0.74
Accuracy: 0.743
Accuracy: 0.75
Accuracy: 0.749
Accuracy: 0.748
Accuracy: 0.743
Accuracy: 0.745
Accuracy: 0.745
Accuracy: 0.743
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596341133117676
Epoch 10, training loss: 8.585060119628906
Epoch 20, training loss: 8.54501724243164
Epoch 30, training loss: 8.382918357849121
Epoch 40, training loss: 8.058915138244629
Epoch 50, training loss: 7.696994304656982
Epoch 60, training loss: 7.381376266479492
Epoch 70, training loss: 7.3744940757751465
Epoch 80, training loss: 7.210084915161133
Epoch 90, training loss: 6.950623035430908
Epoch 100, training loss: 7.034205436706543
Epoch 110, training loss: 6.8746232986450195
Epoch 120, training loss: 6.748847484588623
Epoch 130, training loss: 6.7791266441345215
Epoch 140, training loss: 6.674163341522217
Epoch 150, training loss: 6.613797664642334
Epoch 160, training loss: 6.5304484367370605
Epoch 170, training loss: 6.539344310760498
Epoch 180, training loss: 6.404011249542236
Epoch 190, training loss: 6.364089488983154
Epoch 200, training loss: 6.400001049041748
Epoch 210, training loss: 6.230886936187744
Epoch 220, training loss: 6.193758010864258
Epoch 230, training loss: 6.2112321853637695
Epoch 240, training loss: 6.274083614349365
Epoch 250, training loss: 6.205300331115723
Epoch 260, training loss: 6.0190582275390625
Epoch 270, training loss: 5.9982500076293945
Epoch 280, training loss: 6.062864780426025
Epoch 290, training loss: 5.958499431610107
Epoch 300, training loss: 5.877706527709961
Epoch 310, training loss: 5.922637462615967
Epoch 320, training loss: 5.86850643157959
Epoch 330, training loss: 5.874343395233154
Epoch 340, training loss: 5.831062316894531
Epoch 350, training loss: 5.783071041107178
Epoch 360, training loss: 5.81052303314209
Epoch 370, training loss: 5.880873680114746
Epoch 380, training loss: 5.714958190917969
Epoch 390, training loss: 5.704580307006836
Epoch 400, training loss: 5.770040988922119
Epoch 410, training loss: 5.719618797302246
Epoch 420, training loss: 5.665170669555664
Epoch 430, training loss: 5.736963272094727
Epoch 440, training loss: 5.6417460441589355
Epoch 450, training loss: 5.631599426269531
Epoch 460, training loss: 5.5758748054504395
Epoch 470, training loss: 5.560479164123535
Epoch 480, training loss: 5.5657267570495605
Epoch 490, training loss: 5.548446178436279
random
Accuracy: 0.774
Accuracy: 0.775
Accuracy: 0.773
Accuracy: 0.77
Accuracy: 0.77
Accuracy: 0.766
Accuracy: 0.76
Accuracy: 0.767
Accuracy: 0.765
Accuracy: 0.756
Accuracy: 0.752
Accuracy: 0.746
Accuracy: 0.739
Accuracy: 0.73
Accuracy: 0.733
Accuracy: 0.725
Accuracy: 0.729
Accuracy: 0.728
Accuracy: 0.716
Accuracy: 0.718
Accuracy: 0.72
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.59643840789795
Epoch 10, training loss: 8.583183288574219
Epoch 20, training loss: 8.541041374206543
Epoch 30, training loss: 8.407464981079102
Epoch 40, training loss: 8.008082389831543
Epoch 50, training loss: 7.820878028869629
Epoch 60, training loss: 7.568662166595459
Epoch 70, training loss: 7.3071136474609375
Epoch 80, training loss: 7.1721367835998535
Epoch 90, training loss: 7.035898208618164
Epoch 100, training loss: 6.8872294425964355
Epoch 110, training loss: 6.8393473625183105
Epoch 120, training loss: 6.663391590118408
Epoch 130, training loss: 6.844602584838867
Epoch 140, training loss: 6.521234512329102
Epoch 150, training loss: 6.524425506591797
Epoch 160, training loss: 6.4018144607543945
Epoch 170, training loss: 6.438231945037842
Epoch 180, training loss: 6.357570171356201
Epoch 190, training loss: 6.409290790557861
Epoch 200, training loss: 6.22818660736084
Epoch 210, training loss: 6.167299270629883
Epoch 220, training loss: 6.180313587188721
Epoch 230, training loss: 6.084763050079346
Epoch 240, training loss: 6.08405876159668
Epoch 250, training loss: 6.221329689025879
Epoch 260, training loss: 6.058135032653809
Epoch 270, training loss: 6.015538215637207
Epoch 280, training loss: 6.007535934448242
Epoch 290, training loss: 5.948522090911865
Epoch 300, training loss: 5.99202299118042
Epoch 310, training loss: 5.834270477294922
Epoch 320, training loss: 5.880061626434326
Epoch 330, training loss: 5.76569128036499
Epoch 340, training loss: 5.745229721069336
Epoch 350, training loss: 5.829400539398193
Epoch 360, training loss: 5.799991607666016
Epoch 370, training loss: 5.711375713348389
Epoch 380, training loss: 5.652836799621582
Epoch 390, training loss: 5.754443168640137
Epoch 400, training loss: 5.74444055557251
Epoch 410, training loss: 5.745110988616943
Epoch 420, training loss: 5.613053798675537
Epoch 430, training loss: 5.6075921058654785
Epoch 440, training loss: 5.646197319030762
Epoch 450, training loss: 5.623876094818115
Epoch 460, training loss: 5.598872661590576
Epoch 470, training loss: 5.53485107421875
Epoch 480, training loss: 5.498878002166748
Epoch 490, training loss: 5.467950344085693
random
Accuracy: 0.768
Accuracy: 0.77
Accuracy: 0.772
Accuracy: 0.77
Accuracy: 0.766
Accuracy: 0.751
Accuracy: 0.745
Accuracy: 0.747
Accuracy: 0.743
Accuracy: 0.731
Accuracy: 0.728
Accuracy: 0.722
Accuracy: 0.72
Accuracy: 0.704
Accuracy: 0.707
Accuracy: 0.706
Accuracy: 0.71
Accuracy: 0.706
Accuracy: 0.699
Accuracy: 0.704
Accuracy: 0.703
Beta:0.4 Ptb size:0 Accuracy:0.7882+-0.0142
Beta:0.4 Ptb size:1 Accuracy:0.7840+-0.0099
Beta:0.4 Ptb size:2 Accuracy:0.7806+-0.0077
Beta:0.4 Ptb size:3 Accuracy:0.7754+-0.0062
Beta:0.4 Ptb size:4 Accuracy:0.7744+-0.0072
Beta:0.4 Ptb size:5 Accuracy:0.7620+-0.0057
Beta:0.4 Ptb size:6 Accuracy:0.7546+-0.0074
Beta:0.4 Ptb size:7 Accuracy:0.7540+-0.0115
Beta:0.4 Ptb size:8 Accuracy:0.7534+-0.0121
Beta:0.4 Ptb size:9 Accuracy:0.7468+-0.0151
Beta:0.4 Ptb size:10 Accuracy:0.7414+-0.0106
Beta:0.4 Ptb size:11 Accuracy:0.7376+-0.0128
Beta:0.4 Ptb size:12 Accuracy:0.7274+-0.0161
Beta:0.4 Ptb size:13 Accuracy:0.7218+-0.0154
Beta:0.4 Ptb size:14 Accuracy:0.7222+-0.0188
Beta:0.4 Ptb size:15 Accuracy:0.7208+-0.0181
Beta:0.4 Ptb size:16 Accuracy:0.7260+-0.0139
Beta:0.4 Ptb size:17 Accuracy:0.7228+-0.0124
Beta:0.4 Ptb size:18 Accuracy:0.7132+-0.0171
Beta:0.4 Ptb size:19 Accuracy:0.7154+-0.0172
Beta:0.4 Ptb size:20 Accuracy:0.7164+-0.0155
beta 0.5
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596475601196289
Epoch 10, training loss: 8.585864067077637
Epoch 20, training loss: 8.49661636352539
Epoch 30, training loss: 8.3001708984375
Epoch 40, training loss: 8.030060768127441
Epoch 50, training loss: 7.506731033325195
Epoch 60, training loss: 7.215855598449707
Epoch 70, training loss: 7.234662055969238
Epoch 80, training loss: 7.016725540161133
Epoch 90, training loss: 6.840502738952637
Epoch 100, training loss: 7.093842029571533
Epoch 110, training loss: 6.7567362785339355
Epoch 120, training loss: 6.579812526702881
Epoch 130, training loss: 6.659369945526123
Epoch 140, training loss: 6.654922008514404
Epoch 150, training loss: 6.581834316253662
Epoch 160, training loss: 6.454199314117432
Epoch 170, training loss: 6.28956413269043
Epoch 180, training loss: 6.243409156799316
Epoch 190, training loss: 6.208642959594727
Epoch 200, training loss: 6.267571449279785
Epoch 210, training loss: 6.253602981567383
Epoch 220, training loss: 6.160395622253418
Epoch 230, training loss: 6.130234718322754
Epoch 240, training loss: 6.063200950622559
Epoch 250, training loss: 6.157761096954346
Epoch 260, training loss: 5.9996819496154785
Epoch 270, training loss: 6.1206278800964355
Epoch 280, training loss: 6.081109523773193
Epoch 290, training loss: 5.944739818572998
Epoch 300, training loss: 5.9185471534729
Epoch 310, training loss: 5.965167999267578
Epoch 320, training loss: 5.8742289543151855
Epoch 330, training loss: 5.852313041687012
Epoch 340, training loss: 5.877079010009766
Epoch 350, training loss: 5.802657127380371
Epoch 360, training loss: 5.811361312866211
Epoch 370, training loss: 5.765059947967529
Epoch 380, training loss: 5.874027729034424
Epoch 390, training loss: 5.707075119018555
Epoch 400, training loss: 5.695939064025879
Epoch 410, training loss: 5.7011871337890625
Epoch 420, training loss: 5.7662787437438965
Epoch 430, training loss: 5.7740044593811035
Epoch 440, training loss: 5.5801262855529785
Epoch 450, training loss: 5.630056858062744
Epoch 460, training loss: 5.512448310852051
Epoch 470, training loss: 5.54786491394043
Epoch 480, training loss: 5.598199844360352
Epoch 490, training loss: 5.567049980163574
random
Accuracy: 0.797
Accuracy: 0.79
Accuracy: 0.786
Accuracy: 0.783
Accuracy: 0.777
Accuracy: 0.77
Accuracy: 0.758
Accuracy: 0.759
Accuracy: 0.758
Accuracy: 0.748
Accuracy: 0.747
Accuracy: 0.737
Accuracy: 0.735
Accuracy: 0.726
Accuracy: 0.718
Accuracy: 0.721
Accuracy: 0.698
Accuracy: 0.702
Accuracy: 0.696
Accuracy: 0.694
Accuracy: 0.696
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.5964937210083
Epoch 10, training loss: 8.587570190429688
Epoch 20, training loss: 8.527173042297363
Epoch 30, training loss: 8.406559944152832
Epoch 40, training loss: 8.179681777954102
Epoch 50, training loss: 7.882376670837402
Epoch 60, training loss: 7.692384243011475
Epoch 70, training loss: 7.414034366607666
Epoch 80, training loss: 7.264345169067383
Epoch 90, training loss: 7.277158737182617
Epoch 100, training loss: 7.173157215118408
Epoch 110, training loss: 6.913956165313721
Epoch 120, training loss: 6.908501625061035
Epoch 130, training loss: 6.90285062789917
Epoch 140, training loss: 6.7387542724609375
Epoch 150, training loss: 6.675361156463623
Epoch 160, training loss: 6.591183662414551
Epoch 170, training loss: 6.538188934326172
Epoch 180, training loss: 6.478850364685059
Epoch 190, training loss: 6.4235310554504395
Epoch 200, training loss: 6.263275146484375
Epoch 210, training loss: 6.289790630340576
Epoch 220, training loss: 6.158496379852295
Epoch 230, training loss: 6.14150333404541
Epoch 240, training loss: 6.1636576652526855
Epoch 250, training loss: 6.1395955085754395
Epoch 260, training loss: 6.011590957641602
Epoch 270, training loss: 5.989829063415527
Epoch 280, training loss: 5.88719367980957
Epoch 290, training loss: 5.970451354980469
Epoch 300, training loss: 5.949984073638916
Epoch 310, training loss: 5.907243251800537
Epoch 320, training loss: 5.9364705085754395
Epoch 330, training loss: 5.709589958190918
Epoch 340, training loss: 5.80398416519165
Epoch 350, training loss: 5.821095943450928
Epoch 360, training loss: 5.756472110748291
Epoch 370, training loss: 5.703758716583252
Epoch 380, training loss: 5.782892227172852
Epoch 390, training loss: 5.647910118103027
Epoch 400, training loss: 5.6219916343688965
Epoch 410, training loss: 5.585975646972656
Epoch 420, training loss: 5.646888256072998
Epoch 430, training loss: 5.595902919769287
Epoch 440, training loss: 5.568704605102539
Epoch 450, training loss: 5.596180438995361
Epoch 460, training loss: 5.550586223602295
Epoch 470, training loss: 5.532536506652832
Epoch 480, training loss: 5.420468330383301
Epoch 490, training loss: 5.463191986083984
random
Accuracy: 0.777
Accuracy: 0.773
Accuracy: 0.777
Accuracy: 0.769
Accuracy: 0.767
Accuracy: 0.754
Accuracy: 0.743
Accuracy: 0.734
Accuracy: 0.727
Accuracy: 0.723
Accuracy: 0.706
Accuracy: 0.709
Accuracy: 0.693
Accuracy: 0.688
Accuracy: 0.688
Accuracy: 0.697
Accuracy: 0.723
Accuracy: 0.717
Accuracy: 0.703
Accuracy: 0.671
Accuracy: 0.681
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.59654712677002
Epoch 10, training loss: 8.582934379577637
Epoch 20, training loss: 8.522974014282227
Epoch 30, training loss: 8.38046646118164
Epoch 40, training loss: 7.978107452392578
Epoch 50, training loss: 7.820248126983643
Epoch 60, training loss: 7.61074161529541
Epoch 70, training loss: 7.215891361236572
Epoch 80, training loss: 7.412237644195557
Epoch 90, training loss: 7.1444807052612305
Epoch 100, training loss: 6.956492900848389
Epoch 110, training loss: 6.809975624084473
Epoch 120, training loss: 6.786924362182617
Epoch 130, training loss: 6.610925674438477
Epoch 140, training loss: 6.6760358810424805
Epoch 150, training loss: 6.400565147399902
Epoch 160, training loss: 6.463315486907959
Epoch 170, training loss: 6.365102767944336
Epoch 180, training loss: 6.404112815856934
Epoch 190, training loss: 6.234746932983398
Epoch 200, training loss: 6.314107418060303
Epoch 210, training loss: 6.065371990203857
Epoch 220, training loss: 5.969349384307861
Epoch 230, training loss: 6.063436031341553
Epoch 240, training loss: 6.019763469696045
Epoch 250, training loss: 5.993597507476807
Epoch 260, training loss: 5.993170261383057
Epoch 270, training loss: 5.949703693389893
Epoch 280, training loss: 5.952242374420166
Epoch 290, training loss: 5.824227809906006
Epoch 300, training loss: 5.786485195159912
Epoch 310, training loss: 5.8095293045043945
Epoch 320, training loss: 5.833250045776367
Epoch 330, training loss: 5.7716240882873535
Epoch 340, training loss: 5.754982948303223
Epoch 350, training loss: 5.696072578430176
Epoch 360, training loss: 5.725851058959961
Epoch 370, training loss: 5.777581691741943
Epoch 380, training loss: 5.563224792480469
Epoch 390, training loss: 5.566211700439453
Epoch 400, training loss: 5.543559551239014
Epoch 410, training loss: 5.5912933349609375
Epoch 420, training loss: 5.533631324768066
Epoch 430, training loss: 5.502078533172607
Epoch 440, training loss: 5.4975152015686035
Epoch 450, training loss: 5.452472686767578
Epoch 460, training loss: 5.52377986907959
Epoch 470, training loss: 5.455446243286133
Epoch 480, training loss: 5.494348049163818
Epoch 490, training loss: 5.5239176750183105
random
Accuracy: 0.789
Accuracy: 0.796
Accuracy: 0.785
Accuracy: 0.777
Accuracy: 0.786
Accuracy: 0.778
Accuracy: 0.774
Accuracy: 0.764
Accuracy: 0.763
Accuracy: 0.765
Accuracy: 0.763
Accuracy: 0.768
Accuracy: 0.75
Accuracy: 0.747
Accuracy: 0.751
Accuracy: 0.742
Accuracy: 0.751
Accuracy: 0.748
Accuracy: 0.742
Accuracy: 0.733
Accuracy: 0.728
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596327781677246
Epoch 10, training loss: 8.581411361694336
Epoch 20, training loss: 8.52941608428955
Epoch 30, training loss: 8.383544921875
Epoch 40, training loss: 8.04765796661377
Epoch 50, training loss: 7.681621551513672
Epoch 60, training loss: 7.364312648773193
Epoch 70, training loss: 7.330348968505859
Epoch 80, training loss: 7.1312174797058105
Epoch 90, training loss: 6.864841938018799
Epoch 100, training loss: 6.982942581176758
Epoch 110, training loss: 6.8035969734191895
Epoch 120, training loss: 6.683260440826416
Epoch 130, training loss: 6.71462869644165
Epoch 140, training loss: 6.560187339782715
Epoch 150, training loss: 6.53256893157959
Epoch 160, training loss: 6.43198823928833
Epoch 170, training loss: 6.431528091430664
Epoch 180, training loss: 6.33588981628418
Epoch 190, training loss: 6.259390354156494
Epoch 200, training loss: 6.331910610198975
Epoch 210, training loss: 6.11953592300415
Epoch 220, training loss: 6.063034534454346
Epoch 230, training loss: 6.125511169433594
Epoch 240, training loss: 6.180656909942627
Epoch 250, training loss: 6.089877605438232
Epoch 260, training loss: 5.926684856414795
Epoch 270, training loss: 5.918956756591797
Epoch 280, training loss: 5.954692363739014
Epoch 290, training loss: 5.858314037322998
Epoch 300, training loss: 5.778129577636719
Epoch 310, training loss: 5.830182075500488
Epoch 320, training loss: 5.759191513061523
Epoch 330, training loss: 5.768312931060791
Epoch 340, training loss: 5.767490863800049
Epoch 350, training loss: 5.728110313415527
Epoch 360, training loss: 5.7316718101501465
Epoch 370, training loss: 5.788655757904053
Epoch 380, training loss: 5.6233906745910645
Epoch 390, training loss: 5.60980749130249
Epoch 400, training loss: 5.6947340965271
Epoch 410, training loss: 5.639490127563477
Epoch 420, training loss: 5.587548732757568
Epoch 430, training loss: 5.635830879211426
Epoch 440, training loss: 5.545909881591797
Epoch 450, training loss: 5.564011096954346
Epoch 460, training loss: 5.500645160675049
Epoch 470, training loss: 5.485022068023682
Epoch 480, training loss: 5.4773759841918945
Epoch 490, training loss: 5.453546047210693
random
Accuracy: 0.771
Accuracy: 0.775
Accuracy: 0.778
Accuracy: 0.772
Accuracy: 0.776
Accuracy: 0.775
Accuracy: 0.767
Accuracy: 0.769
Accuracy: 0.76
Accuracy: 0.757
Accuracy: 0.747
Accuracy: 0.75
Accuracy: 0.746
Accuracy: 0.738
Accuracy: 0.737
Accuracy: 0.739
Accuracy: 0.741
Accuracy: 0.744
Accuracy: 0.728
Accuracy: 0.732
Accuracy: 0.723
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596449851989746
Epoch 10, training loss: 8.579726219177246
Epoch 20, training loss: 8.524937629699707
Epoch 30, training loss: 8.41248893737793
Epoch 40, training loss: 8.02843189239502
Epoch 50, training loss: 7.7844767570495605
Epoch 60, training loss: 7.5212578773498535
Epoch 70, training loss: 7.262619972229004
Epoch 80, training loss: 7.123628616333008
Epoch 90, training loss: 6.944581031799316
Epoch 100, training loss: 6.786985397338867
Epoch 110, training loss: 6.769476890563965
Epoch 120, training loss: 6.581381797790527
Epoch 130, training loss: 6.788175106048584
Epoch 140, training loss: 6.439520835876465
Epoch 150, training loss: 6.445502758026123
Epoch 160, training loss: 6.330536842346191
Epoch 170, training loss: 6.3699445724487305
Epoch 180, training loss: 6.299070358276367
Epoch 190, training loss: 6.328130722045898
Epoch 200, training loss: 6.145798206329346
Epoch 210, training loss: 6.114833354949951
Epoch 220, training loss: 6.111040115356445
Epoch 230, training loss: 5.994365692138672
Epoch 240, training loss: 6.003758907318115
Epoch 250, training loss: 6.130640029907227
Epoch 260, training loss: 5.9810333251953125
Epoch 270, training loss: 5.934664726257324
Epoch 280, training loss: 5.925377368927002
Epoch 290, training loss: 5.855221271514893
Epoch 300, training loss: 5.940401554107666
Epoch 310, training loss: 5.7672858238220215
Epoch 320, training loss: 5.807713508605957
Epoch 330, training loss: 5.690763473510742
Epoch 340, training loss: 5.695656776428223
Epoch 350, training loss: 5.74672269821167
Epoch 360, training loss: 5.743448257446289
Epoch 370, training loss: 5.639336585998535
Epoch 380, training loss: 5.586923122406006
Epoch 390, training loss: 5.692181587219238
Epoch 400, training loss: 5.695342540740967
Epoch 410, training loss: 5.684453964233398
Epoch 420, training loss: 5.541701316833496
Epoch 430, training loss: 5.554952144622803
Epoch 440, training loss: 5.598456859588623
Epoch 450, training loss: 5.57101583480835
Epoch 460, training loss: 5.546574115753174
Epoch 470, training loss: 5.493532657623291
Epoch 480, training loss: 5.443580627441406
Epoch 490, training loss: 5.4034342765808105
random
Accuracy: 0.76
Accuracy: 0.757
Accuracy: 0.761
Accuracy: 0.753
Accuracy: 0.745
Accuracy: 0.742
Accuracy: 0.737
Accuracy: 0.727
Accuracy: 0.733
Accuracy: 0.725
Accuracy: 0.72
Accuracy: 0.714
Accuracy: 0.716
Accuracy: 0.701
Accuracy: 0.705
Accuracy: 0.703
Accuracy: 0.699
Accuracy: 0.697
Accuracy: 0.696
Accuracy: 0.694
Accuracy: 0.69
Beta:0.5 Ptb size:0 Accuracy:0.7788+-0.0131
Beta:0.5 Ptb size:1 Accuracy:0.7782+-0.0137
Beta:0.5 Ptb size:2 Accuracy:0.7774+-0.0090
Beta:0.5 Ptb size:3 Accuracy:0.7708+-0.0101
Beta:0.5 Ptb size:4 Accuracy:0.7702+-0.0140
Beta:0.5 Ptb size:5 Accuracy:0.7638+-0.0137
Beta:0.5 Ptb size:6 Accuracy:0.7558+-0.0140
Beta:0.5 Ptb size:7 Accuracy:0.7506+-0.0169
Beta:0.5 Ptb size:8 Accuracy:0.7482+-0.0151
Beta:0.5 Ptb size:9 Accuracy:0.7436+-0.0169
Beta:0.5 Ptb size:10 Accuracy:0.7366+-0.0206
Beta:0.5 Ptb size:11 Accuracy:0.7356+-0.0221
Beta:0.5 Ptb size:12 Accuracy:0.7280+-0.0211
Beta:0.5 Ptb size:13 Accuracy:0.7200+-0.0222
Beta:0.5 Ptb size:14 Accuracy:0.7198+-0.0224
Beta:0.5 Ptb size:15 Accuracy:0.7204+-0.0182
Beta:0.5 Ptb size:16 Accuracy:0.7224+-0.0215
Beta:0.5 Ptb size:17 Accuracy:0.7216+-0.0210
Beta:0.5 Ptb size:18 Accuracy:0.7130+-0.0187
Beta:0.5 Ptb size:19 Accuracy:0.7048+-0.0241
Beta:0.5 Ptb size:20 Accuracy:0.7036+-0.0186
beta 0.6
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.59646987915039
Epoch 10, training loss: 8.584183692932129
Epoch 20, training loss: 8.483617782592773
Epoch 30, training loss: 8.290106773376465
Epoch 40, training loss: 7.916182994842529
Epoch 50, training loss: 7.413286209106445
Epoch 60, training loss: 7.139876365661621
Epoch 70, training loss: 7.187905311584473
Epoch 80, training loss: 6.937732219696045
Epoch 90, training loss: 6.771399974822998
Epoch 100, training loss: 7.031378269195557
Epoch 110, training loss: 6.668907642364502
Epoch 120, training loss: 6.495833873748779
Epoch 130, training loss: 6.590912342071533
Epoch 140, training loss: 6.588498592376709
Epoch 150, training loss: 6.534537315368652
Epoch 160, training loss: 6.386922836303711
Epoch 170, training loss: 6.2298583984375
Epoch 180, training loss: 6.168830394744873
Epoch 190, training loss: 6.130185604095459
Epoch 200, training loss: 6.216549873352051
Epoch 210, training loss: 6.190047264099121
Epoch 220, training loss: 6.068159580230713
Epoch 230, training loss: 6.0393242835998535
Epoch 240, training loss: 5.995222568511963
Epoch 250, training loss: 6.097786903381348
Epoch 260, training loss: 5.905250072479248
Epoch 270, training loss: 6.044597148895264
Epoch 280, training loss: 6.006806373596191
Epoch 290, training loss: 5.874345779418945
Epoch 300, training loss: 5.8192853927612305
Epoch 310, training loss: 5.867462158203125
Epoch 320, training loss: 5.789467811584473
Epoch 330, training loss: 5.7752909660339355
Epoch 340, training loss: 5.81107234954834
Epoch 350, training loss: 5.705538272857666
Epoch 360, training loss: 5.739259243011475
Epoch 370, training loss: 5.670961380004883
Epoch 380, training loss: 5.774990081787109
Epoch 390, training loss: 5.601573944091797
Epoch 400, training loss: 5.601496696472168
Epoch 410, training loss: 5.628021717071533
Epoch 420, training loss: 5.65219783782959
Epoch 430, training loss: 5.694071292877197
Epoch 440, training loss: 5.4971022605896
Epoch 450, training loss: 5.566351413726807
Epoch 460, training loss: 5.4424214363098145
Epoch 470, training loss: 5.468133449554443
Epoch 480, training loss: 5.530807018280029
Epoch 490, training loss: 5.473531246185303
random
Accuracy: 0.783
Accuracy: 0.784
Accuracy: 0.773
Accuracy: 0.774
Accuracy: 0.768
Accuracy: 0.76
Accuracy: 0.758
Accuracy: 0.749
Accuracy: 0.744
Accuracy: 0.736
Accuracy: 0.727
Accuracy: 0.717
Accuracy: 0.72
Accuracy: 0.708
Accuracy: 0.704
Accuracy: 0.694
Accuracy: 0.706
Accuracy: 0.709
Accuracy: 0.701
Accuracy: 0.681
Accuracy: 0.678
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.596494674682617
Epoch 10, training loss: 8.58506965637207
Epoch 20, training loss: 8.518712997436523
Epoch 30, training loss: 8.40233039855957
Epoch 40, training loss: 8.172574996948242
Epoch 50, training loss: 7.9040961265563965
Epoch 60, training loss: 7.651339530944824
Epoch 70, training loss: 7.346994876861572
Epoch 80, training loss: 7.1976318359375
Epoch 90, training loss: 7.1935930252075195
Epoch 100, training loss: 7.092233657836914
Epoch 110, training loss: 6.827295303344727
Epoch 120, training loss: 6.851210594177246
Epoch 130, training loss: 6.837525367736816
Epoch 140, training loss: 6.651346206665039
Epoch 150, training loss: 6.591192245483398
Epoch 160, training loss: 6.534451961517334
Epoch 170, training loss: 6.464136600494385
Epoch 180, training loss: 6.407186985015869
Epoch 190, training loss: 6.3522844314575195
Epoch 200, training loss: 6.184360504150391
Epoch 210, training loss: 6.1863932609558105
Epoch 220, training loss: 6.080083847045898
Epoch 230, training loss: 6.036101818084717
Epoch 240, training loss: 6.041241645812988
Epoch 250, training loss: 6.063587665557861
Epoch 260, training loss: 5.943933486938477
Epoch 270, training loss: 5.915748119354248
Epoch 280, training loss: 5.805791854858398
Epoch 290, training loss: 5.877811908721924
Epoch 300, training loss: 5.863137722015381
Epoch 310, training loss: 5.824078559875488
Epoch 320, training loss: 5.843971252441406
Epoch 330, training loss: 5.625570297241211
Epoch 340, training loss: 5.735389709472656
Epoch 350, training loss: 5.739326477050781
Epoch 360, training loss: 5.675022602081299
Epoch 370, training loss: 5.626501560211182
Epoch 380, training loss: 5.700913429260254
Epoch 390, training loss: 5.589745044708252
Epoch 400, training loss: 5.529946804046631
Epoch 410, training loss: 5.494936943054199
Epoch 420, training loss: 5.540287017822266
Epoch 430, training loss: 5.523830413818359
Epoch 440, training loss: 5.48966646194458
Epoch 450, training loss: 5.537559509277344
Epoch 460, training loss: 5.4945268630981445
Epoch 470, training loss: 5.4454145431518555
Epoch 480, training loss: 5.345085144042969
Epoch 490, training loss: 5.387883186340332
random
Accuracy: 0.769
Accuracy: 0.774
Accuracy: 0.769
Accuracy: 0.763
Accuracy: 0.758
Accuracy: 0.744
Accuracy: 0.731
Accuracy: 0.734
Accuracy: 0.728
Accuracy: 0.717
Accuracy: 0.701
Accuracy: 0.699
Accuracy: 0.697
Accuracy: 0.687
Accuracy: 0.675
Accuracy: 0.678
Accuracy: 0.729
Accuracy: 0.715
Accuracy: 0.692
Accuracy: 0.656
Accuracy: 0.67
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.59654712677002
Epoch 10, training loss: 8.579935073852539
Epoch 20, training loss: 8.507542610168457
Epoch 30, training loss: 8.406891822814941
Epoch 40, training loss: 7.953700542449951
Epoch 50, training loss: 7.7698655128479
Epoch 60, training loss: 7.567798614501953
Epoch 70, training loss: 7.144470691680908
Epoch 80, training loss: 7.297110080718994
Epoch 90, training loss: 7.066392421722412
Epoch 100, training loss: 6.860421180725098
Epoch 110, training loss: 6.698409557342529
Epoch 120, training loss: 6.686795711517334
Epoch 130, training loss: 6.458887100219727
Epoch 140, training loss: 6.538827419281006
Epoch 150, training loss: 6.278382778167725
Epoch 160, training loss: 6.330207824707031
Epoch 170, training loss: 6.241786479949951
Epoch 180, training loss: 6.273870944976807
Epoch 190, training loss: 6.103917121887207
Epoch 200, training loss: 6.171777725219727
Epoch 210, training loss: 5.974177837371826
Epoch 220, training loss: 5.85083532333374
Epoch 230, training loss: 5.943525791168213
Epoch 240, training loss: 5.884256362915039
Epoch 250, training loss: 5.873452663421631
Epoch 260, training loss: 5.850278377532959
Epoch 270, training loss: 5.822781085968018
Epoch 280, training loss: 5.8572187423706055
Epoch 290, training loss: 5.71842098236084
Epoch 300, training loss: 5.700699329376221
Epoch 310, training loss: 5.688965320587158
Epoch 320, training loss: 5.731729030609131
Epoch 330, training loss: 5.695724964141846
Epoch 340, training loss: 5.6489362716674805
Epoch 350, training loss: 5.586855888366699
Epoch 360, training loss: 5.633077621459961
Epoch 370, training loss: 5.698925495147705
Epoch 380, training loss: 5.502596378326416
Epoch 390, training loss: 5.491376876831055
Epoch 400, training loss: 5.448012351989746
Epoch 410, training loss: 5.519345760345459
Epoch 420, training loss: 5.478508472442627
Epoch 430, training loss: 5.438782215118408
Epoch 440, training loss: 5.421302795410156
Epoch 450, training loss: 5.375275611877441
Epoch 460, training loss: 5.485597610473633
Epoch 470, training loss: 5.387025833129883
Epoch 480, training loss: 5.406402111053467
Epoch 490, training loss: 5.42915678024292
random
Accuracy: 0.793
Accuracy: 0.789
Accuracy: 0.782
Accuracy: 0.771
Accuracy: 0.773
Accuracy: 0.765
Accuracy: 0.753
Accuracy: 0.75
Accuracy: 0.745
Accuracy: 0.745
Accuracy: 0.738
Accuracy: 0.735
Accuracy: 0.718
Accuracy: 0.72
Accuracy: 0.713
Accuracy: 0.734
Accuracy: 0.728
Accuracy: 0.74
Accuracy: 0.699
Accuracy: 0.709
Accuracy: 0.695
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596320152282715
Epoch 10, training loss: 8.577637672424316
Epoch 20, training loss: 8.506924629211426
Epoch 30, training loss: 8.384444236755371
Epoch 40, training loss: 8.050166130065918
Epoch 50, training loss: 7.68602180480957
Epoch 60, training loss: 7.368797779083252
Epoch 70, training loss: 7.30226469039917
Epoch 80, training loss: 7.078540325164795
Epoch 90, training loss: 6.8391218185424805
Epoch 100, training loss: 6.92444372177124
Epoch 110, training loss: 6.760535717010498
Epoch 120, training loss: 6.6249260902404785
Epoch 130, training loss: 6.658488750457764
Epoch 140, training loss: 6.483776092529297
Epoch 150, training loss: 6.4814653396606445
Epoch 160, training loss: 6.352485656738281
Epoch 170, training loss: 6.342334270477295
Epoch 180, training loss: 6.282534599304199
Epoch 190, training loss: 6.1916093826293945
Epoch 200, training loss: 6.250412464141846
Epoch 210, training loss: 6.0611491203308105
Epoch 220, training loss: 6.011967182159424
Epoch 230, training loss: 6.103912353515625
Epoch 240, training loss: 6.093193054199219
Epoch 250, training loss: 6.021302700042725
Epoch 260, training loss: 5.8815083503723145
Epoch 270, training loss: 5.862452983856201
Epoch 280, training loss: 5.890027046203613
Epoch 290, training loss: 5.80340051651001
Epoch 300, training loss: 5.698590278625488
Epoch 310, training loss: 5.7701263427734375
Epoch 320, training loss: 5.7022528648376465
Epoch 330, training loss: 5.721832275390625
Epoch 340, training loss: 5.717393398284912
Epoch 350, training loss: 5.681672096252441
Epoch 360, training loss: 5.668359756469727
Epoch 370, training loss: 5.7103447914123535
Epoch 380, training loss: 5.565173625946045
Epoch 390, training loss: 5.538034439086914
Epoch 400, training loss: 5.612265110015869
Epoch 410, training loss: 5.572573661804199
Epoch 420, training loss: 5.521368980407715
Epoch 430, training loss: 5.568169593811035
Epoch 440, training loss: 5.498575210571289
Epoch 450, training loss: 5.509184837341309
Epoch 460, training loss: 5.4172749519348145
Epoch 470, training loss: 5.426767826080322
Epoch 480, training loss: 5.41538143157959
Epoch 490, training loss: 5.393470764160156
random
Accuracy: 0.778
Accuracy: 0.78
Accuracy: 0.781
Accuracy: 0.78
Accuracy: 0.779
Accuracy: 0.77
Accuracy: 0.774
Accuracy: 0.77
Accuracy: 0.771
Accuracy: 0.772
Accuracy: 0.765
Accuracy: 0.767
Accuracy: 0.757
Accuracy: 0.75
Accuracy: 0.756
Accuracy: 0.749
Accuracy: 0.745
Accuracy: 0.744
Accuracy: 0.738
Accuracy: 0.733
Accuracy: 0.736
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596437454223633
Epoch 10, training loss: 8.577032089233398
Epoch 20, training loss: 8.499556541442871
Epoch 30, training loss: 8.383201599121094
Epoch 40, training loss: 7.9980034828186035
Epoch 50, training loss: 7.780995845794678
Epoch 60, training loss: 7.4587907791137695
Epoch 70, training loss: 7.216041088104248
Epoch 80, training loss: 7.039331912994385
Epoch 90, training loss: 6.882989883422852
Epoch 100, training loss: 6.714296817779541
Epoch 110, training loss: 6.716139793395996
Epoch 120, training loss: 6.5216474533081055
Epoch 130, training loss: 6.7123308181762695
Epoch 140, training loss: 6.362590789794922
Epoch 150, training loss: 6.380162715911865
Epoch 160, training loss: 6.255214691162109
Epoch 170, training loss: 6.29646110534668
Epoch 180, training loss: 6.1841044425964355
Epoch 190, training loss: 6.210216045379639
Epoch 200, training loss: 6.059346675872803
Epoch 210, training loss: 6.027548313140869
Epoch 220, training loss: 5.995896339416504
Epoch 230, training loss: 5.896391868591309
Epoch 240, training loss: 5.919524192810059
Epoch 250, training loss: 6.0302414894104
Epoch 260, training loss: 5.895653247833252
Epoch 270, training loss: 5.857910633087158
Epoch 280, training loss: 5.82307243347168
Epoch 290, training loss: 5.7382307052612305
Epoch 300, training loss: 5.798635959625244
Epoch 310, training loss: 5.68013334274292
Epoch 320, training loss: 5.745228290557861
Epoch 330, training loss: 5.602121353149414
Epoch 340, training loss: 5.572813034057617
Epoch 350, training loss: 5.644458293914795
Epoch 360, training loss: 5.671421051025391
Epoch 370, training loss: 5.545277118682861
Epoch 380, training loss: 5.486776351928711
Epoch 390, training loss: 5.58493185043335
Epoch 400, training loss: 5.588857650756836
Epoch 410, training loss: 5.600587844848633
Epoch 420, training loss: 5.4404754638671875
Epoch 430, training loss: 5.438541412353516
Epoch 440, training loss: 5.473140239715576
Epoch 450, training loss: 5.447361469268799
Epoch 460, training loss: 5.456911563873291
Epoch 470, training loss: 5.392725944519043
Epoch 480, training loss: 5.338959217071533
Epoch 490, training loss: 5.322762966156006
random
Accuracy: 0.77
Accuracy: 0.777
Accuracy: 0.771
Accuracy: 0.761
Accuracy: 0.751
Accuracy: 0.753
Accuracy: 0.748
Accuracy: 0.743
Accuracy: 0.734
Accuracy: 0.718
Accuracy: 0.719
Accuracy: 0.714
Accuracy: 0.706
Accuracy: 0.703
Accuracy: 0.687
Accuracy: 0.695
Accuracy: 0.697
Accuracy: 0.7
Accuracy: 0.692
Accuracy: 0.688
Accuracy: 0.693
Beta:0.6 Ptb size:0 Accuracy:0.7786+-0.0089
Beta:0.6 Ptb size:1 Accuracy:0.7808+-0.0053
Beta:0.6 Ptb size:2 Accuracy:0.7752+-0.0053
Beta:0.6 Ptb size:3 Accuracy:0.7698+-0.0070
Beta:0.6 Ptb size:4 Accuracy:0.7658+-0.0101
Beta:0.6 Ptb size:5 Accuracy:0.7584+-0.0091
Beta:0.6 Ptb size:6 Accuracy:0.7528+-0.0140
Beta:0.6 Ptb size:7 Accuracy:0.7492+-0.0119
Beta:0.6 Ptb size:8 Accuracy:0.7444+-0.0147
Beta:0.6 Ptb size:9 Accuracy:0.7376+-0.0202
Beta:0.6 Ptb size:10 Accuracy:0.7300+-0.0213
Beta:0.6 Ptb size:11 Accuracy:0.7264+-0.0233
Beta:0.6 Ptb size:12 Accuracy:0.7196+-0.0205
Beta:0.6 Ptb size:13 Accuracy:0.7136+-0.0211
Beta:0.6 Ptb size:14 Accuracy:0.7070+-0.0278
Beta:0.6 Ptb size:15 Accuracy:0.7100+-0.0268
Beta:0.6 Ptb size:16 Accuracy:0.7210+-0.0173
Beta:0.6 Ptb size:17 Accuracy:0.7216+-0.0174
Beta:0.6 Ptb size:18 Accuracy:0.7044+-0.0172
Beta:0.6 Ptb size:19 Accuracy:0.6934+-0.0261
Beta:0.6 Ptb size:20 Accuracy:0.6944+-0.0228
beta 0.7
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596465110778809
Epoch 10, training loss: 8.58286190032959
Epoch 20, training loss: 8.472968101501465
Epoch 30, training loss: 8.293073654174805
Epoch 40, training loss: 7.8831467628479
Epoch 50, training loss: 7.37020206451416
Epoch 60, training loss: 7.0810546875
Epoch 70, training loss: 7.129729747772217
Epoch 80, training loss: 6.875118255615234
Epoch 90, training loss: 6.740105152130127
Epoch 100, training loss: 6.969355583190918
Epoch 110, training loss: 6.590687274932861
Epoch 120, training loss: 6.407305717468262
Epoch 130, training loss: 6.513116359710693
Epoch 140, training loss: 6.504168510437012
Epoch 150, training loss: 6.43480110168457
Epoch 160, training loss: 6.288025856018066
Epoch 170, training loss: 6.150554180145264
Epoch 180, training loss: 6.104962348937988
Epoch 190, training loss: 6.061032772064209
Epoch 200, training loss: 6.153714656829834
Epoch 210, training loss: 6.110942840576172
Epoch 220, training loss: 5.979541778564453
Epoch 230, training loss: 5.9522247314453125
Epoch 240, training loss: 5.917366981506348
Epoch 250, training loss: 5.987621307373047
Epoch 260, training loss: 5.831510066986084
Epoch 270, training loss: 5.96142578125
Epoch 280, training loss: 5.919194221496582
Epoch 290, training loss: 5.776975154876709
Epoch 300, training loss: 5.723214626312256
Epoch 310, training loss: 5.749309062957764
Epoch 320, training loss: 5.707424640655518
Epoch 330, training loss: 5.711141586303711
Epoch 340, training loss: 5.7157979011535645
Epoch 350, training loss: 5.627488136291504
Epoch 360, training loss: 5.649659156799316
Epoch 370, training loss: 5.612359523773193
Epoch 380, training loss: 5.6754865646362305
Epoch 390, training loss: 5.535892486572266
Epoch 400, training loss: 5.497408390045166
Epoch 410, training loss: 5.540797233581543
Epoch 420, training loss: 5.5731048583984375
Epoch 430, training loss: 5.620872497558594
Epoch 440, training loss: 5.421503067016602
Epoch 450, training loss: 5.4725823402404785
Epoch 460, training loss: 5.3745856285095215
Epoch 470, training loss: 5.41961145401001
Epoch 480, training loss: 5.469096660614014
Epoch 490, training loss: 5.384585380554199
random
Accuracy: 0.787
Accuracy: 0.781
Accuracy: 0.776
Accuracy: 0.775
Accuracy: 0.764
Accuracy: 0.756
Accuracy: 0.752
Accuracy: 0.744
Accuracy: 0.739
Accuracy: 0.737
Accuracy: 0.72
Accuracy: 0.722
Accuracy: 0.711
Accuracy: 0.717
Accuracy: 0.713
Accuracy: 0.711
Accuracy: 0.705
Accuracy: 0.718
Accuracy: 0.709
Accuracy: 0.697
Accuracy: 0.684
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.596513748168945
Epoch 10, training loss: 8.583197593688965
Epoch 20, training loss: 8.498971939086914
Epoch 30, training loss: 8.3943452835083
Epoch 40, training loss: 8.143588066101074
Epoch 50, training loss: 7.905459880828857
Epoch 60, training loss: 7.664487838745117
Epoch 70, training loss: 7.291474342346191
Epoch 80, training loss: 7.180016040802002
Epoch 90, training loss: 7.176974773406982
Epoch 100, training loss: 7.040070533752441
Epoch 110, training loss: 6.7642645835876465
Epoch 120, training loss: 6.792400360107422
Epoch 130, training loss: 6.752358436584473
Epoch 140, training loss: 6.6065802574157715
Epoch 150, training loss: 6.540111064910889
Epoch 160, training loss: 6.500817775726318
Epoch 170, training loss: 6.384511470794678
Epoch 180, training loss: 6.332862854003906
Epoch 190, training loss: 6.271696090698242
Epoch 200, training loss: 6.117325782775879
Epoch 210, training loss: 6.095190048217773
Epoch 220, training loss: 6.014247417449951
Epoch 230, training loss: 5.981410026550293
Epoch 240, training loss: 5.9758195877075195
Epoch 250, training loss: 5.965154647827148
Epoch 260, training loss: 5.886906147003174
Epoch 270, training loss: 5.832720756530762
Epoch 280, training loss: 5.723639011383057
Epoch 290, training loss: 5.8120341300964355
Epoch 300, training loss: 5.774769306182861
Epoch 310, training loss: 5.718937873840332
Epoch 320, training loss: 5.7654547691345215
Epoch 330, training loss: 5.550207614898682
Epoch 340, training loss: 5.664592266082764
Epoch 350, training loss: 5.689616680145264
Epoch 360, training loss: 5.6073150634765625
Epoch 370, training loss: 5.545760631561279
Epoch 380, training loss: 5.6330060958862305
Epoch 390, training loss: 5.515164852142334
Epoch 400, training loss: 5.468727111816406
Epoch 410, training loss: 5.443054676055908
Epoch 420, training loss: 5.480741500854492
Epoch 430, training loss: 5.442933559417725
Epoch 440, training loss: 5.4413652420043945
Epoch 450, training loss: 5.463442802429199
Epoch 460, training loss: 5.412459850311279
Epoch 470, training loss: 5.369060516357422
Epoch 480, training loss: 5.266727447509766
Epoch 490, training loss: 5.314090728759766
random
Accuracy: 0.76
Accuracy: 0.754
Accuracy: 0.756
Accuracy: 0.746
Accuracy: 0.743
Accuracy: 0.738
Accuracy: 0.729
Accuracy: 0.721
Accuracy: 0.715
Accuracy: 0.702
Accuracy: 0.701
Accuracy: 0.692
Accuracy: 0.683
Accuracy: 0.673
Accuracy: 0.668
Accuracy: 0.671
Accuracy: 0.701
Accuracy: 0.694
Accuracy: 0.684
Accuracy: 0.658
Accuracy: 0.662
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596545219421387
Epoch 10, training loss: 8.577970504760742
Epoch 20, training loss: 8.48486042022705
Epoch 30, training loss: 8.401488304138184
Epoch 40, training loss: 7.955121040344238
Epoch 50, training loss: 7.773975372314453
Epoch 60, training loss: 7.561021327972412
Epoch 70, training loss: 7.112496376037598
Epoch 80, training loss: 7.2515435218811035
Epoch 90, training loss: 6.991823673248291
Epoch 100, training loss: 6.788755893707275
Epoch 110, training loss: 6.612441539764404
Epoch 120, training loss: 6.586298942565918
Epoch 130, training loss: 6.388780117034912
Epoch 140, training loss: 6.440950870513916
Epoch 150, training loss: 6.2301788330078125
Epoch 160, training loss: 6.289736747741699
Epoch 170, training loss: 6.1946330070495605
Epoch 180, training loss: 6.205324649810791
Epoch 190, training loss: 6.045688629150391
Epoch 200, training loss: 6.090902328491211
Epoch 210, training loss: 5.92254114151001
Epoch 220, training loss: 5.799814701080322
Epoch 230, training loss: 5.882833480834961
Epoch 240, training loss: 5.834131240844727
Epoch 250, training loss: 5.7881178855896
Epoch 260, training loss: 5.774239540100098
Epoch 270, training loss: 5.74998140335083
Epoch 280, training loss: 5.775920391082764
Epoch 290, training loss: 5.635851860046387
Epoch 300, training loss: 5.649045467376709
Epoch 310, training loss: 5.6162214279174805
Epoch 320, training loss: 5.691162109375
Epoch 330, training loss: 5.623876094818115
Epoch 340, training loss: 5.55725622177124
Epoch 350, training loss: 5.500821590423584
Epoch 360, training loss: 5.558398246765137
Epoch 370, training loss: 5.625029563903809
Epoch 380, training loss: 5.438188552856445
Epoch 390, training loss: 5.431390285491943
Epoch 400, training loss: 5.417578220367432
Epoch 410, training loss: 5.457708835601807
Epoch 420, training loss: 5.410284519195557
Epoch 430, training loss: 5.3765974044799805
Epoch 440, training loss: 5.343844413757324
Epoch 450, training loss: 5.286353588104248
Epoch 460, training loss: 5.417881488800049
Epoch 470, training loss: 5.327137470245361
Epoch 480, training loss: 5.319540500640869
Epoch 490, training loss: 5.361688613891602
random
Accuracy: 0.815
Accuracy: 0.803
Accuracy: 0.796
Accuracy: 0.786
Accuracy: 0.779
Accuracy: 0.779
Accuracy: 0.769
Accuracy: 0.763
Accuracy: 0.761
Accuracy: 0.754
Accuracy: 0.755
Accuracy: 0.748
Accuracy: 0.726
Accuracy: 0.727
Accuracy: 0.704
Accuracy: 0.714
Accuracy: 0.715
Accuracy: 0.71
Accuracy: 0.687
Accuracy: 0.682
Accuracy: 0.678
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596331596374512
Epoch 10, training loss: 8.57529354095459
Epoch 20, training loss: 8.492022514343262
Epoch 30, training loss: 8.36114501953125
Epoch 40, training loss: 8.008806228637695
Epoch 50, training loss: 7.658637046813965
Epoch 60, training loss: 7.35042142868042
Epoch 70, training loss: 7.239266872406006
Epoch 80, training loss: 7.031446933746338
Epoch 90, training loss: 6.754209041595459
Epoch 100, training loss: 6.851775646209717
Epoch 110, training loss: 6.716900825500488
Epoch 120, training loss: 6.559479236602783
Epoch 130, training loss: 6.637100696563721
Epoch 140, training loss: 6.425025463104248
Epoch 150, training loss: 6.422013282775879
Epoch 160, training loss: 6.254014492034912
Epoch 170, training loss: 6.265721321105957
Epoch 180, training loss: 6.214932441711426
Epoch 190, training loss: 6.1143927574157715
Epoch 200, training loss: 6.158432483673096
Epoch 210, training loss: 5.981457233428955
Epoch 220, training loss: 5.961830139160156
Epoch 230, training loss: 6.0066142082214355
Epoch 240, training loss: 6.04808235168457
Epoch 250, training loss: 5.948970317840576
Epoch 260, training loss: 5.800905227661133
Epoch 270, training loss: 5.785697937011719
Epoch 280, training loss: 5.802215099334717
Epoch 290, training loss: 5.7532477378845215
Epoch 300, training loss: 5.619914531707764
Epoch 310, training loss: 5.680362701416016
Epoch 320, training loss: 5.613157272338867
Epoch 330, training loss: 5.640906810760498
Epoch 340, training loss: 5.655997276306152
Epoch 350, training loss: 5.599756240844727
Epoch 360, training loss: 5.594182014465332
Epoch 370, training loss: 5.657987594604492
Epoch 380, training loss: 5.480981349945068
Epoch 390, training loss: 5.464092254638672
Epoch 400, training loss: 5.507573127746582
Epoch 410, training loss: 5.486657619476318
Epoch 420, training loss: 5.437024116516113
Epoch 430, training loss: 5.492344856262207
Epoch 440, training loss: 5.4142374992370605
Epoch 450, training loss: 5.43168830871582
Epoch 460, training loss: 5.347897052764893
Epoch 470, training loss: 5.347969055175781
Epoch 480, training loss: 5.343952655792236
Epoch 490, training loss: 5.340332508087158
random
Accuracy: 0.795
Accuracy: 0.788
Accuracy: 0.789
Accuracy: 0.778
Accuracy: 0.777
Accuracy: 0.772
Accuracy: 0.771
Accuracy: 0.769
Accuracy: 0.762
Accuracy: 0.765
Accuracy: 0.755
Accuracy: 0.752
Accuracy: 0.748
Accuracy: 0.746
Accuracy: 0.745
Accuracy: 0.744
Accuracy: 0.723
Accuracy: 0.733
Accuracy: 0.722
Accuracy: 0.721
Accuracy: 0.716
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.59643840789795
Epoch 10, training loss: 8.574728965759277
Epoch 20, training loss: 8.486396789550781
Epoch 30, training loss: 8.373372077941895
Epoch 40, training loss: 8.003708839416504
Epoch 50, training loss: 7.731245994567871
Epoch 60, training loss: 7.394379615783691
Epoch 70, training loss: 7.134892463684082
Epoch 80, training loss: 6.984912872314453
Epoch 90, training loss: 6.816971778869629
Epoch 100, training loss: 6.629721164703369
Epoch 110, training loss: 6.627055644989014
Epoch 120, training loss: 6.449329853057861
Epoch 130, training loss: 6.658600330352783
Epoch 140, training loss: 6.2931647300720215
Epoch 150, training loss: 6.310561180114746
Epoch 160, training loss: 6.179323673248291
Epoch 170, training loss: 6.213828086853027
Epoch 180, training loss: 6.102804183959961
Epoch 190, training loss: 6.140812397003174
Epoch 200, training loss: 5.998661041259766
Epoch 210, training loss: 5.924156188964844
Epoch 220, training loss: 5.897100448608398
Epoch 230, training loss: 5.812808513641357
Epoch 240, training loss: 5.839928150177002
Epoch 250, training loss: 5.9124555587768555
Epoch 260, training loss: 5.800685405731201
Epoch 270, training loss: 5.779791355133057
Epoch 280, training loss: 5.720052719116211
Epoch 290, training loss: 5.65935754776001
Epoch 300, training loss: 5.709000110626221
Epoch 310, training loss: 5.605344772338867
Epoch 320, training loss: 5.674720764160156
Epoch 330, training loss: 5.526987552642822
Epoch 340, training loss: 5.4953203201293945
Epoch 350, training loss: 5.583872318267822
Epoch 360, training loss: 5.600953578948975
Epoch 370, training loss: 5.471426486968994
Epoch 380, training loss: 5.394179344177246
Epoch 390, training loss: 5.505115985870361
Epoch 400, training loss: 5.505008697509766
Epoch 410, training loss: 5.5346150398254395
Epoch 420, training loss: 5.357999324798584
Epoch 430, training loss: 5.357317924499512
Epoch 440, training loss: 5.402276515960693
Epoch 450, training loss: 5.358527183532715
Epoch 460, training loss: 5.413951873779297
Epoch 470, training loss: 5.345315933227539
Epoch 480, training loss: 5.260006904602051
Epoch 490, training loss: 5.2733988761901855
random
Accuracy: 0.781
Accuracy: 0.776
Accuracy: 0.768
Accuracy: 0.768
Accuracy: 0.761
Accuracy: 0.751
Accuracy: 0.75
Accuracy: 0.743
Accuracy: 0.736
Accuracy: 0.731
Accuracy: 0.722
Accuracy: 0.719
Accuracy: 0.712
Accuracy: 0.713
Accuracy: 0.704
Accuracy: 0.709
Accuracy: 0.708
Accuracy: 0.702
Accuracy: 0.704
Accuracy: 0.682
Accuracy: 0.688
Beta:0.7 Ptb size:0 Accuracy:0.7876+-0.0180
Beta:0.7 Ptb size:1 Accuracy:0.7804+-0.0160
Beta:0.7 Ptb size:2 Accuracy:0.7770+-0.0143
Beta:0.7 Ptb size:3 Accuracy:0.7706+-0.0136
Beta:0.7 Ptb size:4 Accuracy:0.7648+-0.0130
Beta:0.7 Ptb size:5 Accuracy:0.7592+-0.0147
Beta:0.7 Ptb size:6 Accuracy:0.7542+-0.0152
Beta:0.7 Ptb size:7 Accuracy:0.7480+-0.0169
Beta:0.7 Ptb size:8 Accuracy:0.7426+-0.0175
Beta:0.7 Ptb size:9 Accuracy:0.7378+-0.0216
Beta:0.7 Ptb size:10 Accuracy:0.7306+-0.0212
Beta:0.7 Ptb size:11 Accuracy:0.7266+-0.0218
Beta:0.7 Ptb size:12 Accuracy:0.7160+-0.0212
Beta:0.7 Ptb size:13 Accuracy:0.7152+-0.0240
Beta:0.7 Ptb size:14 Accuracy:0.7068+-0.0246
Beta:0.7 Ptb size:15 Accuracy:0.7098+-0.0232
Beta:0.7 Ptb size:16 Accuracy:0.7104+-0.0078
Beta:0.7 Ptb size:17 Accuracy:0.7114+-0.0134
Beta:0.7 Ptb size:18 Accuracy:0.7012+-0.0141
Beta:0.7 Ptb size:19 Accuracy:0.6880+-0.0207
Beta:0.7 Ptb size:20 Accuracy:0.6856+-0.0176
beta 0.8
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.596476554870605
Epoch 10, training loss: 8.581368446350098
Epoch 20, training loss: 8.459004402160645
Epoch 30, training loss: 8.284424781799316
Epoch 40, training loss: 7.840019702911377
Epoch 50, training loss: 7.32870626449585
Epoch 60, training loss: 7.066607475280762
Epoch 70, training loss: 7.09719181060791
Epoch 80, training loss: 6.818709850311279
Epoch 90, training loss: 6.642902374267578
Epoch 100, training loss: 6.899787425994873
Epoch 110, training loss: 6.525334358215332
Epoch 120, training loss: 6.364263534545898
Epoch 130, training loss: 6.437307834625244
Epoch 140, training loss: 6.445044040679932
Epoch 150, training loss: 6.359715938568115
Epoch 160, training loss: 6.226896286010742
Epoch 170, training loss: 6.0995917320251465
Epoch 180, training loss: 6.054085731506348
Epoch 190, training loss: 5.967628479003906
Epoch 200, training loss: 6.113468647003174
Epoch 210, training loss: 6.073012828826904
Epoch 220, training loss: 5.906152725219727
Epoch 230, training loss: 5.895586967468262
Epoch 240, training loss: 5.829242706298828
Epoch 250, training loss: 5.884021282196045
Epoch 260, training loss: 5.76991081237793
Epoch 270, training loss: 5.885006904602051
Epoch 280, training loss: 5.848793029785156
Epoch 290, training loss: 5.69574499130249
Epoch 300, training loss: 5.633115291595459
Epoch 310, training loss: 5.678999900817871
Epoch 320, training loss: 5.615457057952881
Epoch 330, training loss: 5.634133815765381
Epoch 340, training loss: 5.620542049407959
Epoch 350, training loss: 5.547590255737305
Epoch 360, training loss: 5.547128677368164
Epoch 370, training loss: 5.5255303382873535
Epoch 380, training loss: 5.58504056930542
Epoch 390, training loss: 5.462806701660156
Epoch 400, training loss: 5.432658672332764
Epoch 410, training loss: 5.450090408325195
Epoch 420, training loss: 5.491795539855957
Epoch 430, training loss: 5.533242225646973
Epoch 440, training loss: 5.339492321014404
Epoch 450, training loss: 5.394579887390137
Epoch 460, training loss: 5.284564018249512
Epoch 470, training loss: 5.325440406799316
Epoch 480, training loss: 5.379289627075195
Epoch 490, training loss: 5.300482749938965
random
Accuracy: 0.769
Accuracy: 0.768
Accuracy: 0.772
Accuracy: 0.766
Accuracy: 0.755
Accuracy: 0.744
Accuracy: 0.744
Accuracy: 0.739
Accuracy: 0.737
Accuracy: 0.725
Accuracy: 0.718
Accuracy: 0.709
Accuracy: 0.718
Accuracy: 0.706
Accuracy: 0.706
Accuracy: 0.702
Accuracy: 0.695
Accuracy: 0.7
Accuracy: 0.702
Accuracy: 0.683
Accuracy: 0.674
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.596539497375488
Epoch 10, training loss: 8.581825256347656
Epoch 20, training loss: 8.486451148986816
Epoch 30, training loss: 8.389394760131836
Epoch 40, training loss: 8.139827728271484
Epoch 50, training loss: 7.921328067779541
Epoch 60, training loss: 7.630880832672119
Epoch 70, training loss: 7.272472381591797
Epoch 80, training loss: 7.100144386291504
Epoch 90, training loss: 7.112454414367676
Epoch 100, training loss: 6.9810991287231445
Epoch 110, training loss: 6.692287445068359
Epoch 120, training loss: 6.702462673187256
Epoch 130, training loss: 6.6648125648498535
Epoch 140, training loss: 6.528243064880371
Epoch 150, training loss: 6.452165603637695
Epoch 160, training loss: 6.4309306144714355
Epoch 170, training loss: 6.29984188079834
Epoch 180, training loss: 6.263540267944336
Epoch 190, training loss: 6.193845272064209
Epoch 200, training loss: 6.045140266418457
Epoch 210, training loss: 6.02269172668457
Epoch 220, training loss: 5.948406219482422
Epoch 230, training loss: 5.899908065795898
Epoch 240, training loss: 5.902895450592041
Epoch 250, training loss: 5.87741756439209
Epoch 260, training loss: 5.812201023101807
Epoch 270, training loss: 5.746453285217285
Epoch 280, training loss: 5.65211296081543
Epoch 290, training loss: 5.732439994812012
Epoch 300, training loss: 5.695320129394531
Epoch 310, training loss: 5.659542560577393
Epoch 320, training loss: 5.682120323181152
Epoch 330, training loss: 5.486222743988037
Epoch 340, training loss: 5.603489398956299
Epoch 350, training loss: 5.637590408325195
Epoch 360, training loss: 5.527413368225098
Epoch 370, training loss: 5.474058151245117
Epoch 380, training loss: 5.559223175048828
Epoch 390, training loss: 5.438591480255127
Epoch 400, training loss: 5.401157855987549
Epoch 410, training loss: 5.374385833740234
Epoch 420, training loss: 5.421662330627441
Epoch 430, training loss: 5.359476566314697
Epoch 440, training loss: 5.365395545959473
Epoch 450, training loss: 5.399063587188721
Epoch 460, training loss: 5.335280418395996
Epoch 470, training loss: 5.3309454917907715
Epoch 480, training loss: 5.2142181396484375
Epoch 490, training loss: 5.256587505340576
random
Accuracy: 0.744
Accuracy: 0.747
Accuracy: 0.738
Accuracy: 0.726
Accuracy: 0.73
Accuracy: 0.724
Accuracy: 0.73
Accuracy: 0.722
Accuracy: 0.718
Accuracy: 0.704
Accuracy: 0.691
Accuracy: 0.687
Accuracy: 0.697
Accuracy: 0.682
Accuracy: 0.687
Accuracy: 0.684
Accuracy: 0.705
Accuracy: 0.706
Accuracy: 0.695
Accuracy: 0.675
Accuracy: 0.682
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596565246582031
Epoch 10, training loss: 8.57654857635498
Epoch 20, training loss: 8.47319221496582
Epoch 30, training loss: 8.364232063293457
Epoch 40, training loss: 7.930552959442139
Epoch 50, training loss: 7.7555317878723145
Epoch 60, training loss: 7.559812545776367
Epoch 70, training loss: 7.089427947998047
Epoch 80, training loss: 7.236982822418213
Epoch 90, training loss: 6.959545135498047
Epoch 100, training loss: 6.761493682861328
Epoch 110, training loss: 6.582387924194336
Epoch 120, training loss: 6.550393581390381
Epoch 130, training loss: 6.362800121307373
Epoch 140, training loss: 6.380441665649414
Epoch 150, training loss: 6.172059535980225
Epoch 160, training loss: 6.251038551330566
Epoch 170, training loss: 6.138716697692871
Epoch 180, training loss: 6.122596740722656
Epoch 190, training loss: 5.998465538024902
Epoch 200, training loss: 6.021345138549805
Epoch 210, training loss: 5.869241714477539
Epoch 220, training loss: 5.734399795532227
Epoch 230, training loss: 5.798455238342285
Epoch 240, training loss: 5.7700300216674805
Epoch 250, training loss: 5.741803169250488
Epoch 260, training loss: 5.7000250816345215
Epoch 270, training loss: 5.662099361419678
Epoch 280, training loss: 5.703132629394531
Epoch 290, training loss: 5.570046901702881
Epoch 300, training loss: 5.575671672821045
Epoch 310, training loss: 5.518004894256592
Epoch 320, training loss: 5.610542297363281
Epoch 330, training loss: 5.551980018615723
Epoch 340, training loss: 5.481105327606201
Epoch 350, training loss: 5.415170669555664
Epoch 360, training loss: 5.485938549041748
Epoch 370, training loss: 5.5532660484313965
Epoch 380, training loss: 5.3744120597839355
Epoch 390, training loss: 5.365338325500488
Epoch 400, training loss: 5.339832305908203
Epoch 410, training loss: 5.375217914581299
Epoch 420, training loss: 5.331187725067139
Epoch 430, training loss: 5.3049092292785645
Epoch 440, training loss: 5.282517910003662
Epoch 450, training loss: 5.245550632476807
Epoch 460, training loss: 5.312000751495361
Epoch 470, training loss: 5.270590305328369
Epoch 480, training loss: 5.240412712097168
Epoch 490, training loss: 5.31240177154541
random
Accuracy: 0.792
Accuracy: 0.785
Accuracy: 0.778
Accuracy: 0.767
Accuracy: 0.752
Accuracy: 0.741
Accuracy: 0.728
Accuracy: 0.721
Accuracy: 0.716
Accuracy: 0.697
Accuracy: 0.693
Accuracy: 0.676
Accuracy: 0.672
Accuracy: 0.654
Accuracy: 0.656
Accuracy: 0.654
Accuracy: 0.66
Accuracy: 0.653
Accuracy: 0.631
Accuracy: 0.627
Accuracy: 0.634
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.59631061553955
Epoch 10, training loss: 8.573028564453125
Epoch 20, training loss: 8.478710174560547
Epoch 30, training loss: 8.343323707580566
Epoch 40, training loss: 7.957024097442627
Epoch 50, training loss: 7.631045341491699
Epoch 60, training loss: 7.302852630615234
Epoch 70, training loss: 7.217973709106445
Epoch 80, training loss: 6.98438835144043
Epoch 90, training loss: 6.742040157318115
Epoch 100, training loss: 6.807501792907715
Epoch 110, training loss: 6.6701459884643555
Epoch 120, training loss: 6.498556137084961
Epoch 130, training loss: 6.587384223937988
Epoch 140, training loss: 6.373178958892822
Epoch 150, training loss: 6.353304862976074
Epoch 160, training loss: 6.186054706573486
Epoch 170, training loss: 6.196784973144531
Epoch 180, training loss: 6.131073951721191
Epoch 190, training loss: 6.034522533416748
Epoch 200, training loss: 6.0579071044921875
Epoch 210, training loss: 5.872433662414551
Epoch 220, training loss: 5.869640827178955
Epoch 230, training loss: 5.918220520019531
Epoch 240, training loss: 5.9773759841918945
Epoch 250, training loss: 5.860846996307373
Epoch 260, training loss: 5.748439311981201
Epoch 270, training loss: 5.742465019226074
Epoch 280, training loss: 5.698570728302002
Epoch 290, training loss: 5.656235694885254
Epoch 300, training loss: 5.544035911560059
Epoch 310, training loss: 5.595361232757568
Epoch 320, training loss: 5.550921440124512
Epoch 330, training loss: 5.566018104553223
Epoch 340, training loss: 5.5793776512146
Epoch 350, training loss: 5.523197174072266
Epoch 360, training loss: 5.526346683502197
Epoch 370, training loss: 5.555056571960449
Epoch 380, training loss: 5.41206693649292
Epoch 390, training loss: 5.413491725921631
Epoch 400, training loss: 5.4339470863342285
Epoch 410, training loss: 5.43423318862915
Epoch 420, training loss: 5.363413333892822
Epoch 430, training loss: 5.407463550567627
Epoch 440, training loss: 5.328042030334473
Epoch 450, training loss: 5.35249137878418
Epoch 460, training loss: 5.2776970863342285
Epoch 470, training loss: 5.296067237854004
Epoch 480, training loss: 5.2713942527771
Epoch 490, training loss: 5.288686752319336
random
Accuracy: 0.786
Accuracy: 0.783
Accuracy: 0.771
Accuracy: 0.769
Accuracy: 0.768
Accuracy: 0.755
Accuracy: 0.753
Accuracy: 0.749
Accuracy: 0.744
Accuracy: 0.736
Accuracy: 0.72
Accuracy: 0.721
Accuracy: 0.716
Accuracy: 0.706
Accuracy: 0.698
Accuracy: 0.698
Accuracy: 0.676
Accuracy: 0.67
Accuracy: 0.679
Accuracy: 0.665
Accuracy: 0.677
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596441268920898
Epoch 10, training loss: 8.572811126708984
Epoch 20, training loss: 8.47116756439209
Epoch 30, training loss: 8.353803634643555
Epoch 40, training loss: 8.036538124084473
Epoch 50, training loss: 7.704380035400391
Epoch 60, training loss: 7.368166923522949
Epoch 70, training loss: 7.088908672332764
Epoch 80, training loss: 6.9382195472717285
Epoch 90, training loss: 6.747424125671387
Epoch 100, training loss: 6.576037406921387
Epoch 110, training loss: 6.548064708709717
Epoch 120, training loss: 6.385049819946289
Epoch 130, training loss: 6.610125541687012
Epoch 140, training loss: 6.243206977844238
Epoch 150, training loss: 6.227841854095459
Epoch 160, training loss: 6.105126857757568
Epoch 170, training loss: 6.133058547973633
Epoch 180, training loss: 6.053521156311035
Epoch 190, training loss: 6.092455863952637
Epoch 200, training loss: 5.952450752258301
Epoch 210, training loss: 5.870203495025635
Epoch 220, training loss: 5.838284015655518
Epoch 230, training loss: 5.751538276672363
Epoch 240, training loss: 5.775387763977051
Epoch 250, training loss: 5.819250583648682
Epoch 260, training loss: 5.751062870025635
Epoch 270, training loss: 5.7376484870910645
Epoch 280, training loss: 5.641100883483887
Epoch 290, training loss: 5.5883002281188965
Epoch 300, training loss: 5.645701885223389
Epoch 310, training loss: 5.533690452575684
Epoch 320, training loss: 5.601685523986816
Epoch 330, training loss: 5.4692063331604
Epoch 340, training loss: 5.460326671600342
Epoch 350, training loss: 5.531492710113525
Epoch 360, training loss: 5.522489547729492
Epoch 370, training loss: 5.401792526245117
Epoch 380, training loss: 5.350255012512207
Epoch 390, training loss: 5.470447540283203
Epoch 400, training loss: 5.414259433746338
Epoch 410, training loss: 5.489810466766357
Epoch 420, training loss: 5.324187755584717
Epoch 430, training loss: 5.299741268157959
Epoch 440, training loss: 5.344080924987793
Epoch 450, training loss: 5.3119611740112305
Epoch 460, training loss: 5.3520612716674805
Epoch 470, training loss: 5.304337024688721
Epoch 480, training loss: 5.1904215812683105
Epoch 490, training loss: 5.241143226623535
random
Accuracy: 0.774
Accuracy: 0.77
Accuracy: 0.759
Accuracy: 0.762
Accuracy: 0.756
Accuracy: 0.749
Accuracy: 0.748
Accuracy: 0.739
Accuracy: 0.735
Accuracy: 0.728
Accuracy: 0.715
Accuracy: 0.712
Accuracy: 0.711
Accuracy: 0.705
Accuracy: 0.704
Accuracy: 0.705
Accuracy: 0.717
Accuracy: 0.708
Accuracy: 0.695
Accuracy: 0.697
Accuracy: 0.689
Beta:0.8 Ptb size:0 Accuracy:0.7730+-0.0167
Beta:0.8 Ptb size:1 Accuracy:0.7706+-0.0136
Beta:0.8 Ptb size:2 Accuracy:0.7636+-0.0142
Beta:0.8 Ptb size:3 Accuracy:0.7580+-0.0162
Beta:0.8 Ptb size:4 Accuracy:0.7522+-0.0124
Beta:0.8 Ptb size:5 Accuracy:0.7426+-0.0104
Beta:0.8 Ptb size:6 Accuracy:0.7406+-0.0099
Beta:0.8 Ptb size:7 Accuracy:0.7340+-0.0108
Beta:0.8 Ptb size:8 Accuracy:0.7300+-0.0110
Beta:0.8 Ptb size:9 Accuracy:0.7180+-0.0149
Beta:0.8 Ptb size:10 Accuracy:0.7074+-0.0127
Beta:0.8 Ptb size:11 Accuracy:0.7010+-0.0168
Beta:0.8 Ptb size:12 Accuracy:0.7028+-0.0171
Beta:0.8 Ptb size:13 Accuracy:0.6906+-0.0205
Beta:0.8 Ptb size:14 Accuracy:0.6902+-0.0183
Beta:0.8 Ptb size:15 Accuracy:0.6886+-0.0187
Beta:0.8 Ptb size:16 Accuracy:0.6906+-0.0204
Beta:0.8 Ptb size:17 Accuracy:0.6874+-0.0220
Beta:0.8 Ptb size:18 Accuracy:0.6804+-0.0258
Beta:0.8 Ptb size:19 Accuracy:0.6694+-0.0236
Beta:0.8 Ptb size:20 Accuracy:0.6712+-0.0193
beta 0.9
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.5964994430542
Epoch 10, training loss: 8.580233573913574
Epoch 20, training loss: 8.445606231689453
Epoch 30, training loss: 8.28371524810791
Epoch 40, training loss: 7.795506477355957
Epoch 50, training loss: 7.29937744140625
Epoch 60, training loss: 7.028787612915039
Epoch 70, training loss: 7.095539093017578
Epoch 80, training loss: 6.745785713195801
Epoch 90, training loss: 6.60764741897583
Epoch 100, training loss: 6.8790459632873535
Epoch 110, training loss: 6.47222900390625
Epoch 120, training loss: 6.302685737609863
Epoch 130, training loss: 6.3617753982543945
Epoch 140, training loss: 6.361761569976807
Epoch 150, training loss: 6.312013626098633
Epoch 160, training loss: 6.141445636749268
Epoch 170, training loss: 6.050271987915039
Epoch 180, training loss: 6.000556468963623
Epoch 190, training loss: 5.910889625549316
Epoch 200, training loss: 6.055820941925049
Epoch 210, training loss: 6.013408660888672
Epoch 220, training loss: 5.821589469909668
Epoch 230, training loss: 5.834910869598389
Epoch 240, training loss: 5.769246578216553
Epoch 250, training loss: 5.844807147979736
Epoch 260, training loss: 5.7196736335754395
Epoch 270, training loss: 5.813639163970947
Epoch 280, training loss: 5.787516117095947
Epoch 290, training loss: 5.632699489593506
Epoch 300, training loss: 5.574202060699463
Epoch 310, training loss: 5.604464530944824
Epoch 320, training loss: 5.550882339477539
Epoch 330, training loss: 5.569736003875732
Epoch 340, training loss: 5.550954341888428
Epoch 350, training loss: 5.469843864440918
Epoch 360, training loss: 5.505878448486328
Epoch 370, training loss: 5.477034568786621
Epoch 380, training loss: 5.522853851318359
Epoch 390, training loss: 5.404462814331055
Epoch 400, training loss: 5.355351448059082
Epoch 410, training loss: 5.400693893432617
Epoch 420, training loss: 5.428289413452148
Epoch 430, training loss: 5.453283786773682
Epoch 440, training loss: 5.283419132232666
Epoch 450, training loss: 5.360025405883789
Epoch 460, training loss: 5.228490829467773
Epoch 470, training loss: 5.273422718048096
Epoch 480, training loss: 5.311179161071777
Epoch 490, training loss: 5.24604606628418
random
Accuracy: 0.776
Accuracy: 0.784
Accuracy: 0.779
Accuracy: 0.781
Accuracy: 0.767
Accuracy: 0.76
Accuracy: 0.759
Accuracy: 0.757
Accuracy: 0.755
Accuracy: 0.752
Accuracy: 0.731
Accuracy: 0.733
Accuracy: 0.737
Accuracy: 0.722
Accuracy: 0.725
Accuracy: 0.718
Accuracy: 0.693
Accuracy: 0.701
Accuracy: 0.709
Accuracy: 0.713
Accuracy: 0.686
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.596555709838867
Epoch 10, training loss: 8.580765724182129
Epoch 20, training loss: 8.476387977600098
Epoch 30, training loss: 8.385246276855469
Epoch 40, training loss: 8.13570499420166
Epoch 50, training loss: 7.922859191894531
Epoch 60, training loss: 7.616909027099609
Epoch 70, training loss: 7.244178771972656
Epoch 80, training loss: 7.099249362945557
Epoch 90, training loss: 7.1041154861450195
Epoch 100, training loss: 6.947969913482666
Epoch 110, training loss: 6.6674370765686035
Epoch 120, training loss: 6.670170783996582
Epoch 130, training loss: 6.619914531707764
Epoch 140, training loss: 6.476529121398926
Epoch 150, training loss: 6.40308141708374
Epoch 160, training loss: 6.404808044433594
Epoch 170, training loss: 6.25792932510376
Epoch 180, training loss: 6.235426425933838
Epoch 190, training loss: 6.131377220153809
Epoch 200, training loss: 5.9842095375061035
Epoch 210, training loss: 6.011268138885498
Epoch 220, training loss: 5.907144069671631
Epoch 230, training loss: 5.898733139038086
Epoch 240, training loss: 5.86445951461792
Epoch 250, training loss: 5.8302507400512695
Epoch 260, training loss: 5.785340309143066
Epoch 270, training loss: 5.739941596984863
Epoch 280, training loss: 5.631937503814697
Epoch 290, training loss: 5.6967878341674805
Epoch 300, training loss: 5.657689094543457
Epoch 310, training loss: 5.625792503356934
Epoch 320, training loss: 5.662118434906006
Epoch 330, training loss: 5.483875751495361
Epoch 340, training loss: 5.556280612945557
Epoch 350, training loss: 5.593276023864746
Epoch 360, training loss: 5.493738174438477
Epoch 370, training loss: 5.451010227203369
Epoch 380, training loss: 5.535501480102539
Epoch 390, training loss: 5.400392055511475
Epoch 400, training loss: 5.353158473968506
Epoch 410, training loss: 5.347770690917969
Epoch 420, training loss: 5.375461101531982
Epoch 430, training loss: 5.323597431182861
Epoch 440, training loss: 5.355919361114502
Epoch 450, training loss: 5.367920875549316
Epoch 460, training loss: 5.30682897567749
Epoch 470, training loss: 5.303205966949463
Epoch 480, training loss: 5.1847686767578125
Epoch 490, training loss: 5.2199249267578125
random
Accuracy: 0.746
Accuracy: 0.74
Accuracy: 0.739
Accuracy: 0.728
Accuracy: 0.729
Accuracy: 0.715
Accuracy: 0.718
Accuracy: 0.696
Accuracy: 0.692
Accuracy: 0.692
Accuracy: 0.681
Accuracy: 0.674
Accuracy: 0.671
Accuracy: 0.659
Accuracy: 0.661
Accuracy: 0.647
Accuracy: 0.668
Accuracy: 0.665
Accuracy: 0.664
Accuracy: 0.635
Accuracy: 0.634
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.596578598022461
Epoch 10, training loss: 8.575615882873535
Epoch 20, training loss: 8.463202476501465
Epoch 30, training loss: 8.337069511413574
Epoch 40, training loss: 7.916318416595459
Epoch 50, training loss: 7.771720886230469
Epoch 60, training loss: 7.550224304199219
Epoch 70, training loss: 7.084961414337158
Epoch 80, training loss: 7.235774040222168
Epoch 90, training loss: 6.937378883361816
Epoch 100, training loss: 6.765928268432617
Epoch 110, training loss: 6.572054386138916
Epoch 120, training loss: 6.556685924530029
Epoch 130, training loss: 6.333417892456055
Epoch 140, training loss: 6.335989475250244
Epoch 150, training loss: 6.130654335021973
Epoch 160, training loss: 6.211315155029297
Epoch 170, training loss: 6.1134843826293945
Epoch 180, training loss: 6.059515476226807
Epoch 190, training loss: 5.974026679992676
Epoch 200, training loss: 5.971220970153809
Epoch 210, training loss: 5.834323406219482
Epoch 220, training loss: 5.68724250793457
Epoch 230, training loss: 5.747334957122803
Epoch 240, training loss: 5.715528964996338
Epoch 250, training loss: 5.6955718994140625
Epoch 260, training loss: 5.650435924530029
Epoch 270, training loss: 5.602336406707764
Epoch 280, training loss: 5.664669513702393
Epoch 290, training loss: 5.529056549072266
Epoch 300, training loss: 5.5182576179504395
Epoch 310, training loss: 5.476895809173584
Epoch 320, training loss: 5.536654949188232
Epoch 330, training loss: 5.4937357902526855
Epoch 340, training loss: 5.456820011138916
Epoch 350, training loss: 5.375482559204102
Epoch 360, training loss: 5.433077812194824
Epoch 370, training loss: 5.5117998123168945
Epoch 380, training loss: 5.331594467163086
Epoch 390, training loss: 5.332337856292725
Epoch 400, training loss: 5.288857936859131
Epoch 410, training loss: 5.324400424957275
Epoch 420, training loss: 5.291420936584473
Epoch 430, training loss: 5.256406784057617
Epoch 440, training loss: 5.25054407119751
Epoch 450, training loss: 5.211667060852051
Epoch 460, training loss: 5.267492771148682
Epoch 470, training loss: 5.239656448364258
Epoch 480, training loss: 5.204168319702148
Epoch 490, training loss: 5.247849941253662
random
Accuracy: 0.804
Accuracy: 0.793
Accuracy: 0.787
Accuracy: 0.786
Accuracy: 0.78
Accuracy: 0.773
Accuracy: 0.768
Accuracy: 0.762
Accuracy: 0.743
Accuracy: 0.736
Accuracy: 0.735
Accuracy: 0.721
Accuracy: 0.704
Accuracy: 0.703
Accuracy: 0.697
Accuracy: 0.691
Accuracy: 0.672
Accuracy: 0.664
Accuracy: 0.67
Accuracy: 0.676
Accuracy: 0.653
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.596338272094727
Epoch 10, training loss: 8.57187557220459
Epoch 20, training loss: 8.468086242675781
Epoch 30, training loss: 8.324993133544922
Epoch 40, training loss: 7.905468940734863
Epoch 50, training loss: 7.622080326080322
Epoch 60, training loss: 7.311069011688232
Epoch 70, training loss: 7.184904098510742
Epoch 80, training loss: 6.950868606567383
Epoch 90, training loss: 6.712180137634277
Epoch 100, training loss: 6.775048732757568
Epoch 110, training loss: 6.656487941741943
Epoch 120, training loss: 6.470393657684326
Epoch 130, training loss: 6.560774803161621
Epoch 140, training loss: 6.315979957580566
Epoch 150, training loss: 6.2870774269104
Epoch 160, training loss: 6.132694244384766
Epoch 170, training loss: 6.143388748168945
Epoch 180, training loss: 6.095402240753174
Epoch 190, training loss: 5.979702472686768
Epoch 200, training loss: 6.004243850708008
Epoch 210, training loss: 5.845546722412109
Epoch 220, training loss: 5.862161636352539
Epoch 230, training loss: 5.829085350036621
Epoch 240, training loss: 5.917383193969727
Epoch 250, training loss: 5.823669910430908
Epoch 260, training loss: 5.691262722015381
Epoch 270, training loss: 5.699124336242676
Epoch 280, training loss: 5.650627613067627
Epoch 290, training loss: 5.594078063964844
Epoch 300, training loss: 5.50112771987915
Epoch 310, training loss: 5.52705717086792
Epoch 320, training loss: 5.517390251159668
Epoch 330, training loss: 5.493701934814453
Epoch 340, training loss: 5.524876117706299
Epoch 350, training loss: 5.482782363891602
Epoch 360, training loss: 5.452408313751221
Epoch 370, training loss: 5.487288475036621
Epoch 380, training loss: 5.3431196212768555
Epoch 390, training loss: 5.3664631843566895
Epoch 400, training loss: 5.362949371337891
Epoch 410, training loss: 5.366261959075928
Epoch 420, training loss: 5.280360698699951
Epoch 430, training loss: 5.354259490966797
Epoch 440, training loss: 5.2739081382751465
Epoch 450, training loss: 5.271422863006592
Epoch 460, training loss: 5.214210510253906
Epoch 470, training loss: 5.224146842956543
Epoch 480, training loss: 5.210449695587158
Epoch 490, training loss: 5.230138301849365
random
Accuracy: 0.791
Accuracy: 0.792
Accuracy: 0.786
Accuracy: 0.782
Accuracy: 0.768
Accuracy: 0.752
Accuracy: 0.752
Accuracy: 0.743
Accuracy: 0.735
Accuracy: 0.728
Accuracy: 0.718
Accuracy: 0.716
Accuracy: 0.699
Accuracy: 0.69
Accuracy: 0.678
Accuracy: 0.677
Accuracy: 0.636
Accuracy: 0.635
Accuracy: 0.632
Accuracy: 0.622
Accuracy: 0.635
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.596458435058594
Epoch 10, training loss: 8.571884155273438
Epoch 20, training loss: 8.45712947845459
Epoch 30, training loss: 8.346458435058594
Epoch 40, training loss: 8.05391788482666
Epoch 50, training loss: 7.683601379394531
Epoch 60, training loss: 7.305220127105713
Epoch 70, training loss: 7.075908660888672
Epoch 80, training loss: 6.894869327545166
Epoch 90, training loss: 6.731010913848877
Epoch 100, training loss: 6.550521373748779
Epoch 110, training loss: 6.489932537078857
Epoch 120, training loss: 6.3355560302734375
Epoch 130, training loss: 6.58193302154541
Epoch 140, training loss: 6.199589252471924
Epoch 150, training loss: 6.17503547668457
Epoch 160, training loss: 6.041842937469482
Epoch 170, training loss: 6.086391925811768
Epoch 180, training loss: 5.973060607910156
Epoch 190, training loss: 6.053189277648926
Epoch 200, training loss: 5.91738748550415
Epoch 210, training loss: 5.850461006164551
Epoch 220, training loss: 5.800025463104248
Epoch 230, training loss: 5.732899188995361
Epoch 240, training loss: 5.756595611572266
Epoch 250, training loss: 5.76267671585083
Epoch 260, training loss: 5.724995136260986
Epoch 270, training loss: 5.689194202423096
Epoch 280, training loss: 5.588998317718506
Epoch 290, training loss: 5.5776286125183105
Epoch 300, training loss: 5.601564884185791
Epoch 310, training loss: 5.5042829513549805
Epoch 320, training loss: 5.566203594207764
Epoch 330, training loss: 5.423624038696289
Epoch 340, training loss: 5.420899868011475
Epoch 350, training loss: 5.505573749542236
Epoch 360, training loss: 5.52486515045166
Epoch 370, training loss: 5.389235973358154
Epoch 380, training loss: 5.319676399230957
Epoch 390, training loss: 5.455937385559082
Epoch 400, training loss: 5.3872246742248535
Epoch 410, training loss: 5.462451934814453
Epoch 420, training loss: 5.316688537597656
Epoch 430, training loss: 5.296868324279785
Epoch 440, training loss: 5.320549011230469
Epoch 450, training loss: 5.314323425292969
Epoch 460, training loss: 5.325858116149902
Epoch 470, training loss: 5.2736921310424805
Epoch 480, training loss: 5.185651779174805
Epoch 490, training loss: 5.239573001861572
random
Accuracy: 0.768
Accuracy: 0.767
Accuracy: 0.755
Accuracy: 0.754
Accuracy: 0.743
Accuracy: 0.741
Accuracy: 0.735
Accuracy: 0.726
Accuracy: 0.723
Accuracy: 0.721
Accuracy: 0.714
Accuracy: 0.7
Accuracy: 0.686
Accuracy: 0.668
Accuracy: 0.664
Accuracy: 0.667
Accuracy: 0.664
Accuracy: 0.67
Accuracy: 0.661
Accuracy: 0.656
Accuracy: 0.644
Beta:0.9 Ptb size:0 Accuracy:0.7770+-0.0198
Beta:0.9 Ptb size:1 Accuracy:0.7752+-0.0199
Beta:0.9 Ptb size:2 Accuracy:0.7692+-0.0190
Beta:0.9 Ptb size:3 Accuracy:0.7662+-0.0222
Beta:0.9 Ptb size:4 Accuracy:0.7574+-0.0186
Beta:0.9 Ptb size:5 Accuracy:0.7482+-0.0196
Beta:0.9 Ptb size:6 Accuracy:0.7464+-0.0179
Beta:0.9 Ptb size:7 Accuracy:0.7368+-0.0239
Beta:0.9 Ptb size:8 Accuracy:0.7296+-0.0215
Beta:0.9 Ptb size:9 Accuracy:0.7258+-0.0198
Beta:0.9 Ptb size:10 Accuracy:0.7158+-0.0191
Beta:0.9 Ptb size:11 Accuracy:0.7088+-0.0204
Beta:0.9 Ptb size:12 Accuracy:0.6994+-0.0220
Beta:0.9 Ptb size:13 Accuracy:0.6884+-0.0229
Beta:0.9 Ptb size:14 Accuracy:0.6850+-0.0237
Beta:0.9 Ptb size:15 Accuracy:0.6800+-0.0238
Beta:0.9 Ptb size:16 Accuracy:0.6666+-0.0183
Beta:0.9 Ptb size:17 Accuracy:0.6670+-0.0210
Beta:0.9 Ptb size:18 Accuracy:0.6672+-0.0247
Beta:0.9 Ptb size:19 Accuracy:0.6604+-0.0321
Beta:0.9 Ptb size:20 Accuracy:0.6504+-0.0191
