nohup: ignoring input
run_gnn.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Namespace(add_edge_rate_1=0, add_edge_rate_2=0, attack='none', base_model='GCN', cl_activation='relu', cl_base_model='GCNConv', cl_lr=0.0005, cl_num_epochs=200, cl_num_layers=2, cl_num_proj_hidden=128, cl_weight_decay=1e-05, clf_weight=1, config='config.yaml', cont_batch_size=0, cont_weight=1, cuda=True, dataset='Cora', debug=True, device_id=0, drop_edge_rate_1=0.2, drop_edge_rate_2=0, drop_feat_rate_1=0.3, drop_feat_rate_2=0.2, dropout=0.5, hidden=128, if_smoothed=True, inv_weight=1, model='GCN', no_cuda=False, noisy_level=0.3, num_hidden=128, num_proj_hidden=128, num_repeat=5, prob=0.8, seed=10, select_target_ratio=0.1, tau=0.1, test_model='GCN', train_lr=0.01, weight_decay=0.0005)
=== training gcn model ===
Epoch 0, training loss: 1.9463679790496826
acc_val: 0.5620
Epoch 10, training loss: 1.492151141166687
acc_val: 0.7340
Epoch 20, training loss: 0.7281809449195862
acc_val: 0.7840
Epoch 30, training loss: 0.25319281220436096
acc_val: 0.8040
Epoch 40, training loss: 0.1027442216873169
acc_val: 0.7900
Epoch 50, training loss: 0.05001194402575493
acc_val: 0.7880
Epoch 60, training loss: 0.02853526547551155
acc_val: 0.7880
Epoch 70, training loss: 0.025163447484374046
acc_val: 0.7860
Epoch 80, training loss: 0.019340887665748596
acc_val: 0.7860
Epoch 90, training loss: 0.015190120786428452
acc_val: 0.7900
Epoch 100, training loss: 0.013777153566479683
acc_val: 0.7840
Epoch 110, training loss: 0.01346125639975071
acc_val: 0.7900
Epoch 120, training loss: 0.014144079759716988
acc_val: 0.7880
Epoch 130, training loss: 0.013547740876674652
acc_val: 0.7940
Epoch 140, training loss: 0.014551692642271519
acc_val: 0.7880
Epoch 150, training loss: 0.012688622809946537
acc_val: 0.7940
Epoch 160, training loss: 0.012854022905230522
acc_val: 0.7980
Epoch 170, training loss: 0.012102414853870869
acc_val: 0.7980
Epoch 180, training loss: 0.011651686392724514
acc_val: 0.7920
Epoch 190, training loss: 0.011822904460132122
acc_val: 0.7900
Epoch 200, training loss: 0.009487729519605637
acc_val: 0.7960
Epoch 210, training loss: 0.010425269603729248
acc_val: 0.7940
Epoch 220, training loss: 0.009928643703460693
acc_val: 0.7980
Epoch 230, training loss: 0.00968515407294035
acc_val: 0.7920
Epoch 240, training loss: 0.008633707650005817
acc_val: 0.7880
Epoch 250, training loss: 0.008863609284162521
acc_val: 0.7940
Epoch 260, training loss: 0.007864349521696568
acc_val: 0.7920
Epoch 270, training loss: 0.010060718283057213
acc_val: 0.7920
Epoch 280, training loss: 0.009124710224568844
acc_val: 0.7880
Epoch 290, training loss: 0.006687951274216175
acc_val: 0.7940
Epoch 300, training loss: 0.007912705652415752
acc_val: 0.7860
Epoch 310, training loss: 0.007124615367501974
acc_val: 0.7900
Epoch 320, training loss: 0.007075939793139696
acc_val: 0.7920
Epoch 330, training loss: 0.007370770908892155
acc_val: 0.7880
Epoch 340, training loss: 0.007478999439626932
acc_val: 0.7860
Epoch 350, training loss: 0.0068984911777079105
acc_val: 0.7900
Epoch 360, training loss: 0.006380705162882805
acc_val: 0.7900
Epoch 370, training loss: 0.005961539689451456
acc_val: 0.7900
Epoch 380, training loss: 0.006714805029332638
acc_val: 0.7820
Epoch 390, training loss: 0.007683828938752413
acc_val: 0.7840
Epoch 400, training loss: 0.006290471646934748
acc_val: 0.7840
Epoch 410, training loss: 0.005362966563552618
acc_val: 0.7860
Epoch 420, training loss: 0.006516970694065094
acc_val: 0.7860
Epoch 430, training loss: 0.006357969716191292
acc_val: 0.7860
Epoch 440, training loss: 0.006750600878149271
acc_val: 0.7880
Epoch 450, training loss: 0.006236271467059851
acc_val: 0.7880
Epoch 460, training loss: 0.006378555204719305
acc_val: 0.7880
Epoch 470, training loss: 0.006530252750962973
acc_val: 0.7860
Epoch 480, training loss: 0.006700205150991678
acc_val: 0.7860
Epoch 490, training loss: 0.00580682884901762
acc_val: 0.7900
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.8190000000000001
=== training gcn model ===
Epoch 0, training loss: 1.945181965827942
acc_val: 0.3520
Epoch 10, training loss: 1.4791568517684937
acc_val: 0.7720
Epoch 20, training loss: 0.7351546287536621
acc_val: 0.7900
Epoch 30, training loss: 0.2655702531337738
acc_val: 0.7900
Epoch 40, training loss: 0.09855388104915619
acc_val: 0.7880
Epoch 50, training loss: 0.049373529851436615
acc_val: 0.7860
Epoch 60, training loss: 0.028763815760612488
acc_val: 0.7860
Epoch 70, training loss: 0.025115394964814186
acc_val: 0.7900
Epoch 80, training loss: 0.020325638353824615
acc_val: 0.7860
Epoch 90, training loss: 0.016429293900728226
acc_val: 0.7880
Epoch 100, training loss: 0.014821740798652172
acc_val: 0.7840
Epoch 110, training loss: 0.016020573675632477
acc_val: 0.7860
Epoch 120, training loss: 0.0145918233320117
acc_val: 0.7900
Epoch 130, training loss: 0.012657827697694302
acc_val: 0.7860
Epoch 140, training loss: 0.012941752560436726
acc_val: 0.7920
Epoch 150, training loss: 0.012790536507964134
acc_val: 0.7840
Epoch 160, training loss: 0.011478079482913017
acc_val: 0.7940
Epoch 170, training loss: 0.01205960102379322
acc_val: 0.7880
Epoch 180, training loss: 0.013494334183633327
acc_val: 0.7940
Epoch 190, training loss: 0.011321325786411762
acc_val: 0.7820
Epoch 200, training loss: 0.00910119991749525
acc_val: 0.7960
Epoch 210, training loss: 0.011275822296738625
acc_val: 0.7900
Epoch 220, training loss: 0.00817587785422802
acc_val: 0.7920
Epoch 230, training loss: 0.009709637612104416
acc_val: 0.7900
Epoch 240, training loss: 0.009398004971444607
acc_val: 0.7880
Epoch 250, training loss: 0.008651654236018658
acc_val: 0.7900
Epoch 260, training loss: 0.0083245187997818
acc_val: 0.7900
Epoch 270, training loss: 0.007634727284312248
acc_val: 0.7860
Epoch 280, training loss: 0.008138768374919891
acc_val: 0.7900
Epoch 290, training loss: 0.008418996818363667
acc_val: 0.7900
Epoch 300, training loss: 0.007980386726558208
acc_val: 0.7920
Epoch 310, training loss: 0.007269083522260189
acc_val: 0.7880
Epoch 320, training loss: 0.00880241859704256
acc_val: 0.7860
Epoch 330, training loss: 0.007160897832363844
acc_val: 0.7920
Epoch 340, training loss: 0.0075911786407232285
acc_val: 0.7880
Epoch 350, training loss: 0.006707596126943827
acc_val: 0.7860
Epoch 360, training loss: 0.0073168626986444
acc_val: 0.7920
Epoch 370, training loss: 0.006514749955385923
acc_val: 0.7880
Epoch 380, training loss: 0.0066080051474273205
acc_val: 0.7880
Epoch 390, training loss: 0.006013728212565184
acc_val: 0.7900
Epoch 400, training loss: 0.007446935400366783
acc_val: 0.7860
Epoch 410, training loss: 0.006301501300185919
acc_val: 0.7800
Epoch 420, training loss: 0.006096291355788708
acc_val: 0.7900
Epoch 430, training loss: 0.005701287649571896
acc_val: 0.7940
Epoch 440, training loss: 0.006402222905308008
acc_val: 0.7900
Epoch 450, training loss: 0.007424162235110998
acc_val: 0.7920
Epoch 460, training loss: 0.005784930661320686
acc_val: 0.7920
Epoch 470, training loss: 0.005187862552702427
acc_val: 0.7880
Epoch 480, training loss: 0.005992939695715904
acc_val: 0.7860
Epoch 490, training loss: 0.006358213722705841
acc_val: 0.7860
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.8130000000000001
=== training gcn model ===
Epoch 0, training loss: 1.9464703798294067
acc_val: 0.1880
Epoch 10, training loss: 1.5098490715026855
acc_val: 0.7260
Epoch 20, training loss: 0.7570651173591614
acc_val: 0.7820
Epoch 30, training loss: 0.2648828625679016
acc_val: 0.7860
Epoch 40, training loss: 0.12063077837228775
acc_val: 0.7920
Epoch 50, training loss: 0.04401669278740883
acc_val: 0.7900
Epoch 60, training loss: 0.028970932587981224
acc_val: 0.7940
Epoch 70, training loss: 0.024136565625667572
acc_val: 0.7780
Epoch 80, training loss: 0.01858459785580635
acc_val: 0.7880
Epoch 90, training loss: 0.015743667259812355
acc_val: 0.7840
Epoch 100, training loss: 0.016436785459518433
acc_val: 0.7940
Epoch 110, training loss: 0.016416020691394806
acc_val: 0.7800
Epoch 120, training loss: 0.013739809393882751
acc_val: 0.7900
Epoch 130, training loss: 0.014863776974380016
acc_val: 0.7860
Epoch 140, training loss: 0.014186342246830463
acc_val: 0.7880
Epoch 150, training loss: 0.013515787199139595
acc_val: 0.7940
Epoch 160, training loss: 0.013351933099329472
acc_val: 0.7940
Epoch 170, training loss: 0.0128044867888093
acc_val: 0.7820
Epoch 180, training loss: 0.010194051079452038
acc_val: 0.7920
Epoch 190, training loss: 0.010634406469762325
acc_val: 0.7900
Epoch 200, training loss: 0.009994592517614365
acc_val: 0.7880
Epoch 210, training loss: 0.011134500615298748
acc_val: 0.7940
Epoch 220, training loss: 0.010163840837776661
acc_val: 0.7960
Epoch 230, training loss: 0.008955433964729309
acc_val: 0.7940
Epoch 240, training loss: 0.007913241162896156
acc_val: 0.7900
Epoch 250, training loss: 0.008910270407795906
acc_val: 0.7980
Epoch 260, training loss: 0.008070296607911587
acc_val: 0.7900
Epoch 270, training loss: 0.008623318746685982
acc_val: 0.7920
Epoch 280, training loss: 0.00914103351533413
acc_val: 0.7920
Epoch 290, training loss: 0.007232929114252329
acc_val: 0.7900
Epoch 300, training loss: 0.008586633019149303
acc_val: 0.7900
Epoch 310, training loss: 0.00775140430778265
acc_val: 0.7860
Epoch 320, training loss: 0.006970459129661322
acc_val: 0.7940
Epoch 330, training loss: 0.007163311820477247
acc_val: 0.7820
Epoch 340, training loss: 0.00655960850417614
acc_val: 0.7920
Epoch 350, training loss: 0.007191015873104334
acc_val: 0.7900
Epoch 360, training loss: 0.007189131807535887
acc_val: 0.7920
Epoch 370, training loss: 0.008044406771659851
acc_val: 0.7900
Epoch 380, training loss: 0.007326115854084492
acc_val: 0.7900
Epoch 390, training loss: 0.005909151863306761
acc_val: 0.7920
Epoch 400, training loss: 0.0063276272267103195
acc_val: 0.7880
Epoch 410, training loss: 0.0056711831130087376
acc_val: 0.7900
Epoch 420, training loss: 0.006058933679014444
acc_val: 0.7960
Epoch 430, training loss: 0.007052239961922169
acc_val: 0.7840
Epoch 440, training loss: 0.005702953785657883
acc_val: 0.7900
Epoch 450, training loss: 0.006377723533660173
acc_val: 0.7820
Epoch 460, training loss: 0.007183937355875969
acc_val: 0.7960
Epoch 470, training loss: 0.006286618299782276
acc_val: 0.7840
Epoch 480, training loss: 0.006605289410799742
acc_val: 0.7860
Epoch 490, training loss: 0.005278247874230146
acc_val: 0.7820
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.804
=== training gcn model ===
Epoch 0, training loss: 1.9458339214324951
acc_val: 0.4040
Epoch 10, training loss: 1.4898860454559326
acc_val: 0.7720
Epoch 20, training loss: 0.7494657635688782
acc_val: 0.7880
Epoch 30, training loss: 0.25857147574424744
acc_val: 0.7880
Epoch 40, training loss: 0.09130536019802094
acc_val: 0.7940
Epoch 50, training loss: 0.04543312266469002
acc_val: 0.7880
Epoch 60, training loss: 0.028745882213115692
acc_val: 0.7840
Epoch 70, training loss: 0.025927573442459106
acc_val: 0.7880
Epoch 80, training loss: 0.016815846785902977
acc_val: 0.7820
Epoch 90, training loss: 0.016045063734054565
acc_val: 0.7860
Epoch 100, training loss: 0.013838225975632668
acc_val: 0.7840
Epoch 110, training loss: 0.013874391093850136
acc_val: 0.7880
Epoch 120, training loss: 0.014869029633700848
acc_val: 0.7880
Epoch 130, training loss: 0.012820477597415447
acc_val: 0.7920
Epoch 140, training loss: 0.013293969444930553
acc_val: 0.7820
Epoch 150, training loss: 0.011800660751760006
acc_val: 0.7920
Epoch 160, training loss: 0.012242992408573627
acc_val: 0.7880
Epoch 170, training loss: 0.012728672474622726
acc_val: 0.7860
Epoch 180, training loss: 0.012096861377358437
acc_val: 0.7960
Epoch 190, training loss: 0.01103734876960516
acc_val: 0.7960
Epoch 200, training loss: 0.010512146167457104
acc_val: 0.7920
Epoch 210, training loss: 0.00881140399724245
acc_val: 0.7920
Epoch 220, training loss: 0.010367976501584053
acc_val: 0.7900
Epoch 230, training loss: 0.010229316540062428
acc_val: 0.7900
Epoch 240, training loss: 0.009525354951620102
acc_val: 0.7920
Epoch 250, training loss: 0.008478532545268536
acc_val: 0.7940
Epoch 260, training loss: 0.009707823395729065
acc_val: 0.7940
Epoch 270, training loss: 0.009459920227527618
acc_val: 0.7940
Epoch 280, training loss: 0.009623761288821697
acc_val: 0.7960
Epoch 290, training loss: 0.0082286661490798
acc_val: 0.7980
Epoch 300, training loss: 0.007740127854049206
acc_val: 0.7920
Epoch 310, training loss: 0.006915883161127567
acc_val: 0.7960
Epoch 320, training loss: 0.00790389720350504
acc_val: 0.7820
Epoch 330, training loss: 0.006991032976657152
acc_val: 0.7920
Epoch 340, training loss: 0.007193002384155989
acc_val: 0.7860
Epoch 350, training loss: 0.007016458548605442
acc_val: 0.7920
Epoch 360, training loss: 0.006098304409533739
acc_val: 0.7880
Epoch 370, training loss: 0.005830185953527689
acc_val: 0.7860
Epoch 380, training loss: 0.0075522176921367645
acc_val: 0.7800
Epoch 390, training loss: 0.0064113810658454895
acc_val: 0.7760
Epoch 400, training loss: 0.006346146576106548
acc_val: 0.7880
Epoch 410, training loss: 0.006957243662327528
acc_val: 0.7860
Epoch 420, training loss: 0.005456189624965191
acc_val: 0.7860
Epoch 430, training loss: 0.0055558932945132256
acc_val: 0.7880
Epoch 440, training loss: 0.005942560266703367
acc_val: 0.7800
Epoch 450, training loss: 0.006181610282510519
acc_val: 0.7820
Epoch 460, training loss: 0.00600926810875535
acc_val: 0.7860
Epoch 470, training loss: 0.00529266195371747
acc_val: 0.7800
Epoch 480, training loss: 0.005444344598799944
acc_val: 0.7860
Epoch 490, training loss: 0.005559531040489674
acc_val: 0.7760
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.809
=== training gcn model ===
Epoch 0, training loss: 1.9460760354995728
acc_val: 0.4200
Epoch 10, training loss: 1.4894304275512695
acc_val: 0.7660
Epoch 20, training loss: 0.735789954662323
acc_val: 0.7920
Epoch 30, training loss: 0.25374671816825867
acc_val: 0.7920
Epoch 40, training loss: 0.09489138424396515
acc_val: 0.7920
Epoch 50, training loss: 0.045283541083335876
acc_val: 0.7840
Epoch 60, training loss: 0.03272223845124245
acc_val: 0.7860
Epoch 70, training loss: 0.02455846592783928
acc_val: 0.7860
Epoch 80, training loss: 0.020108293741941452
acc_val: 0.7880
Epoch 90, training loss: 0.015720315277576447
acc_val: 0.7900
Epoch 100, training loss: 0.015257704071700573
acc_val: 0.7820
Epoch 110, training loss: 0.015026764944195747
acc_val: 0.7940
Epoch 120, training loss: 0.01400521956384182
acc_val: 0.7920
Epoch 130, training loss: 0.01667335070669651
acc_val: 0.7880
Epoch 140, training loss: 0.013212669640779495
acc_val: 0.7880
Epoch 150, training loss: 0.013999746181070805
acc_val: 0.7900
Epoch 160, training loss: 0.01184476912021637
acc_val: 0.7960
Epoch 170, training loss: 0.009583373554050922
acc_val: 0.7920
Epoch 180, training loss: 0.011500728316605091
acc_val: 0.8000
Epoch 190, training loss: 0.0123677309602499
acc_val: 0.7920
Epoch 200, training loss: 0.01098077092319727
acc_val: 0.7900
Epoch 210, training loss: 0.009455200284719467
acc_val: 0.7900
Epoch 220, training loss: 0.01086009107530117
acc_val: 0.7920
Epoch 230, training loss: 0.008601524867117405
acc_val: 0.7940
Epoch 240, training loss: 0.008029263466596603
acc_val: 0.7900
Epoch 250, training loss: 0.008815652690827847
acc_val: 0.7920
Epoch 260, training loss: 0.00905174482613802
acc_val: 0.7940
Epoch 270, training loss: 0.00942049827426672
acc_val: 0.7800
Epoch 280, training loss: 0.009023726917803288
acc_val: 0.7900
Epoch 290, training loss: 0.009075433015823364
acc_val: 0.7920
Epoch 300, training loss: 0.007759409490972757
acc_val: 0.7840
Epoch 310, training loss: 0.007446699310094118
acc_val: 0.7900
Epoch 320, training loss: 0.0076612913981080055
acc_val: 0.7960
Epoch 330, training loss: 0.007853023707866669
acc_val: 0.7860
Epoch 340, training loss: 0.008082796819508076
acc_val: 0.7900
Epoch 350, training loss: 0.008696941658854485
acc_val: 0.7960
Epoch 360, training loss: 0.0068911598064005375
acc_val: 0.7900
Epoch 370, training loss: 0.0070145088247954845
acc_val: 0.7840
Epoch 380, training loss: 0.006469284184277058
acc_val: 0.7920
Epoch 390, training loss: 0.0062447721138596535
acc_val: 0.7840
Epoch 400, training loss: 0.006389046087861061
acc_val: 0.7940
Epoch 410, training loss: 0.006043403875082731
acc_val: 0.7920
Epoch 420, training loss: 0.0065384311601519585
acc_val: 0.7780
Epoch 430, training loss: 0.005707914941012859
acc_val: 0.7960
Epoch 440, training loss: 0.006126427557319403
acc_val: 0.7940
Epoch 450, training loss: 0.006335235666483641
acc_val: 0.7780
Epoch 460, training loss: 0.006376808043569326
acc_val: 0.7940
Epoch 470, training loss: 0.005354174412786961
acc_val: 0.7880
Epoch 480, training loss: 0.0052977148443460464
acc_val: 0.7860
Epoch 490, training loss: 0.005895453039556742
acc_val: 0.7860
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.803
