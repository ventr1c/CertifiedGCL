nohup: ignoring input
run_robust_acc.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Namespace(add_edge_rate_1=0, add_edge_rate_2=0, attack='random', base_model='GCN', cl_activation='relu', cl_base_model='GCNConv', cl_lr=0.0005, cl_num_epochs=200, cl_num_layers=2, cl_num_proj_hidden=128, cl_weight_decay=1e-05, clf_weight=1, config='config.yaml', cont_batch_size=0, cont_weight=1, cuda=True, dataset='Cora', debug=True, device_id=1, drop_edge_rate_1=0.2, drop_edge_rate_2=0, drop_feat_rate_1=0.3, drop_feat_rate_2=0.2, dropout=0.5, encoder_model='Grace', hidden=128, if_smoothed=True, inv_weight=1, no_cuda=False, noisy_level=0.3, num_hidden=128, num_proj_hidden=128, num_repeat=5, prob=0.8, seed=10, select_target_ratio=0.1, tau=0.1, test_model='GCN', train_lr=0.01, weight_decay=0.0005)
beta 0.5
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.598122596740723
Epoch 10, training loss: 8.596550941467285
Epoch 20, training loss: 8.593487739562988
Epoch 30, training loss: 8.55265998840332
Epoch 40, training loss: 8.353352546691895
Epoch 50, training loss: 8.12106704711914
Epoch 60, training loss: 7.720355987548828
Epoch 70, training loss: 7.708555221557617
Epoch 80, training loss: 7.384867191314697
Epoch 90, training loss: 7.295112133026123
Epoch 100, training loss: 7.184230327606201
Epoch 110, training loss: 7.22356653213501
Epoch 120, training loss: 7.076766014099121
Epoch 130, training loss: 6.971292972564697
Epoch 140, training loss: 6.930949687957764
Epoch 150, training loss: 6.821317672729492
Epoch 160, training loss: 6.910660266876221
Epoch 170, training loss: 6.743070125579834
Epoch 180, training loss: 6.726457595825195
Epoch 190, training loss: 6.608195781707764
Epoch 200, training loss: 6.640353679656982
Epoch 210, training loss: 6.671151638031006
Epoch 220, training loss: 6.534326553344727
Epoch 230, training loss: 6.467264175415039
Epoch 240, training loss: 6.493483543395996
Epoch 250, training loss: 6.412299633026123
Epoch 260, training loss: 6.582753658294678
Epoch 270, training loss: 6.481616973876953
Epoch 280, training loss: 6.322820663452148
Epoch 290, training loss: 6.381982803344727
Epoch 300, training loss: 6.345327854156494
Epoch 310, training loss: 6.251802921295166
Epoch 320, training loss: 6.188837051391602
Epoch 330, training loss: 6.192705154418945
Epoch 340, training loss: 6.21889066696167
Epoch 350, training loss: 6.197282791137695
Epoch 360, training loss: 6.147441387176514
Epoch 370, training loss: 6.024295806884766
Epoch 380, training loss: 6.060111999511719
Epoch 390, training loss: 6.039053440093994
Epoch 400, training loss: 6.076063632965088
Epoch 410, training loss: 6.073366165161133
Epoch 420, training loss: 5.981268405914307
Epoch 430, training loss: 5.947056293487549
Epoch 440, training loss: 5.962963104248047
Epoch 450, training loss: 5.977151870727539
Epoch 460, training loss: 5.914468288421631
Epoch 470, training loss: 5.919222354888916
Epoch 480, training loss: 5.859702110290527
Epoch 490, training loss: 5.903716087341309
random
Perturbation Size:0
Accuracy: 0.76
Perturbation Size:1
Accuracy: 0.76
Perturbation Size:2
Accuracy: 0.76
Perturbation Size:3
Accuracy: 0.76
Perturbation Size:4
Accuracy: 0.76
Perturbation Size:5
Accuracy: 0.76
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.598494529724121
Epoch 10, training loss: 8.596138954162598
Epoch 20, training loss: 8.588310241699219
Epoch 30, training loss: 8.455950736999512
Epoch 40, training loss: 8.278843879699707
Epoch 50, training loss: 7.977771282196045
Epoch 60, training loss: 7.719254493713379
Epoch 70, training loss: 7.537135124206543
Epoch 80, training loss: 7.443843364715576
Epoch 90, training loss: 7.29621696472168
Epoch 100, training loss: 7.208580493927002
Epoch 110, training loss: 7.17891788482666
Epoch 120, training loss: 7.209978103637695
Epoch 130, training loss: 6.9036664962768555
Epoch 140, training loss: 6.9243364334106445
Epoch 150, training loss: 6.842972278594971
Epoch 160, training loss: 6.87685489654541
Epoch 170, training loss: 6.948622703552246
Epoch 180, training loss: 6.8125
Epoch 190, training loss: 6.776856899261475
Epoch 200, training loss: 6.6682209968566895
Epoch 210, training loss: 6.620929718017578
Epoch 220, training loss: 6.5784406661987305
Epoch 230, training loss: 6.488137722015381
Epoch 240, training loss: 6.449488162994385
Epoch 250, training loss: 6.510911464691162
Epoch 260, training loss: 6.469759464263916
Epoch 270, training loss: 6.405588626861572
Epoch 280, training loss: 6.421271800994873
Epoch 290, training loss: 6.2814202308654785
Epoch 300, training loss: 6.3812384605407715
Epoch 310, training loss: 6.285328388214111
Epoch 320, training loss: 6.278160095214844
Epoch 330, training loss: 6.250395774841309
Epoch 340, training loss: 6.1961894035339355
Epoch 350, training loss: 6.105372905731201
Epoch 360, training loss: 6.214383602142334
Epoch 370, training loss: 6.181739807128906
Epoch 380, training loss: 6.162555694580078
Epoch 390, training loss: 6.209372043609619
Epoch 400, training loss: 6.063040256500244
Epoch 410, training loss: 6.154601097106934
Epoch 420, training loss: 6.008552551269531
Epoch 430, training loss: 6.039344787597656
Epoch 440, training loss: 6.006173610687256
Epoch 450, training loss: 5.935487747192383
Epoch 460, training loss: 6.042254447937012
Epoch 470, training loss: 5.945999622344971
Epoch 480, training loss: 5.883177280426025
Epoch 490, training loss: 5.860456466674805
random
Perturbation Size:0
Accuracy: 0.777
Perturbation Size:1
Accuracy: 0.777
Perturbation Size:2
Accuracy: 0.777
Perturbation Size:3
Accuracy: 0.777
Perturbation Size:4
Accuracy: 0.777
Perturbation Size:5
Accuracy: 0.777
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.598775863647461
Epoch 10, training loss: 8.597164154052734
Epoch 20, training loss: 8.594459533691406
Epoch 30, training loss: 8.551800727844238
Epoch 40, training loss: 8.273788452148438
Epoch 50, training loss: 8.045781135559082
Epoch 60, training loss: 7.669654846191406
Epoch 70, training loss: 7.622661590576172
Epoch 80, training loss: 7.475149631500244
Epoch 90, training loss: 7.294159889221191
Epoch 100, training loss: 7.0907883644104
Epoch 110, training loss: 7.1236395835876465
Epoch 120, training loss: 6.980551719665527
Epoch 130, training loss: 6.886900424957275
Epoch 140, training loss: 6.982800483703613
Epoch 150, training loss: 6.822295665740967
Epoch 160, training loss: 6.717635631561279
Epoch 170, training loss: 6.656763553619385
Epoch 180, training loss: 6.577061176300049
Epoch 190, training loss: 6.549890995025635
Epoch 200, training loss: 6.4001898765563965
Epoch 210, training loss: 6.391237735748291
Epoch 220, training loss: 6.481696128845215
Epoch 230, training loss: 6.205732822418213
Epoch 240, training loss: 6.242800235748291
Epoch 250, training loss: 6.309345245361328
Epoch 260, training loss: 6.25061559677124
Epoch 270, training loss: 6.322963714599609
Epoch 280, training loss: 6.177696704864502
Epoch 290, training loss: 6.12936544418335
Epoch 300, training loss: 6.1304121017456055
Epoch 310, training loss: 5.972446441650391
Epoch 320, training loss: 6.007153511047363
Epoch 330, training loss: 5.985344409942627
Epoch 340, training loss: 5.968207359313965
Epoch 350, training loss: 6.129777431488037
Epoch 360, training loss: 6.016180038452148
Epoch 370, training loss: 5.969688415527344
Epoch 380, training loss: 6.026214122772217
Epoch 390, training loss: 5.8224077224731445
Epoch 400, training loss: 5.916441917419434
Epoch 410, training loss: 5.92843770980835
Epoch 420, training loss: 5.792374610900879
Epoch 430, training loss: 5.732185363769531
Epoch 440, training loss: 5.791202545166016
Epoch 450, training loss: 5.785786151885986
Epoch 460, training loss: 5.757808685302734
Epoch 470, training loss: 5.781775951385498
Epoch 480, training loss: 5.976382732391357
Epoch 490, training loss: 5.738962173461914
random
Perturbation Size:0
Accuracy: 0.759
Perturbation Size:1
Accuracy: 0.759
Perturbation Size:2
Accuracy: 0.759
Perturbation Size:3
Accuracy: 0.759
Perturbation Size:4
Accuracy: 0.759
Perturbation Size:5
Accuracy: 0.759
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.598759651184082
Epoch 10, training loss: 8.596280097961426
Epoch 20, training loss: 8.594064712524414
Epoch 30, training loss: 8.54012393951416
Epoch 40, training loss: 8.330404281616211
Epoch 50, training loss: 8.165635108947754
Epoch 60, training loss: 7.895348072052002
Epoch 70, training loss: 7.690520286560059
Epoch 80, training loss: 7.5508503913879395
Epoch 90, training loss: 7.4547576904296875
Epoch 100, training loss: 7.398799419403076
Epoch 110, training loss: 7.280801296234131
Epoch 120, training loss: 7.101229667663574
Epoch 130, training loss: 6.978903293609619
Epoch 140, training loss: 7.076815128326416
Epoch 150, training loss: 6.947653293609619
Epoch 160, training loss: 6.75823450088501
Epoch 170, training loss: 6.759145259857178
Epoch 180, training loss: 6.761924743652344
Epoch 190, training loss: 6.610498428344727
Epoch 200, training loss: 6.446099281311035
Epoch 210, training loss: 6.552034854888916
Epoch 220, training loss: 6.5072431564331055
Epoch 230, training loss: 6.487441539764404
Epoch 240, training loss: 6.376951694488525
Epoch 250, training loss: 6.408527374267578
Epoch 260, training loss: 6.442465782165527
Epoch 270, training loss: 6.270951747894287
Epoch 280, training loss: 6.258168697357178
Epoch 290, training loss: 6.366426944732666
Epoch 300, training loss: 6.184055805206299
Epoch 310, training loss: 6.223931312561035
Epoch 320, training loss: 6.13615083694458
Epoch 330, training loss: 6.0578765869140625
Epoch 340, training loss: 6.019566535949707
Epoch 350, training loss: 6.1946234703063965
Epoch 360, training loss: 6.104343414306641
Epoch 370, training loss: 5.9934234619140625
Epoch 380, training loss: 5.966972827911377
Epoch 390, training loss: 6.010379791259766
Epoch 400, training loss: 5.827851295471191
Epoch 410, training loss: 5.905062675476074
Epoch 420, training loss: 5.837242603302002
Epoch 430, training loss: 5.914308547973633
Epoch 440, training loss: 5.824696063995361
Epoch 450, training loss: 5.907327651977539
Epoch 460, training loss: 5.75485897064209
Epoch 470, training loss: 5.800759792327881
Epoch 480, training loss: 5.745728015899658
Epoch 490, training loss: 5.886196613311768
random
Perturbation Size:0
Accuracy: 0.804
Perturbation Size:1
Accuracy: 0.804
Perturbation Size:2
Accuracy: 0.804
Perturbation Size:3
Accuracy: 0.804
Perturbation Size:4
Accuracy: 0.804
Perturbation Size:5
Accuracy: 0.804
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.598325729370117
Epoch 10, training loss: 8.59664249420166
Epoch 20, training loss: 8.594499588012695
Epoch 30, training loss: 8.554594993591309
Epoch 40, training loss: 8.300433158874512
Epoch 50, training loss: 7.997696399688721
Epoch 60, training loss: 7.83992862701416
Epoch 70, training loss: 7.701584339141846
Epoch 80, training loss: 7.4279398918151855
Epoch 90, training loss: 7.3250579833984375
Epoch 100, training loss: 7.185182571411133
Epoch 110, training loss: 7.154266357421875
Epoch 120, training loss: 7.106263637542725
Epoch 130, training loss: 6.956331729888916
Epoch 140, training loss: 6.921613693237305
Epoch 150, training loss: 6.860077381134033
Epoch 160, training loss: 6.871545314788818
Epoch 170, training loss: 6.657565593719482
Epoch 180, training loss: 6.762874603271484
Epoch 190, training loss: 6.664309024810791
Epoch 200, training loss: 6.5907135009765625
Epoch 210, training loss: 6.484801769256592
Epoch 220, training loss: 6.4396233558654785
Epoch 230, training loss: 6.371804237365723
Epoch 240, training loss: 6.39901876449585
Epoch 250, training loss: 6.213586330413818
Epoch 260, training loss: 6.257689952850342
Epoch 270, training loss: 6.181157112121582
Epoch 280, training loss: 6.307634353637695
Epoch 290, training loss: 6.1375508308410645
Epoch 300, training loss: 6.0690741539001465
Epoch 310, training loss: 6.105346202850342
Epoch 320, training loss: 6.082059383392334
Epoch 330, training loss: 6.124277114868164
Epoch 340, training loss: 6.1080427169799805
Epoch 350, training loss: 6.208802700042725
Epoch 360, training loss: 5.936497211456299
Epoch 370, training loss: 5.905990123748779
Epoch 380, training loss: 5.859858989715576
Epoch 390, training loss: 5.9465250968933105
Epoch 400, training loss: 5.977599143981934
Epoch 410, training loss: 5.961422920227051
Epoch 420, training loss: 5.92772912979126
Epoch 430, training loss: 5.861486911773682
Epoch 440, training loss: 5.808403015136719
Epoch 450, training loss: 5.83526611328125
Epoch 460, training loss: 5.77740478515625
Epoch 470, training loss: 5.804324626922607
Epoch 480, training loss: 5.829310417175293
Epoch 490, training loss: 5.819108963012695
random
Perturbation Size:0
Accuracy: 0.784
Perturbation Size:1
Accuracy: 0.784
Perturbation Size:2
Accuracy: 0.784
Perturbation Size:3
Accuracy: 0.784
Perturbation Size:4
Accuracy: 0.784
Perturbation Size:5
Accuracy: 0.784
beta 0.6
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.598885536193848
Epoch 10, training loss: 8.596505165100098
Epoch 20, training loss: 8.594496726989746
Epoch 30, training loss: 8.547062873840332
Epoch 40, training loss: 8.17839241027832
Epoch 50, training loss: 8.007024765014648
Epoch 60, training loss: 7.911474704742432
Epoch 70, training loss: 7.749629020690918
Epoch 80, training loss: 7.764863014221191
Epoch 90, training loss: 7.437615394592285
Epoch 100, training loss: 7.34014368057251
Epoch 110, training loss: 7.2685546875
Epoch 120, training loss: 7.041962623596191
Epoch 130, training loss: 7.058515548706055
Epoch 140, training loss: 6.9067888259887695
Epoch 150, training loss: 6.846062183380127
Epoch 160, training loss: 6.909134864807129
Epoch 170, training loss: 6.7804765701293945
Epoch 180, training loss: 6.757717132568359
Epoch 190, training loss: 6.654806613922119
Epoch 200, training loss: 6.691287994384766
Epoch 210, training loss: 6.660529136657715
Epoch 220, training loss: 6.519047737121582
Epoch 230, training loss: 6.481818675994873
Epoch 240, training loss: 6.450920581817627
Epoch 250, training loss: 6.4670305252075195
Epoch 260, training loss: 6.375109672546387
Epoch 270, training loss: 6.349187850952148
Epoch 280, training loss: 6.33600378036499
Epoch 290, training loss: 6.337176322937012
Epoch 300, training loss: 6.300463676452637
Epoch 310, training loss: 6.272994041442871
Epoch 320, training loss: 6.287542819976807
Epoch 330, training loss: 6.183313846588135
Epoch 340, training loss: 6.151758193969727
Epoch 350, training loss: 6.113865852355957
Epoch 360, training loss: 6.077849388122559
Epoch 370, training loss: 6.029228210449219
Epoch 380, training loss: 6.017721652984619
Epoch 390, training loss: 6.154486656188965
Epoch 400, training loss: 6.04336404800415
Epoch 410, training loss: 6.000512599945068
Epoch 420, training loss: 5.984079837799072
Epoch 430, training loss: 5.971506118774414
Epoch 440, training loss: 5.943466663360596
Epoch 450, training loss: 5.963756084442139
Epoch 460, training loss: 5.885922908782959
Epoch 470, training loss: 6.132782936096191
Epoch 480, training loss: 5.894759654998779
Epoch 490, training loss: 6.038615703582764
random
Perturbation Size:0
Accuracy: 0.78
Perturbation Size:1
Accuracy: 0.78
Perturbation Size:2
Accuracy: 0.78
Perturbation Size:3
Accuracy: 0.78
Perturbation Size:4
Accuracy: 0.78
Perturbation Size:5
Accuracy: 0.78
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.598843574523926
Epoch 10, training loss: 8.596057891845703
Epoch 20, training loss: 8.589497566223145
Epoch 30, training loss: 8.44186019897461
Epoch 40, training loss: 8.315778732299805
Epoch 50, training loss: 8.096556663513184
Epoch 60, training loss: 7.899491786956787
Epoch 70, training loss: 7.702545166015625
Epoch 80, training loss: 7.555032253265381
Epoch 90, training loss: 7.43615198135376
Epoch 100, training loss: 7.278140544891357
Epoch 110, training loss: 7.4309401512146
Epoch 120, training loss: 7.093778610229492
Epoch 130, training loss: 7.0708112716674805
Epoch 140, training loss: 6.916609764099121
Epoch 150, training loss: 6.918384075164795
Epoch 160, training loss: 6.843790054321289
Epoch 170, training loss: 6.968573093414307
Epoch 180, training loss: 6.81793212890625
Epoch 190, training loss: 6.696477890014648
Epoch 200, training loss: 6.764043807983398
Epoch 210, training loss: 6.692750453948975
Epoch 220, training loss: 6.684629440307617
Epoch 230, training loss: 6.604650020599365
Epoch 240, training loss: 6.554858207702637
Epoch 250, training loss: 6.4680914878845215
Epoch 260, training loss: 6.396332263946533
Epoch 270, training loss: 6.354682445526123
Epoch 280, training loss: 6.423647880554199
Epoch 290, training loss: 6.3291144371032715
Epoch 300, training loss: 6.282510757446289
Epoch 310, training loss: 6.150700569152832
Epoch 320, training loss: 6.2093000411987305
Epoch 330, training loss: 6.201157093048096
Epoch 340, training loss: 6.1821441650390625
Epoch 350, training loss: 6.238969326019287
Epoch 360, training loss: 6.077558517456055
Epoch 370, training loss: 6.287405490875244
Epoch 380, training loss: 6.071946620941162
Epoch 390, training loss: 6.0926594734191895
Epoch 400, training loss: 6.271878242492676
Epoch 410, training loss: 6.05052375793457
Epoch 420, training loss: 5.98101806640625
Epoch 430, training loss: 5.9944963455200195
Epoch 440, training loss: 5.9729509353637695
Epoch 450, training loss: 6.006351947784424
Epoch 460, training loss: 5.992196083068848
Epoch 470, training loss: 5.920158386230469
Epoch 480, training loss: 5.824430465698242
Epoch 490, training loss: 5.9977312088012695
random
Perturbation Size:0
Accuracy: 0.795
Perturbation Size:1
Accuracy: 0.795
Perturbation Size:2
Accuracy: 0.795
Perturbation Size:3
Accuracy: 0.795
Perturbation Size:4
Accuracy: 0.795
Perturbation Size:5
Accuracy: 0.795
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.598950386047363
Epoch 10, training loss: 8.596329689025879
Epoch 20, training loss: 8.59039306640625
Epoch 30, training loss: 8.4877290725708
Epoch 40, training loss: 8.303557395935059
Epoch 50, training loss: 8.118254661560059
Epoch 60, training loss: 8.012310028076172
Epoch 70, training loss: 7.7734599113464355
Epoch 80, training loss: 7.622033596038818
Epoch 90, training loss: 7.445575714111328
Epoch 100, training loss: 7.389848232269287
Epoch 110, training loss: 7.274649143218994
Epoch 120, training loss: 7.187765121459961
Epoch 130, training loss: 7.0633769035339355
Epoch 140, training loss: 7.0894036293029785
Epoch 150, training loss: 6.903486251831055
Epoch 160, training loss: 6.835023403167725
Epoch 170, training loss: 6.743103504180908
Epoch 180, training loss: 6.766974449157715
Epoch 190, training loss: 6.804396629333496
Epoch 200, training loss: 6.741963863372803
Epoch 210, training loss: 6.693036079406738
Epoch 220, training loss: 6.667389392852783
Epoch 230, training loss: 6.470709323883057
Epoch 240, training loss: 6.655412673950195
Epoch 250, training loss: 6.47546911239624
Epoch 260, training loss: 6.47413969039917
Epoch 270, training loss: 6.551945209503174
Epoch 280, training loss: 6.509266376495361
Epoch 290, training loss: 6.403642654418945
Epoch 300, training loss: 6.412389278411865
Epoch 310, training loss: 6.389606475830078
Epoch 320, training loss: 6.312378883361816
Epoch 330, training loss: 6.294991493225098
Epoch 340, training loss: 6.238853931427002
Epoch 350, training loss: 6.319333076477051
Epoch 360, training loss: 6.15001916885376
Epoch 370, training loss: 6.227764129638672
Epoch 380, training loss: 6.048550128936768
Epoch 390, training loss: 6.170178413391113
Epoch 400, training loss: 6.173043251037598
Epoch 410, training loss: 6.0378007888793945
Epoch 420, training loss: 6.028273105621338
Epoch 430, training loss: 6.156928062438965
Epoch 440, training loss: 5.992687702178955
Epoch 450, training loss: 6.015793800354004
Epoch 460, training loss: 6.0455241203308105
Epoch 470, training loss: 5.969171047210693
Epoch 480, training loss: 6.036631107330322
Epoch 490, training loss: 5.863112926483154
random
Perturbation Size:0
Accuracy: 0.769
Perturbation Size:1
Accuracy: 0.769
Perturbation Size:2
Accuracy: 0.769
Perturbation Size:3
Accuracy: 0.769
Perturbation Size:4
Accuracy: 0.769
Perturbation Size:5
Accuracy: 0.769
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.599024772644043
Epoch 10, training loss: 8.597084999084473
Epoch 20, training loss: 8.593465805053711
Epoch 30, training loss: 8.542461395263672
Epoch 40, training loss: 8.307846069335938
Epoch 50, training loss: 8.203238487243652
Epoch 60, training loss: 7.876404762268066
Epoch 70, training loss: 7.65471076965332
Epoch 80, training loss: 7.539522647857666
Epoch 90, training loss: 7.356274127960205
Epoch 100, training loss: 7.091604709625244
Epoch 110, training loss: 7.186720848083496
Epoch 120, training loss: 7.080104827880859
Epoch 130, training loss: 7.005874156951904
Epoch 140, training loss: 6.894932270050049
Epoch 150, training loss: 6.886960983276367
Epoch 160, training loss: 6.863002777099609
Epoch 170, training loss: 6.640878677368164
Epoch 180, training loss: 6.648186206817627
Epoch 190, training loss: 6.669567108154297
Epoch 200, training loss: 6.547271728515625
Epoch 210, training loss: 6.531669616699219
Epoch 220, training loss: 6.519798755645752
Epoch 230, training loss: 6.448938846588135
Epoch 240, training loss: 6.467176914215088
Epoch 250, training loss: 6.271692752838135
Epoch 260, training loss: 6.328893661499023
Epoch 270, training loss: 6.342465400695801
Epoch 280, training loss: 6.195639133453369
Epoch 290, training loss: 6.2767333984375
Epoch 300, training loss: 6.2497639656066895
Epoch 310, training loss: 6.295962333679199
Epoch 320, training loss: 6.31005859375
Epoch 330, training loss: 6.021733283996582
Epoch 340, training loss: 6.063154220581055
Epoch 350, training loss: 6.135641098022461
Epoch 360, training loss: 6.116495132446289
Epoch 370, training loss: 6.088854789733887
Epoch 380, training loss: 6.141345977783203
Epoch 390, training loss: 6.047261714935303
Epoch 400, training loss: 5.923108100891113
Epoch 410, training loss: 5.941298484802246
Epoch 420, training loss: 5.872745513916016
Epoch 430, training loss: 5.8376922607421875
Epoch 440, training loss: 5.910809516906738
Epoch 450, training loss: 5.889856815338135
Epoch 460, training loss: 5.836060523986816
Epoch 470, training loss: 5.888373374938965
Epoch 480, training loss: 5.866162300109863
Epoch 490, training loss: 5.852943420410156
random
Perturbation Size:0
Accuracy: 0.773
Perturbation Size:1
Accuracy: 0.773
Perturbation Size:2
Accuracy: 0.773
Perturbation Size:3
Accuracy: 0.773
Perturbation Size:4
Accuracy: 0.773
Perturbation Size:5
Accuracy: 0.773
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.59788990020752
Epoch 10, training loss: 8.59675407409668
Epoch 20, training loss: 8.59184741973877
Epoch 30, training loss: 8.517648696899414
Epoch 40, training loss: 8.229043960571289
Epoch 50, training loss: 7.987210273742676
Epoch 60, training loss: 7.7178754806518555
Epoch 70, training loss: 7.647097110748291
Epoch 80, training loss: 7.41618013381958
Epoch 90, training loss: 7.390055179595947
Epoch 100, training loss: 7.21511173248291
Epoch 110, training loss: 7.2093281745910645
Epoch 120, training loss: 7.133527755737305
Epoch 130, training loss: 7.244442462921143
Epoch 140, training loss: 6.927755355834961
Epoch 150, training loss: 6.976615905761719
Epoch 160, training loss: 6.867023468017578
Epoch 170, training loss: 6.798359394073486
Epoch 180, training loss: 6.681991100311279
Epoch 190, training loss: 6.720903396606445
Epoch 200, training loss: 6.677838325500488
Epoch 210, training loss: 6.593813419342041
Epoch 220, training loss: 6.443799018859863
Epoch 230, training loss: 6.471080303192139
Epoch 240, training loss: 6.456125259399414
Epoch 250, training loss: 6.589498996734619
Epoch 260, training loss: 6.39442777633667
Epoch 270, training loss: 6.3400678634643555
Epoch 280, training loss: 6.390025615692139
Epoch 290, training loss: 6.236587047576904
Epoch 300, training loss: 6.267127990722656
Epoch 310, training loss: 6.306309223175049
Epoch 320, training loss: 6.242162704467773
Epoch 330, training loss: 6.104513645172119
Epoch 340, training loss: 6.047860145568848
Epoch 350, training loss: 6.185633182525635
Epoch 360, training loss: 6.133194446563721
Epoch 370, training loss: 6.0745086669921875
Epoch 380, training loss: 6.096543788909912
Epoch 390, training loss: 5.949932098388672
Epoch 400, training loss: 6.046088218688965
Epoch 410, training loss: 6.0201334953308105
Epoch 420, training loss: 5.950535774230957
Epoch 430, training loss: 5.973411560058594
Epoch 440, training loss: 5.93593168258667
Epoch 450, training loss: 5.848884582519531
Epoch 460, training loss: 5.776984691619873
Epoch 470, training loss: 5.859786510467529
Epoch 480, training loss: 5.953001499176025
Epoch 490, training loss: 5.802862644195557
random
Perturbation Size:0
Accuracy: 0.808
Perturbation Size:1
Accuracy: 0.808
Perturbation Size:2
Accuracy: 0.808
Perturbation Size:3
Accuracy: 0.808
Perturbation Size:4
Accuracy: 0.808
Perturbation Size:5
Accuracy: 0.808
beta 0.7
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.597468376159668
Epoch 10, training loss: 8.59638786315918
Epoch 20, training loss: 8.594348907470703
Epoch 30, training loss: 8.570355415344238
Epoch 40, training loss: 8.24073314666748
Epoch 50, training loss: 7.992992877960205
Epoch 60, training loss: 7.820336818695068
Epoch 70, training loss: 7.68133020401001
Epoch 80, training loss: 7.563158988952637
Epoch 90, training loss: 7.3984880447387695
Epoch 100, training loss: 7.310368061065674
Epoch 110, training loss: 7.229047775268555
Epoch 120, training loss: 7.167965888977051
Epoch 130, training loss: 7.033332824707031
Epoch 140, training loss: 7.002234935760498
Epoch 150, training loss: 6.945763111114502
Epoch 160, training loss: 6.8402862548828125
Epoch 170, training loss: 6.850100994110107
Epoch 180, training loss: 6.685248374938965
Epoch 190, training loss: 6.721823692321777
Epoch 200, training loss: 6.562309265136719
Epoch 210, training loss: 6.5602498054504395
Epoch 220, training loss: 6.627203941345215
Epoch 230, training loss: 6.569382190704346
Epoch 240, training loss: 6.375990867614746
Epoch 250, training loss: 6.3648247718811035
Epoch 260, training loss: 6.349982261657715
Epoch 270, training loss: 6.381896495819092
Epoch 280, training loss: 6.476553916931152
Epoch 290, training loss: 6.312016010284424
Epoch 300, training loss: 6.223928451538086
Epoch 310, training loss: 6.30740213394165
Epoch 320, training loss: 6.175579071044922
Epoch 330, training loss: 6.2870635986328125
Epoch 340, training loss: 6.17917013168335
Epoch 350, training loss: 6.086978912353516
Epoch 360, training loss: 6.073644638061523
Epoch 370, training loss: 6.086429119110107
Epoch 380, training loss: 6.096339225769043
Epoch 390, training loss: 6.0322957038879395
Epoch 400, training loss: 6.034597396850586
Epoch 410, training loss: 6.060655117034912
Epoch 420, training loss: 6.022406578063965
Epoch 430, training loss: 5.974273204803467
Epoch 440, training loss: 6.0350565910339355
Epoch 450, training loss: 5.879830837249756
Epoch 460, training loss: 5.976147651672363
Epoch 470, training loss: 5.8388872146606445
Epoch 480, training loss: 5.846521377563477
Epoch 490, training loss: 5.8813605308532715
random
Perturbation Size:0
Accuracy: 0.777
Perturbation Size:1
Accuracy: 0.777
Perturbation Size:2
Accuracy: 0.777
Perturbation Size:3
Accuracy: 0.777
Perturbation Size:4
Accuracy: 0.777
Perturbation Size:5
Accuracy: 0.777
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.598420143127441
Epoch 10, training loss: 8.596689224243164
Epoch 20, training loss: 8.59412956237793
Epoch 30, training loss: 8.561844825744629
Epoch 40, training loss: 8.317183494567871
Epoch 50, training loss: 7.986464977264404
Epoch 60, training loss: 7.8284149169921875
Epoch 70, training loss: 7.612991809844971
Epoch 80, training loss: 7.5848307609558105
Epoch 90, training loss: 7.377368450164795
Epoch 100, training loss: 7.367442607879639
Epoch 110, training loss: 7.137096405029297
Epoch 120, training loss: 7.2007317543029785
Epoch 130, training loss: 7.086702823638916
Epoch 140, training loss: 7.061304092407227
Epoch 150, training loss: 6.931894302368164
Epoch 160, training loss: 6.956389427185059
Epoch 170, training loss: 6.804945468902588
Epoch 180, training loss: 6.785646438598633
Epoch 190, training loss: 6.6712517738342285
Epoch 200, training loss: 6.6089653968811035
Epoch 210, training loss: 6.590356349945068
Epoch 220, training loss: 6.5415449142456055
Epoch 230, training loss: 6.429593563079834
Epoch 240, training loss: 6.439123153686523
Epoch 250, training loss: 6.41263484954834
Epoch 260, training loss: 6.431719779968262
Epoch 270, training loss: 6.3228325843811035
Epoch 280, training loss: 6.190057277679443
Epoch 290, training loss: 6.225338935852051
Epoch 300, training loss: 6.272632598876953
Epoch 310, training loss: 6.215939998626709
Epoch 320, training loss: 6.08880090713501
Epoch 330, training loss: 6.194555282592773
Epoch 340, training loss: 6.140787124633789
Epoch 350, training loss: 6.044997692108154
Epoch 360, training loss: 6.058294296264648
Epoch 370, training loss: 6.0790510177612305
Epoch 380, training loss: 5.982227325439453
Epoch 390, training loss: 6.038047790527344
Epoch 400, training loss: 6.066577911376953
Epoch 410, training loss: 5.981714248657227
Epoch 420, training loss: 5.946196556091309
Epoch 430, training loss: 5.985665321350098
Epoch 440, training loss: 5.873603820800781
Epoch 450, training loss: 5.95642614364624
Epoch 460, training loss: 5.817251205444336
Epoch 470, training loss: 5.848363399505615
Epoch 480, training loss: 5.815458297729492
Epoch 490, training loss: 5.829415321350098
random
Perturbation Size:0
Accuracy: 0.773
Perturbation Size:1
Accuracy: 0.773
Perturbation Size:2
Accuracy: 0.773
Perturbation Size:3
Accuracy: 0.773
Perturbation Size:4
Accuracy: 0.773
Perturbation Size:5
Accuracy: 0.773
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.597983360290527
Epoch 10, training loss: 8.596467018127441
Epoch 20, training loss: 8.593883514404297
Epoch 30, training loss: 8.561721801757812
Epoch 40, training loss: 8.138439178466797
Epoch 50, training loss: 7.9278106689453125
Epoch 60, training loss: 7.688440322875977
Epoch 70, training loss: 7.542844772338867
Epoch 80, training loss: 7.420835018157959
Epoch 90, training loss: 7.393187999725342
Epoch 100, training loss: 7.30238151550293
Epoch 110, training loss: 7.085910797119141
Epoch 120, training loss: 7.047408580780029
Epoch 130, training loss: 7.2887091636657715
Epoch 140, training loss: 6.91640567779541
Epoch 150, training loss: 6.822432041168213
Epoch 160, training loss: 6.821174144744873
Epoch 170, training loss: 6.696408748626709
Epoch 180, training loss: 6.628708362579346
Epoch 190, training loss: 6.6517486572265625
Epoch 200, training loss: 6.702122211456299
Epoch 210, training loss: 6.551930904388428
Epoch 220, training loss: 6.6894450187683105
Epoch 230, training loss: 6.561692237854004
Epoch 240, training loss: 6.462923049926758
Epoch 250, training loss: 6.335721492767334
Epoch 260, training loss: 6.315467834472656
Epoch 270, training loss: 6.401516914367676
Epoch 280, training loss: 6.292087078094482
Epoch 290, training loss: 6.332757949829102
Epoch 300, training loss: 6.219000339508057
Epoch 310, training loss: 6.21305513381958
Epoch 320, training loss: 6.240993022918701
Epoch 330, training loss: 6.269400596618652
Epoch 340, training loss: 6.1660542488098145
Epoch 350, training loss: 6.187485218048096
Epoch 360, training loss: 6.182608604431152
Epoch 370, training loss: 6.1859941482543945
Epoch 380, training loss: 6.078841686248779
Epoch 390, training loss: 6.087167739868164
Epoch 400, training loss: 6.052220821380615
Epoch 410, training loss: 6.032005786895752
Epoch 420, training loss: 6.1017961502075195
Epoch 430, training loss: 5.960403919219971
Epoch 440, training loss: 5.987433433532715
Epoch 450, training loss: 6.00648832321167
Epoch 460, training loss: 5.9654364585876465
Epoch 470, training loss: 5.994734287261963
Epoch 480, training loss: 6.064177989959717
Epoch 490, training loss: 5.846009731292725
random
Perturbation Size:0
Accuracy: 0.769
Perturbation Size:1
Accuracy: 0.769
Perturbation Size:2
Accuracy: 0.769
Perturbation Size:3
Accuracy: 0.769
Perturbation Size:4
Accuracy: 0.769
Perturbation Size:5
Accuracy: 0.769
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.598812103271484
Epoch 10, training loss: 8.59619426727295
Epoch 20, training loss: 8.59045124053955
Epoch 30, training loss: 8.494845390319824
Epoch 40, training loss: 8.2190523147583
Epoch 50, training loss: 8.1550931930542
Epoch 60, training loss: 7.816744327545166
Epoch 70, training loss: 7.599219799041748
Epoch 80, training loss: 7.5796685218811035
Epoch 90, training loss: 7.254318714141846
Epoch 100, training loss: 7.276741981506348
Epoch 110, training loss: 7.250462055206299
Epoch 120, training loss: 7.1211628913879395
Epoch 130, training loss: 7.0341477394104
Epoch 140, training loss: 7.004724502563477
Epoch 150, training loss: 6.779961585998535
Epoch 160, training loss: 6.810271739959717
Epoch 170, training loss: 6.665403366088867
Epoch 180, training loss: 6.691553115844727
Epoch 190, training loss: 6.693897247314453
Epoch 200, training loss: 6.630405426025391
Epoch 210, training loss: 6.499986171722412
Epoch 220, training loss: 6.483823776245117
Epoch 230, training loss: 6.461244583129883
Epoch 240, training loss: 6.377039432525635
Epoch 250, training loss: 6.4113287925720215
Epoch 260, training loss: 6.317588806152344
Epoch 270, training loss: 6.4204888343811035
Epoch 280, training loss: 6.256600856781006
Epoch 290, training loss: 6.298311710357666
Epoch 300, training loss: 6.161556243896484
Epoch 310, training loss: 6.269749164581299
Epoch 320, training loss: 6.165724754333496
Epoch 330, training loss: 6.189652919769287
Epoch 340, training loss: 6.1830902099609375
Epoch 350, training loss: 6.0965166091918945
Epoch 360, training loss: 6.19874382019043
Epoch 370, training loss: 5.966598987579346
Epoch 380, training loss: 6.141630172729492
Epoch 390, training loss: 6.130039691925049
Epoch 400, training loss: 5.931298732757568
Epoch 410, training loss: 6.055139064788818
Epoch 420, training loss: 5.9480743408203125
Epoch 430, training loss: 5.981744289398193
Epoch 440, training loss: 5.906599521636963
Epoch 450, training loss: 5.884532451629639
Epoch 460, training loss: 5.870528221130371
Epoch 470, training loss: 5.864650249481201
Epoch 480, training loss: 5.79713249206543
Epoch 490, training loss: 5.810847282409668
random
Perturbation Size:0
Accuracy: 0.77
Perturbation Size:1
Accuracy: 0.77
Perturbation Size:2
Accuracy: 0.77
Perturbation Size:3
Accuracy: 0.77
Perturbation Size:4
Accuracy: 0.77
Perturbation Size:5
Accuracy: 0.77
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.598283767700195
Epoch 10, training loss: 8.596858024597168
Epoch 20, training loss: 8.593023300170898
Epoch 30, training loss: 8.545364379882812
Epoch 40, training loss: 8.33794116973877
Epoch 50, training loss: 7.936975002288818
Epoch 60, training loss: 7.905387878417969
Epoch 70, training loss: 7.639456272125244
Epoch 80, training loss: 7.37399959564209
Epoch 90, training loss: 7.221194744110107
Epoch 100, training loss: 7.152875900268555
Epoch 110, training loss: 7.202721118927002
Epoch 120, training loss: 7.010214328765869
Epoch 130, training loss: 6.923562049865723
Epoch 140, training loss: 6.946767330169678
Epoch 150, training loss: 6.8080973625183105
Epoch 160, training loss: 6.839502334594727
Epoch 170, training loss: 6.60170316696167
Epoch 180, training loss: 6.777096748352051
Epoch 190, training loss: 6.579005718231201
Epoch 200, training loss: 6.640630722045898
Epoch 210, training loss: 6.511396884918213
Epoch 220, training loss: 6.5553154945373535
Epoch 230, training loss: 6.512768745422363
Epoch 240, training loss: 6.431490421295166
Epoch 250, training loss: 6.3027215003967285
Epoch 260, training loss: 6.383678436279297
Epoch 270, training loss: 6.333332061767578
Epoch 280, training loss: 6.277249336242676
Epoch 290, training loss: 6.314723968505859
Epoch 300, training loss: 6.315345764160156
Epoch 310, training loss: 6.307979106903076
Epoch 320, training loss: 6.233024597167969
Epoch 330, training loss: 6.100976943969727
Epoch 340, training loss: 6.182231903076172
Epoch 350, training loss: 6.172381401062012
Epoch 360, training loss: 6.127567291259766
Epoch 370, training loss: 6.0420026779174805
Epoch 380, training loss: 6.042048454284668
Epoch 390, training loss: 6.058340549468994
Epoch 400, training loss: 6.068991661071777
Epoch 410, training loss: 6.08317232131958
Epoch 420, training loss: 6.069099426269531
Epoch 430, training loss: 6.085255146026611
Epoch 440, training loss: 5.898603439331055
Epoch 450, training loss: 5.974026203155518
Epoch 460, training loss: 5.9824724197387695
Epoch 470, training loss: 5.954470634460449
Epoch 480, training loss: 5.9493255615234375
Epoch 490, training loss: 5.973984718322754
random
Perturbation Size:0
Accuracy: 0.788
Perturbation Size:1
Accuracy: 0.788
Perturbation Size:2
Accuracy: 0.788
Perturbation Size:3
Accuracy: 0.788
Perturbation Size:4
Accuracy: 0.788
Perturbation Size:5
Accuracy: 0.788
beta 0.9
seed 265
=== training gcn model ===
Epoch 0, training loss: 8.598470687866211
Epoch 10, training loss: 8.596147537231445
Epoch 20, training loss: 8.592292785644531
Epoch 30, training loss: 8.50436019897461
Epoch 40, training loss: 8.263041496276855
Epoch 50, training loss: 8.157122611999512
Epoch 60, training loss: 7.9644670486450195
Epoch 70, training loss: 7.612503528594971
Epoch 80, training loss: 7.5370659828186035
Epoch 90, training loss: 7.587637424468994
Epoch 100, training loss: 7.42896032333374
Epoch 110, training loss: 7.258062839508057
Epoch 120, training loss: 7.0433349609375
Epoch 130, training loss: 7.1345319747924805
Epoch 140, training loss: 6.94893217086792
Epoch 150, training loss: 6.998316287994385
Epoch 160, training loss: 6.908670425415039
Epoch 170, training loss: 6.747966766357422
Epoch 180, training loss: 6.732799530029297
Epoch 190, training loss: 6.629231929779053
Epoch 200, training loss: 6.63503885269165
Epoch 210, training loss: 6.660536766052246
Epoch 220, training loss: 6.518509864807129
Epoch 230, training loss: 6.343924522399902
Epoch 240, training loss: 6.431286334991455
Epoch 250, training loss: 6.463580131530762
Epoch 260, training loss: 6.332899570465088
Epoch 270, training loss: 6.300209999084473
Epoch 280, training loss: 6.358363628387451
Epoch 290, training loss: 6.279853343963623
Epoch 300, training loss: 6.258406162261963
Epoch 310, training loss: 6.236421585083008
Epoch 320, training loss: 6.116664409637451
Epoch 330, training loss: 6.180737495422363
Epoch 340, training loss: 6.123739242553711
Epoch 350, training loss: 6.207098960876465
Epoch 360, training loss: 6.1148295402526855
Epoch 370, training loss: 6.050901412963867
Epoch 380, training loss: 6.166079044342041
Epoch 390, training loss: 6.018040180206299
Epoch 400, training loss: 6.046330451965332
Epoch 410, training loss: 5.911330223083496
Epoch 420, training loss: 5.964804172515869
Epoch 430, training loss: 5.9672136306762695
Epoch 440, training loss: 6.069520950317383
Epoch 450, training loss: 5.826355457305908
Epoch 460, training loss: 5.861040115356445
Epoch 470, training loss: 5.938579082489014
Epoch 480, training loss: 5.898476600646973
Epoch 490, training loss: 5.76806116104126
random
Perturbation Size:0
Accuracy: 0.794
Perturbation Size:1
Accuracy: 0.794
Perturbation Size:2
Accuracy: 0.794
Perturbation Size:3
Accuracy: 0.794
Perturbation Size:4
Accuracy: 0.794
Perturbation Size:5
Accuracy: 0.794
seed 125
=== training gcn model ===
Epoch 0, training loss: 8.598382949829102
Epoch 10, training loss: 8.596572875976562
Epoch 20, training loss: 8.594693183898926
Epoch 30, training loss: 8.561963081359863
Epoch 40, training loss: 8.305377006530762
Epoch 50, training loss: 7.994281768798828
Epoch 60, training loss: 7.868443965911865
Epoch 70, training loss: 7.734340190887451
Epoch 80, training loss: 7.611113548278809
Epoch 90, training loss: 7.5328826904296875
Epoch 100, training loss: 7.3961310386657715
Epoch 110, training loss: 7.382238388061523
Epoch 120, training loss: 7.270188808441162
Epoch 130, training loss: 7.06480073928833
Epoch 140, training loss: 6.999976634979248
Epoch 150, training loss: 6.991573810577393
Epoch 160, training loss: 6.923330307006836
Epoch 170, training loss: 6.804004192352295
Epoch 180, training loss: 6.671280384063721
Epoch 190, training loss: 6.592947006225586
Epoch 200, training loss: 6.581966400146484
Epoch 210, training loss: 6.600130081176758
Epoch 220, training loss: 6.484330177307129
Epoch 230, training loss: 6.490571975708008
Epoch 240, training loss: 6.4412055015563965
Epoch 250, training loss: 6.424309730529785
Epoch 260, training loss: 6.3816986083984375
Epoch 270, training loss: 6.290108680725098
Epoch 280, training loss: 6.2851152420043945
Epoch 290, training loss: 6.346148490905762
Epoch 300, training loss: 6.192971229553223
Epoch 310, training loss: 6.1280999183654785
Epoch 320, training loss: 6.249834060668945
Epoch 330, training loss: 6.154628753662109
Epoch 340, training loss: 6.088214874267578
Epoch 350, training loss: 6.102612018585205
Epoch 360, training loss: 5.997396945953369
Epoch 370, training loss: 6.02913236618042
Epoch 380, training loss: 6.035966873168945
Epoch 390, training loss: 5.949812412261963
Epoch 400, training loss: 6.023365020751953
Epoch 410, training loss: 5.960126876831055
Epoch 420, training loss: 5.959135055541992
Epoch 430, training loss: 5.978119373321533
Epoch 440, training loss: 5.932520389556885
Epoch 450, training loss: 6.0028839111328125
Epoch 460, training loss: 5.793667316436768
Epoch 470, training loss: 5.917572021484375
Epoch 480, training loss: 5.765629768371582
Epoch 490, training loss: 5.919332027435303
random
Perturbation Size:0
Accuracy: 0.793
Perturbation Size:1
Accuracy: 0.793
Perturbation Size:2
Accuracy: 0.793
Perturbation Size:3
Accuracy: 0.793
Perturbation Size:4
Accuracy: 0.793
Perturbation Size:5
Accuracy: 0.793
seed 996
=== training gcn model ===
Epoch 0, training loss: 8.598355293273926
Epoch 10, training loss: 8.59648609161377
Epoch 20, training loss: 8.595227241516113
Epoch 30, training loss: 8.572724342346191
Epoch 40, training loss: 8.450894355773926
Epoch 50, training loss: 8.16318130493164
Epoch 60, training loss: 7.910647869110107
Epoch 70, training loss: 7.645282745361328
Epoch 80, training loss: 7.41029167175293
Epoch 90, training loss: 7.26329231262207
Epoch 100, training loss: 7.201282978057861
Epoch 110, training loss: 7.092362403869629
Epoch 120, training loss: 6.993081569671631
Epoch 130, training loss: 7.000401020050049
Epoch 140, training loss: 6.793376922607422
Epoch 150, training loss: 6.829281806945801
Epoch 160, training loss: 6.725185394287109
Epoch 170, training loss: 6.694088935852051
Epoch 180, training loss: 6.770237922668457
Epoch 190, training loss: 6.626166820526123
Epoch 200, training loss: 6.509792327880859
Epoch 210, training loss: 6.57888650894165
Epoch 220, training loss: 6.538100242614746
Epoch 230, training loss: 6.294917583465576
Epoch 240, training loss: 6.287209987640381
Epoch 250, training loss: 6.405391693115234
Epoch 260, training loss: 6.370024681091309
Epoch 270, training loss: 6.219939231872559
Epoch 280, training loss: 6.166199207305908
Epoch 290, training loss: 6.269950866699219
Epoch 300, training loss: 6.210246562957764
Epoch 310, training loss: 6.197386741638184
Epoch 320, training loss: 6.111408710479736
Epoch 330, training loss: 6.106311798095703
Epoch 340, training loss: 6.154220104217529
Epoch 350, training loss: 6.065273761749268
Epoch 360, training loss: 6.047943592071533
Epoch 370, training loss: 6.043896675109863
Epoch 380, training loss: 6.104631423950195
Epoch 390, training loss: 6.064903259277344
Epoch 400, training loss: 5.897101879119873
Epoch 410, training loss: 5.949103832244873
Epoch 420, training loss: 5.9366631507873535
Epoch 430, training loss: 5.96333646774292
Epoch 440, training loss: 5.881476402282715
Epoch 450, training loss: 5.810183048248291
Epoch 460, training loss: 5.793649196624756
Epoch 470, training loss: 5.809168815612793
Epoch 480, training loss: 5.725645065307617
Epoch 490, training loss: 5.705796241760254
random
Perturbation Size:0
Accuracy: 0.805
Perturbation Size:1
Accuracy: 0.805
Perturbation Size:2
Accuracy: 0.805
Perturbation Size:3
Accuracy: 0.805
Perturbation Size:4
Accuracy: 0.805
Perturbation Size:5
Accuracy: 0.805
seed 527
=== training gcn model ===
Epoch 0, training loss: 8.598278999328613
Epoch 10, training loss: 8.596468925476074
Epoch 20, training loss: 8.59146785736084
Epoch 30, training loss: 8.511290550231934
Epoch 40, training loss: 8.21203899383545
Epoch 50, training loss: 7.825520992279053
Epoch 60, training loss: 7.6350250244140625
Epoch 70, training loss: 7.470032215118408
Epoch 80, training loss: 7.3646721839904785
Epoch 90, training loss: 7.336134910583496
Epoch 100, training loss: 7.1932454109191895
Epoch 110, training loss: 7.1698150634765625
Epoch 120, training loss: 7.134481430053711
Epoch 130, training loss: 6.955358028411865
Epoch 140, training loss: 6.88629674911499
Epoch 150, training loss: 6.856342792510986
Epoch 160, training loss: 6.876289367675781
Epoch 170, training loss: 6.689848899841309
Epoch 180, training loss: 6.696956157684326
Epoch 190, training loss: 6.550757884979248
Epoch 200, training loss: 6.601244926452637
Epoch 210, training loss: 6.621589660644531
Epoch 220, training loss: 6.524633407592773
Epoch 230, training loss: 6.536467552185059
Epoch 240, training loss: 6.473648548126221
Epoch 250, training loss: 6.357202529907227
Epoch 260, training loss: 6.289596080780029
Epoch 270, training loss: 6.291945934295654
Epoch 280, training loss: 6.372539043426514
Epoch 290, training loss: 6.310227870941162
Epoch 300, training loss: 6.208118915557861
Epoch 310, training loss: 6.2973480224609375
Epoch 320, training loss: 6.2055253982543945
Epoch 330, training loss: 6.249351978302002
Epoch 340, training loss: 6.222542762756348
Epoch 350, training loss: 6.1535162925720215
Epoch 360, training loss: 6.110562801361084
Epoch 370, training loss: 6.169272422790527
Epoch 380, training loss: 6.059213161468506
Epoch 390, training loss: 6.008358955383301
Epoch 400, training loss: 6.045275688171387
Epoch 410, training loss: 5.973652362823486
Epoch 420, training loss: 5.859354496002197
Epoch 430, training loss: 6.000843524932861
Epoch 440, training loss: 5.943028926849365
Epoch 450, training loss: 5.9487152099609375
Epoch 460, training loss: 5.848682403564453
Epoch 470, training loss: 5.861896514892578
Epoch 480, training loss: 5.894982814788818
Epoch 490, training loss: 5.873400688171387
random
Perturbation Size:0
Accuracy: 0.787
Perturbation Size:1
Accuracy: 0.787
Perturbation Size:2
Accuracy: 0.787
Perturbation Size:3
Accuracy: 0.787
Perturbation Size:4
Accuracy: 0.787
Perturbation Size:5
Accuracy: 0.787
seed 320
=== training gcn model ===
Epoch 0, training loss: 8.598639488220215
Epoch 10, training loss: 8.596174240112305
Epoch 20, training loss: 8.592812538146973
Epoch 30, training loss: 8.541729927062988
Epoch 40, training loss: 8.308160781860352
Epoch 50, training loss: 7.941182613372803
Epoch 60, training loss: 7.710656642913818
Epoch 70, training loss: 7.464909076690674
Epoch 80, training loss: 7.359203338623047
Epoch 90, training loss: 7.198265075683594
Epoch 100, training loss: 7.103776454925537
Epoch 110, training loss: 7.187248229980469
Epoch 120, training loss: 7.1667799949646
Epoch 130, training loss: 7.055750370025635
Epoch 140, training loss: 6.956785678863525
Epoch 150, training loss: 6.884467124938965
Epoch 160, training loss: 6.837404251098633
Epoch 170, training loss: 6.89980411529541
Epoch 180, training loss: 6.705119609832764
Epoch 190, training loss: 6.717884540557861
Epoch 200, training loss: 6.569579601287842
Epoch 210, training loss: 6.537082672119141
Epoch 220, training loss: 6.4781060218811035
Epoch 230, training loss: 6.598554611206055
Epoch 240, training loss: 6.513711929321289
Epoch 250, training loss: 6.4463725090026855
Epoch 260, training loss: 6.375960350036621
Epoch 270, training loss: 6.364648818969727
Epoch 280, training loss: 6.341157913208008
Epoch 290, training loss: 6.240065574645996
Epoch 300, training loss: 6.300388813018799
Epoch 310, training loss: 6.201356410980225
Epoch 320, training loss: 6.289115905761719
Epoch 330, training loss: 6.172694206237793
Epoch 340, training loss: 6.160258769989014
Epoch 350, training loss: 6.220901966094971
Epoch 360, training loss: 6.140997886657715
Epoch 370, training loss: 6.077490329742432
Epoch 380, training loss: 6.136496543884277
Epoch 390, training loss: 6.112694263458252
Epoch 400, training loss: 5.991755485534668
Epoch 410, training loss: 6.039377212524414
Epoch 420, training loss: 5.940826892852783
Epoch 430, training loss: 6.032077789306641
Epoch 440, training loss: 5.912563323974609
Epoch 450, training loss: 6.0131096839904785
Epoch 460, training loss: 5.821873188018799
Epoch 470, training loss: 5.964261054992676
Epoch 480, training loss: 5.864055633544922
Epoch 490, training loss: 5.795645236968994
random
Perturbation Size:0
Accuracy: 0.791
Perturbation Size:1
Accuracy: 0.791
Perturbation Size:2
Accuracy: 0.791
Perturbation Size:3
Accuracy: 0.791
Perturbation Size:4
Accuracy: 0.791
Perturbation Size:5
Accuracy: 0.791
