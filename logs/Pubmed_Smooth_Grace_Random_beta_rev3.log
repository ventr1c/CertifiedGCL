nohup: ignoring input
run_smooth_node.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Namespace(add_edge_rate_1=0, add_edge_rate_2=0, attack='random', base_model='GCN', cl_activation='relu', cl_base_model='GCNConv', cl_lr=0.0005, cl_num_epochs=200, cl_num_layers=2, cl_num_proj_hidden=128, cl_weight_decay=1e-05, clf_weight=1, config='config.yaml', cont_batch_size=0, cont_weight=1, cuda=True, dataset='Pubmed', debug=True, device_id=3, drop_edge_rate_1=0.2, drop_edge_rate_2=0, drop_feat_rate_1=0.3, drop_feat_rate_2=0.2, dropout=0.5, encoder_model='Grace', hidden=128, if_smoothed=True, inv_weight=1, no_cuda=False, noisy_level=0.3, num_hidden=128, num_proj_hidden=128, num_repeat=5, num_sample=20, prob=0.8, seed=10, select_target_ratio=0.1, tau=0.1, test_model='GCN', train_lr=0.01, weight_decay=0.0005)
beta 0.1
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.582045555114746
Epoch 10, training loss: 9.90535831451416
Epoch 20, training loss: 9.248571395874023
Epoch 30, training loss: 9.049432754516602
Epoch 40, training loss: 8.582871437072754
Epoch 50, training loss: 8.38355827331543
Epoch 60, training loss: 8.144940376281738
Epoch 70, training loss: 7.985143184661865
Epoch 80, training loss: 7.861327171325684
Epoch 90, training loss: 7.793769359588623
Epoch 100, training loss: 7.6676435470581055
Epoch 110, training loss: 7.630795955657959
Epoch 120, training loss: 7.635889530181885
Epoch 130, training loss: 7.557249069213867
Epoch 140, training loss: 7.500930309295654
Epoch 150, training loss: 7.428397178649902
Epoch 160, training loss: 7.342741966247559
Epoch 170, training loss: 7.326505184173584
Epoch 180, training loss: 7.290876865386963
Epoch 190, training loss: 7.212040424346924
Epoch 200, training loss: 7.211395263671875
Epoch 210, training loss: 7.179038047790527
Epoch 220, training loss: 7.180876731872559
Epoch 230, training loss: 7.16610050201416
Epoch 240, training loss: 7.095277786254883
Epoch 250, training loss: 7.044565677642822
Epoch 260, training loss: 7.0493998527526855
Epoch 270, training loss: 7.081099033355713
Epoch 280, training loss: 7.039200305938721
Epoch 290, training loss: 7.0428009033203125
Epoch 300, training loss: 6.9806084632873535
Epoch 310, training loss: 6.951564788818359
Epoch 320, training loss: 6.908854007720947
Epoch 330, training loss: 6.91264533996582
Epoch 340, training loss: 6.9015374183654785
Epoch 350, training loss: 6.864075183868408
Epoch 360, training loss: 6.837735176086426
Epoch 370, training loss: 6.86531925201416
Epoch 380, training loss: 6.851562023162842
Epoch 390, training loss: 6.766811370849609
Epoch 400, training loss: 6.846317768096924
Epoch 410, training loss: 6.790014743804932
Epoch 420, training loss: 6.780392646789551
Epoch 430, training loss: 6.76641845703125
Epoch 440, training loss: 6.753117084503174
Epoch 450, training loss: 6.8557257652282715
Epoch 460, training loss: 6.714060306549072
Epoch 470, training loss: 6.738455295562744
Epoch 480, training loss: 6.689487457275391
Epoch 490, training loss: 6.706409931182861
random
Accuracy: 0.772
Accuracy: 0.767
Accuracy: 0.731
Accuracy: 0.737
Accuracy: 0.683
Accuracy: 0.669
Accuracy: 0.655
Accuracy: 0.6
Accuracy: 0.583
Accuracy: 0.589
Accuracy: 0.561
Accuracy: 0.525
Accuracy: 0.524
Accuracy: 0.516
Accuracy: 0.52
Accuracy: 0.504
Accuracy: 0.501
Accuracy: 0.503
Accuracy: 0.488
Accuracy: 0.495
Accuracy: 0.502
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581899642944336
Epoch 10, training loss: 9.982012748718262
Epoch 20, training loss: 9.381606101989746
Epoch 30, training loss: 8.997719764709473
Epoch 40, training loss: 8.630083084106445
Epoch 50, training loss: 8.344404220581055
Epoch 60, training loss: 8.198500633239746
Epoch 70, training loss: 7.966868877410889
Epoch 80, training loss: 7.857364654541016
Epoch 90, training loss: 7.768274307250977
Epoch 100, training loss: 7.699440956115723
Epoch 110, training loss: 7.659653663635254
Epoch 120, training loss: 7.543318748474121
Epoch 130, training loss: 7.530335426330566
Epoch 140, training loss: 7.555971622467041
Epoch 150, training loss: 7.4161176681518555
Epoch 160, training loss: 7.35396671295166
Epoch 170, training loss: 7.398732662200928
Epoch 180, training loss: 7.264967918395996
Epoch 190, training loss: 7.23370885848999
Epoch 200, training loss: 7.173639297485352
Epoch 210, training loss: 7.075954437255859
Epoch 220, training loss: 7.0251078605651855
Epoch 230, training loss: 7.13526725769043
Epoch 240, training loss: 7.006980895996094
Epoch 250, training loss: 7.033310413360596
Epoch 260, training loss: 6.951826095581055
Epoch 270, training loss: 6.999255180358887
Epoch 280, training loss: 6.9160685539245605
Epoch 290, training loss: 7.019434452056885
Epoch 300, training loss: 6.9392499923706055
Epoch 310, training loss: 6.829831123352051
Epoch 320, training loss: 6.862448215484619
Epoch 330, training loss: 6.847153663635254
Epoch 340, training loss: 6.804798126220703
Epoch 350, training loss: 6.88833475112915
Epoch 360, training loss: 6.890763759613037
Epoch 370, training loss: 6.843129634857178
Epoch 380, training loss: 6.7923970222473145
Epoch 390, training loss: 6.847688674926758
Epoch 400, training loss: 6.771091461181641
Epoch 410, training loss: 6.701181411743164
Epoch 420, training loss: 6.697822570800781
Epoch 430, training loss: 6.770895957946777
Epoch 440, training loss: 6.731188774108887
Epoch 450, training loss: 6.717416286468506
Epoch 460, training loss: 6.715264797210693
Epoch 470, training loss: 6.714687824249268
Epoch 480, training loss: 6.623201370239258
Epoch 490, training loss: 6.654192924499512
random
Accuracy: 0.78
Accuracy: 0.77
Accuracy: 0.731
Accuracy: 0.729
Accuracy: 0.656
Accuracy: 0.637
Accuracy: 0.616
Accuracy: 0.556
Accuracy: 0.533
Accuracy: 0.523
Accuracy: 0.512
Accuracy: 0.473
Accuracy: 0.473
Accuracy: 0.473
Accuracy: 0.473
Accuracy: 0.454
Accuracy: 0.449
Accuracy: 0.462
Accuracy: 0.447
Accuracy: 0.453
Accuracy: 0.46
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.58178997039795
Epoch 10, training loss: 9.837766647338867
Epoch 20, training loss: 9.281448364257812
Epoch 30, training loss: 9.00367259979248
Epoch 40, training loss: 8.574067115783691
Epoch 50, training loss: 8.272927284240723
Epoch 60, training loss: 8.07331371307373
Epoch 70, training loss: 7.946143627166748
Epoch 80, training loss: 7.787304401397705
Epoch 90, training loss: 7.736178874969482
Epoch 100, training loss: 7.620240688323975
Epoch 110, training loss: 7.6156697273254395
Epoch 120, training loss: 7.522556781768799
Epoch 130, training loss: 7.482053756713867
Epoch 140, training loss: 7.402822494506836
Epoch 150, training loss: 7.389918804168701
Epoch 160, training loss: 7.315646171569824
Epoch 170, training loss: 7.353634357452393
Epoch 180, training loss: 7.1882243156433105
Epoch 190, training loss: 7.203187942504883
Epoch 200, training loss: 7.117257118225098
Epoch 210, training loss: 7.154440879821777
Epoch 220, training loss: 7.1154913902282715
Epoch 230, training loss: 7.0940375328063965
Epoch 240, training loss: 7.047379970550537
Epoch 250, training loss: 7.053550720214844
Epoch 260, training loss: 6.914914131164551
Epoch 270, training loss: 6.927831172943115
Epoch 280, training loss: 6.960542678833008
Epoch 290, training loss: 6.915922164916992
Epoch 300, training loss: 6.939664363861084
Epoch 310, training loss: 6.907897472381592
Epoch 320, training loss: 6.86365270614624
Epoch 330, training loss: 6.861972808837891
Epoch 340, training loss: 6.815382480621338
Epoch 350, training loss: 6.835455417633057
Epoch 360, training loss: 6.8013787269592285
Epoch 370, training loss: 6.795708656311035
Epoch 380, training loss: 6.731842994689941
Epoch 390, training loss: 6.752198219299316
Epoch 400, training loss: 6.785178184509277
Epoch 410, training loss: 6.726383209228516
Epoch 420, training loss: 6.752607345581055
Epoch 430, training loss: 6.725747585296631
Epoch 440, training loss: 6.650516033172607
Epoch 450, training loss: 6.73372745513916
Epoch 460, training loss: 6.766401767730713
Epoch 470, training loss: 6.67242431640625
Epoch 480, training loss: 6.670896530151367
Epoch 490, training loss: 6.655432224273682
random
Accuracy: 0.759
Accuracy: 0.746
Accuracy: 0.719
Accuracy: 0.72
Accuracy: 0.64
Accuracy: 0.621
Accuracy: 0.595
Accuracy: 0.56
Accuracy: 0.558
Accuracy: 0.563
Accuracy: 0.551
Accuracy: 0.522
Accuracy: 0.531
Accuracy: 0.527
Accuracy: 0.54
Accuracy: 0.535
Accuracy: 0.563
Accuracy: 0.572
Accuracy: 0.566
Accuracy: 0.58
Accuracy: 0.579
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581915855407715
Epoch 10, training loss: 9.857324600219727
Epoch 20, training loss: 9.20847225189209
Epoch 30, training loss: 8.816872596740723
Epoch 40, training loss: 8.530142784118652
Epoch 50, training loss: 8.372418403625488
Epoch 60, training loss: 8.207318305969238
Epoch 70, training loss: 7.984768867492676
Epoch 80, training loss: 7.912924289703369
Epoch 90, training loss: 7.725111961364746
Epoch 100, training loss: 7.567980766296387
Epoch 110, training loss: 7.449737548828125
Epoch 120, training loss: 7.371070384979248
Epoch 130, training loss: 7.311942100524902
Epoch 140, training loss: 7.250947952270508
Epoch 150, training loss: 7.265706539154053
Epoch 160, training loss: 7.136250019073486
Epoch 170, training loss: 7.032379150390625
Epoch 180, training loss: 7.041013240814209
Epoch 190, training loss: 7.091737270355225
Epoch 200, training loss: 7.106337547302246
Epoch 210, training loss: 7.001495361328125
Epoch 220, training loss: 7.01722526550293
Epoch 230, training loss: 6.9832282066345215
Epoch 240, training loss: 6.923218250274658
Epoch 250, training loss: 6.944277286529541
Epoch 260, training loss: 7.022705554962158
Epoch 270, training loss: 6.873098373413086
Epoch 280, training loss: 6.837811470031738
Epoch 290, training loss: 6.832036018371582
Epoch 300, training loss: 6.832575798034668
Epoch 310, training loss: 6.823055744171143
Epoch 320, training loss: 6.775679111480713
Epoch 330, training loss: 6.834766864776611
Epoch 340, training loss: 6.778108596801758
Epoch 350, training loss: 6.806680202484131
Epoch 360, training loss: 6.779635906219482
Epoch 370, training loss: 6.759463787078857
Epoch 380, training loss: 6.785860538482666
Epoch 390, training loss: 6.796530246734619
Epoch 400, training loss: 6.742492198944092
Epoch 410, training loss: 6.87247371673584
Epoch 420, training loss: 6.72699499130249
Epoch 430, training loss: 6.766486644744873
Epoch 440, training loss: 6.698145389556885
Epoch 450, training loss: 6.718607425689697
Epoch 460, training loss: 6.68271541595459
Epoch 470, training loss: 6.707760334014893
Epoch 480, training loss: 6.702108383178711
Epoch 490, training loss: 6.5937628746032715
random
Accuracy: 0.74
Accuracy: 0.73
Accuracy: 0.718
Accuracy: 0.718
Accuracy: 0.647
Accuracy: 0.632
Accuracy: 0.611
Accuracy: 0.547
Accuracy: 0.53
Accuracy: 0.518
Accuracy: 0.473
Accuracy: 0.453
Accuracy: 0.448
Accuracy: 0.45
Accuracy: 0.446
Accuracy: 0.429
Accuracy: 0.429
Accuracy: 0.417
Accuracy: 0.406
Accuracy: 0.408
Accuracy: 0.408
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.58193588256836
Epoch 10, training loss: 9.96203327178955
Epoch 20, training loss: 9.208903312683105
Epoch 30, training loss: 8.67526626586914
Epoch 40, training loss: 8.384976387023926
Epoch 50, training loss: 8.17650032043457
Epoch 60, training loss: 8.000797271728516
Epoch 70, training loss: 7.88239860534668
Epoch 80, training loss: 7.729122638702393
Epoch 90, training loss: 7.754339694976807
Epoch 100, training loss: 7.635961532592773
Epoch 110, training loss: 7.639902591705322
Epoch 120, training loss: 7.557690620422363
Epoch 130, training loss: 7.537147521972656
Epoch 140, training loss: 7.58830451965332
Epoch 150, training loss: 7.489094257354736
Epoch 160, training loss: 7.491947174072266
Epoch 170, training loss: 7.462735176086426
Epoch 180, training loss: 7.327783584594727
Epoch 190, training loss: 7.373514175415039
Epoch 200, training loss: 7.3209381103515625
Epoch 210, training loss: 7.211987018585205
Epoch 220, training loss: 7.257558822631836
Epoch 230, training loss: 7.169682502746582
Epoch 240, training loss: 7.190240383148193
Epoch 250, training loss: 7.114623546600342
Epoch 260, training loss: 7.1321797370910645
Epoch 270, training loss: 7.050095081329346
Epoch 280, training loss: 7.024942874908447
Epoch 290, training loss: 7.038728713989258
Epoch 300, training loss: 7.02792501449585
Epoch 310, training loss: 7.0143327713012695
Epoch 320, training loss: 6.936812400817871
Epoch 330, training loss: 6.8907623291015625
Epoch 340, training loss: 6.935251235961914
Epoch 350, training loss: 6.893650054931641
Epoch 360, training loss: 6.9806132316589355
Epoch 370, training loss: 6.867489337921143
Epoch 380, training loss: 6.863063812255859
Epoch 390, training loss: 6.878735542297363
Epoch 400, training loss: 6.92806339263916
Epoch 410, training loss: 6.785951137542725
Epoch 420, training loss: 6.848876476287842
Epoch 430, training loss: 6.798036098480225
Epoch 440, training loss: 6.77580451965332
Epoch 450, training loss: 6.719931602478027
Epoch 460, training loss: 6.7772932052612305
Epoch 470, training loss: 6.775424003601074
Epoch 480, training loss: 6.684471130371094
Epoch 490, training loss: 6.723894119262695
random
Accuracy: 0.784
Accuracy: 0.777
Accuracy: 0.763
Accuracy: 0.759
Accuracy: 0.753
Accuracy: 0.75
Accuracy: 0.735
Accuracy: 0.677
Accuracy: 0.686
Accuracy: 0.672
Accuracy: 0.646
Accuracy: 0.617
Accuracy: 0.616
Accuracy: 0.626
Accuracy: 0.621
Accuracy: 0.612
Accuracy: 0.61
Accuracy: 0.616
Accuracy: 0.61
Accuracy: 0.605
Accuracy: 0.612
Beta:0.1 Ptb size:0 Accuracy:0.7670+-0.0160
Beta:0.1 Ptb size:1 Accuracy:0.7580+-0.0174
Beta:0.1 Ptb size:2 Accuracy:0.7324+-0.0163
Beta:0.1 Ptb size:3 Accuracy:0.7326+-0.0148
Beta:0.1 Ptb size:4 Accuracy:0.6758+-0.0413
Beta:0.1 Ptb size:5 Accuracy:0.6618+-0.0469
Beta:0.1 Ptb size:6 Accuracy:0.6424+-0.0503
Beta:0.1 Ptb size:7 Accuracy:0.5880+-0.0481
Beta:0.1 Ptb size:8 Accuracy:0.5780+-0.0573
Beta:0.1 Ptb size:9 Accuracy:0.5730+-0.0560
Beta:0.1 Ptb size:10 Accuracy:0.5486+-0.0578
Beta:0.1 Ptb size:11 Accuracy:0.5180+-0.0568
Beta:0.1 Ptb size:12 Accuracy:0.5184+-0.0579
Beta:0.1 Ptb size:13 Accuracy:0.5184+-0.0607
Beta:0.1 Ptb size:14 Accuracy:0.5200+-0.0605
Beta:0.1 Ptb size:15 Accuracy:0.5068+-0.0644
Beta:0.1 Ptb size:16 Accuracy:0.5104+-0.0681
Beta:0.1 Ptb size:17 Accuracy:0.5140+-0.0721
Beta:0.1 Ptb size:18 Accuracy:0.5034+-0.0751
Beta:0.1 Ptb size:19 Accuracy:0.5082+-0.0745
Beta:0.1 Ptb size:20 Accuracy:0.5122+-0.0750
beta 0.2
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581916809082031
Epoch 10, training loss: 9.8416166305542
Epoch 20, training loss: 9.222222328186035
Epoch 30, training loss: 9.001489639282227
Epoch 40, training loss: 8.535279273986816
Epoch 50, training loss: 8.329070091247559
Epoch 60, training loss: 8.112363815307617
Epoch 70, training loss: 7.949506759643555
Epoch 80, training loss: 7.845088481903076
Epoch 90, training loss: 7.764223098754883
Epoch 100, training loss: 7.648707389831543
Epoch 110, training loss: 7.612737655639648
Epoch 120, training loss: 7.6323161125183105
Epoch 130, training loss: 7.562236785888672
Epoch 140, training loss: 7.508940696716309
Epoch 150, training loss: 7.455676078796387
Epoch 160, training loss: 7.374686241149902
Epoch 170, training loss: 7.355391502380371
Epoch 180, training loss: 7.320835113525391
Epoch 190, training loss: 7.214249610900879
Epoch 200, training loss: 7.21674919128418
Epoch 210, training loss: 7.185376167297363
Epoch 220, training loss: 7.176610946655273
Epoch 230, training loss: 7.187067985534668
Epoch 240, training loss: 7.091629505157471
Epoch 250, training loss: 7.045408248901367
Epoch 260, training loss: 7.054417610168457
Epoch 270, training loss: 7.097688674926758
Epoch 280, training loss: 7.047423362731934
Epoch 290, training loss: 7.096532344818115
Epoch 300, training loss: 7.007978439331055
Epoch 310, training loss: 6.9664740562438965
Epoch 320, training loss: 6.913733959197998
Epoch 330, training loss: 6.938474655151367
Epoch 340, training loss: 6.911842346191406
Epoch 350, training loss: 6.883026123046875
Epoch 360, training loss: 6.841203689575195
Epoch 370, training loss: 6.868772029876709
Epoch 380, training loss: 6.863103866577148
Epoch 390, training loss: 6.781221389770508
Epoch 400, training loss: 6.850963115692139
Epoch 410, training loss: 6.793266773223877
Epoch 420, training loss: 6.785339832305908
Epoch 430, training loss: 6.777931213378906
Epoch 440, training loss: 6.7641425132751465
Epoch 450, training loss: 6.852606773376465
Epoch 460, training loss: 6.709267616271973
Epoch 470, training loss: 6.754563331604004
Epoch 480, training loss: 6.689383029937744
Epoch 490, training loss: 6.693532466888428
random
Accuracy: 0.743
Accuracy: 0.74
Accuracy: 0.726
Accuracy: 0.723
Accuracy: 0.684
Accuracy: 0.667
Accuracy: 0.64
Accuracy: 0.59
Accuracy: 0.577
Accuracy: 0.57
Accuracy: 0.552
Accuracy: 0.512
Accuracy: 0.506
Accuracy: 0.498
Accuracy: 0.495
Accuracy: 0.472
Accuracy: 0.473
Accuracy: 0.48
Accuracy: 0.481
Accuracy: 0.488
Accuracy: 0.483
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581807136535645
Epoch 10, training loss: 9.928666114807129
Epoch 20, training loss: 9.341416358947754
Epoch 30, training loss: 8.982637405395508
Epoch 40, training loss: 8.618090629577637
Epoch 50, training loss: 8.337474822998047
Epoch 60, training loss: 8.191356658935547
Epoch 70, training loss: 7.957291126251221
Epoch 80, training loss: 7.833817481994629
Epoch 90, training loss: 7.750903606414795
Epoch 100, training loss: 7.67508602142334
Epoch 110, training loss: 7.656610012054443
Epoch 120, training loss: 7.541994094848633
Epoch 130, training loss: 7.516369819641113
Epoch 140, training loss: 7.5567216873168945
Epoch 150, training loss: 7.43120813369751
Epoch 160, training loss: 7.364840507507324
Epoch 170, training loss: 7.4084601402282715
Epoch 180, training loss: 7.289394855499268
Epoch 190, training loss: 7.262709617614746
Epoch 200, training loss: 7.196985244750977
Epoch 210, training loss: 7.112121105194092
Epoch 220, training loss: 7.076240062713623
Epoch 230, training loss: 7.153768062591553
Epoch 240, training loss: 7.053488254547119
Epoch 250, training loss: 7.053414344787598
Epoch 260, training loss: 6.963428020477295
Epoch 270, training loss: 7.0135393142700195
Epoch 280, training loss: 6.920125961303711
Epoch 290, training loss: 7.021437644958496
Epoch 300, training loss: 6.961546421051025
Epoch 310, training loss: 6.854925632476807
Epoch 320, training loss: 6.884381294250488
Epoch 330, training loss: 6.869070053100586
Epoch 340, training loss: 6.812473297119141
Epoch 350, training loss: 6.88390588760376
Epoch 360, training loss: 6.885013580322266
Epoch 370, training loss: 6.830819606781006
Epoch 380, training loss: 6.771535873413086
Epoch 390, training loss: 6.818546772003174
Epoch 400, training loss: 6.738740921020508
Epoch 410, training loss: 6.678313732147217
Epoch 420, training loss: 6.684445858001709
Epoch 430, training loss: 6.755146503448486
Epoch 440, training loss: 6.702206611633301
Epoch 450, training loss: 6.686404228210449
Epoch 460, training loss: 6.687560558319092
Epoch 470, training loss: 6.691519260406494
Epoch 480, training loss: 6.600654602050781
Epoch 490, training loss: 6.628543853759766
random
Accuracy: 0.772
Accuracy: 0.766
Accuracy: 0.735
Accuracy: 0.728
Accuracy: 0.662
Accuracy: 0.629
Accuracy: 0.611
Accuracy: 0.562
Accuracy: 0.542
Accuracy: 0.54
Accuracy: 0.515
Accuracy: 0.478
Accuracy: 0.479
Accuracy: 0.475
Accuracy: 0.478
Accuracy: 0.457
Accuracy: 0.45
Accuracy: 0.453
Accuracy: 0.446
Accuracy: 0.438
Accuracy: 0.437
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581701278686523
Epoch 10, training loss: 9.800098419189453
Epoch 20, training loss: 9.250328063964844
Epoch 30, training loss: 8.946639060974121
Epoch 40, training loss: 8.48213005065918
Epoch 50, training loss: 8.215387344360352
Epoch 60, training loss: 8.016728401184082
Epoch 70, training loss: 7.9126691818237305
Epoch 80, training loss: 7.759390830993652
Epoch 90, training loss: 7.705816268920898
Epoch 100, training loss: 7.606779098510742
Epoch 110, training loss: 7.6340436935424805
Epoch 120, training loss: 7.555900573730469
Epoch 130, training loss: 7.495131015777588
Epoch 140, training loss: 7.448068618774414
Epoch 150, training loss: 7.437708377838135
Epoch 160, training loss: 7.351756572723389
Epoch 170, training loss: 7.381449222564697
Epoch 180, training loss: 7.221858978271484
Epoch 190, training loss: 7.236271381378174
Epoch 200, training loss: 7.151747226715088
Epoch 210, training loss: 7.1852288246154785
Epoch 220, training loss: 7.161038398742676
Epoch 230, training loss: 7.1503424644470215
Epoch 240, training loss: 7.121359348297119
Epoch 250, training loss: 7.119809627532959
Epoch 260, training loss: 6.997332572937012
Epoch 270, training loss: 7.008710861206055
Epoch 280, training loss: 7.024304389953613
Epoch 290, training loss: 6.979208469390869
Epoch 300, training loss: 7.018242835998535
Epoch 310, training loss: 6.973135471343994
Epoch 320, training loss: 6.971647262573242
Epoch 330, training loss: 6.907641887664795
Epoch 340, training loss: 6.85643196105957
Epoch 350, training loss: 6.86736536026001
Epoch 360, training loss: 6.81850528717041
Epoch 370, training loss: 6.819293022155762
Epoch 380, training loss: 6.750707149505615
Epoch 390, training loss: 6.779858589172363
Epoch 400, training loss: 6.792296886444092
Epoch 410, training loss: 6.75016975402832
Epoch 420, training loss: 6.760550022125244
Epoch 430, training loss: 6.723464488983154
Epoch 440, training loss: 6.670785427093506
Epoch 450, training loss: 6.727470397949219
Epoch 460, training loss: 6.780383110046387
Epoch 470, training loss: 6.681899070739746
Epoch 480, training loss: 6.669881343841553
Epoch 490, training loss: 6.666141510009766
random
Accuracy: 0.766
Accuracy: 0.753
Accuracy: 0.733
Accuracy: 0.736
Accuracy: 0.696
Accuracy: 0.66
Accuracy: 0.635
Accuracy: 0.6
Accuracy: 0.598
Accuracy: 0.597
Accuracy: 0.578
Accuracy: 0.547
Accuracy: 0.548
Accuracy: 0.54
Accuracy: 0.552
Accuracy: 0.539
Accuracy: 0.546
Accuracy: 0.562
Accuracy: 0.568
Accuracy: 0.584
Accuracy: 0.58
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581820487976074
Epoch 10, training loss: 9.80840015411377
Epoch 20, training loss: 9.181408882141113
Epoch 30, training loss: 8.782258033752441
Epoch 40, training loss: 8.50279712677002
Epoch 50, training loss: 8.340370178222656
Epoch 60, training loss: 8.208725929260254
Epoch 70, training loss: 7.9866108894348145
Epoch 80, training loss: 7.915957927703857
Epoch 90, training loss: 7.746495723724365
Epoch 100, training loss: 7.574227809906006
Epoch 110, training loss: 7.472637176513672
Epoch 120, training loss: 7.375231742858887
Epoch 130, training loss: 7.2931671142578125
Epoch 140, training loss: 7.244454383850098
Epoch 150, training loss: 7.252202987670898
Epoch 160, training loss: 7.133110046386719
Epoch 170, training loss: 7.02707052230835
Epoch 180, training loss: 7.041506767272949
Epoch 190, training loss: 7.086388111114502
Epoch 200, training loss: 7.087111473083496
Epoch 210, training loss: 7.000932693481445
Epoch 220, training loss: 7.008594512939453
Epoch 230, training loss: 6.981957912445068
Epoch 240, training loss: 6.929333209991455
Epoch 250, training loss: 6.9237589836120605
Epoch 260, training loss: 7.010936260223389
Epoch 270, training loss: 6.863574504852295
Epoch 280, training loss: 6.840986728668213
Epoch 290, training loss: 6.826204776763916
Epoch 300, training loss: 6.832911014556885
Epoch 310, training loss: 6.810401439666748
Epoch 320, training loss: 6.777331352233887
Epoch 330, training loss: 6.837026119232178
Epoch 340, training loss: 6.771533012390137
Epoch 350, training loss: 6.801450729370117
Epoch 360, training loss: 6.757706165313721
Epoch 370, training loss: 6.749441623687744
Epoch 380, training loss: 6.7627129554748535
Epoch 390, training loss: 6.766168117523193
Epoch 400, training loss: 6.716742992401123
Epoch 410, training loss: 6.846601486206055
Epoch 420, training loss: 6.704371452331543
Epoch 430, training loss: 6.719008445739746
Epoch 440, training loss: 6.6620659828186035
Epoch 450, training loss: 6.6957011222839355
Epoch 460, training loss: 6.654844284057617
Epoch 470, training loss: 6.6829514503479
Epoch 480, training loss: 6.658242225646973
Epoch 490, training loss: 6.567651271820068
random
Accuracy: 0.739
Accuracy: 0.729
Accuracy: 0.72
Accuracy: 0.719
Accuracy: 0.677
Accuracy: 0.655
Accuracy: 0.624
Accuracy: 0.582
Accuracy: 0.575
Accuracy: 0.56
Accuracy: 0.523
Accuracy: 0.484
Accuracy: 0.469
Accuracy: 0.473
Accuracy: 0.473
Accuracy: 0.444
Accuracy: 0.446
Accuracy: 0.442
Accuracy: 0.434
Accuracy: 0.434
Accuracy: 0.433
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.581851959228516
Epoch 10, training loss: 9.932523727416992
Epoch 20, training loss: 9.184086799621582
Epoch 30, training loss: 8.660103797912598
Epoch 40, training loss: 8.36893081665039
Epoch 50, training loss: 8.145696640014648
Epoch 60, training loss: 7.972165584564209
Epoch 70, training loss: 7.858095169067383
Epoch 80, training loss: 7.701184272766113
Epoch 90, training loss: 7.73368501663208
Epoch 100, training loss: 7.615278244018555
Epoch 110, training loss: 7.620140552520752
Epoch 120, training loss: 7.51765775680542
Epoch 130, training loss: 7.4792399406433105
Epoch 140, training loss: 7.51106071472168
Epoch 150, training loss: 7.383939266204834
Epoch 160, training loss: 7.371288776397705
Epoch 170, training loss: 7.309457778930664
Epoch 180, training loss: 7.189791679382324
Epoch 190, training loss: 7.237411022186279
Epoch 200, training loss: 7.185323238372803
Epoch 210, training loss: 7.119935512542725
Epoch 220, training loss: 7.178385257720947
Epoch 230, training loss: 7.129361629486084
Epoch 240, training loss: 7.145507335662842
Epoch 250, training loss: 7.078165531158447
Epoch 260, training loss: 7.117414474487305
Epoch 270, training loss: 7.044318675994873
Epoch 280, training loss: 7.030269145965576
Epoch 290, training loss: 7.039336204528809
Epoch 300, training loss: 7.032845497131348
Epoch 310, training loss: 7.022818088531494
Epoch 320, training loss: 6.979076862335205
Epoch 330, training loss: 6.9457221031188965
Epoch 340, training loss: 6.989969253540039
Epoch 350, training loss: 6.968029022216797
Epoch 360, training loss: 7.046029567718506
Epoch 370, training loss: 6.9418840408325195
Epoch 380, training loss: 6.946011066436768
Epoch 390, training loss: 6.965723037719727
Epoch 400, training loss: 6.995677947998047
Epoch 410, training loss: 6.902572154998779
Epoch 420, training loss: 6.941949844360352
Epoch 430, training loss: 6.917572975158691
Epoch 440, training loss: 6.899531364440918
Epoch 450, training loss: 6.835792064666748
Epoch 460, training loss: 6.904099941253662
Epoch 470, training loss: 6.873383522033691
Epoch 480, training loss: 6.796982765197754
Epoch 490, training loss: 6.841338634490967
random
Accuracy: 0.797
Accuracy: 0.792
Accuracy: 0.778
Accuracy: 0.773
Accuracy: 0.767
Accuracy: 0.767
Accuracy: 0.754
Accuracy: 0.727
Accuracy: 0.72
Accuracy: 0.721
Accuracy: 0.703
Accuracy: 0.679
Accuracy: 0.683
Accuracy: 0.685
Accuracy: 0.686
Accuracy: 0.674
Accuracy: 0.669
Accuracy: 0.669
Accuracy: 0.663
Accuracy: 0.653
Accuracy: 0.645
Beta:0.2 Ptb size:0 Accuracy:0.7634+-0.0211
Beta:0.2 Ptb size:1 Accuracy:0.7560+-0.0219
Beta:0.2 Ptb size:2 Accuracy:0.7384+-0.0205
Beta:0.2 Ptb size:3 Accuracy:0.7358+-0.0194
Beta:0.2 Ptb size:4 Accuracy:0.6972+-0.0366
Beta:0.2 Ptb size:5 Accuracy:0.6756+-0.0475
Beta:0.2 Ptb size:6 Accuracy:0.6528+-0.0516
Beta:0.2 Ptb size:7 Accuracy:0.6122+-0.0587
Beta:0.2 Ptb size:8 Accuracy:0.6024+-0.0615
Beta:0.2 Ptb size:9 Accuracy:0.5976+-0.0644
Beta:0.2 Ptb size:10 Accuracy:0.5742+-0.0682
Beta:0.2 Ptb size:11 Accuracy:0.5400+-0.0737
Beta:0.2 Ptb size:12 Accuracy:0.5370+-0.0780
Beta:0.2 Ptb size:13 Accuracy:0.5342+-0.0792
Beta:0.2 Ptb size:14 Accuracy:0.5368+-0.0797
Beta:0.2 Ptb size:15 Accuracy:0.5172+-0.0850
Beta:0.2 Ptb size:16 Accuracy:0.5168+-0.0842
Beta:0.2 Ptb size:17 Accuracy:0.5212+-0.0850
Beta:0.2 Ptb size:18 Accuracy:0.5184+-0.0862
Beta:0.2 Ptb size:19 Accuracy:0.5194+-0.0859
Beta:0.2 Ptb size:20 Accuracy:0.5156+-0.0836
beta 0.3
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581785202026367
Epoch 10, training loss: 9.79354476928711
Epoch 20, training loss: 9.17738151550293
Epoch 30, training loss: 8.889506340026855
Epoch 40, training loss: 8.48965835571289
Epoch 50, training loss: 8.325206756591797
Epoch 60, training loss: 8.110352516174316
Epoch 70, training loss: 7.9393086433410645
Epoch 80, training loss: 7.8111958503723145
Epoch 90, training loss: 7.741111755371094
Epoch 100, training loss: 7.618825435638428
Epoch 110, training loss: 7.567594051361084
Epoch 120, training loss: 7.587388038635254
Epoch 130, training loss: 7.537797451019287
Epoch 140, training loss: 7.498030185699463
Epoch 150, training loss: 7.4531402587890625
Epoch 160, training loss: 7.403371810913086
Epoch 170, training loss: 7.382999420166016
Epoch 180, training loss: 7.367946624755859
Epoch 190, training loss: 7.25551700592041
Epoch 200, training loss: 7.2630181312561035
Epoch 210, training loss: 7.201830863952637
Epoch 220, training loss: 7.178494453430176
Epoch 230, training loss: 7.197344779968262
Epoch 240, training loss: 7.090324878692627
Epoch 250, training loss: 7.0425519943237305
Epoch 260, training loss: 7.033483028411865
Epoch 270, training loss: 7.088283538818359
Epoch 280, training loss: 7.038217544555664
Epoch 290, training loss: 7.105443000793457
Epoch 300, training loss: 7.006387233734131
Epoch 310, training loss: 6.9626007080078125
Epoch 320, training loss: 6.900035381317139
Epoch 330, training loss: 6.931901931762695
Epoch 340, training loss: 6.889122009277344
Epoch 350, training loss: 6.864476203918457
Epoch 360, training loss: 6.820855617523193
Epoch 370, training loss: 6.837565898895264
Epoch 380, training loss: 6.83294153213501
Epoch 390, training loss: 6.755092620849609
Epoch 400, training loss: 6.826496601104736
Epoch 410, training loss: 6.763912677764893
Epoch 420, training loss: 6.757050037384033
Epoch 430, training loss: 6.736049652099609
Epoch 440, training loss: 6.724715709686279
Epoch 450, training loss: 6.815646171569824
Epoch 460, training loss: 6.663479804992676
Epoch 470, training loss: 6.701456069946289
Epoch 480, training loss: 6.653790473937988
Epoch 490, training loss: 6.640556335449219
random
Accuracy: 0.772
Accuracy: 0.763
Accuracy: 0.761
Accuracy: 0.749
Accuracy: 0.716
Accuracy: 0.705
Accuracy: 0.685
Accuracy: 0.639
Accuracy: 0.616
Accuracy: 0.606
Accuracy: 0.575
Accuracy: 0.545
Accuracy: 0.538
Accuracy: 0.533
Accuracy: 0.524
Accuracy: 0.502
Accuracy: 0.491
Accuracy: 0.488
Accuracy: 0.488
Accuracy: 0.483
Accuracy: 0.479
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581731796264648
Epoch 10, training loss: 9.893867492675781
Epoch 20, training loss: 9.307665824890137
Epoch 30, training loss: 8.966094970703125
Epoch 40, training loss: 8.610774040222168
Epoch 50, training loss: 8.334335327148438
Epoch 60, training loss: 8.177170753479004
Epoch 70, training loss: 7.918568134307861
Epoch 80, training loss: 7.79141902923584
Epoch 90, training loss: 7.687762260437012
Epoch 100, training loss: 7.564343452453613
Epoch 110, training loss: 7.487502098083496
Epoch 120, training loss: 7.41570520401001
Epoch 130, training loss: 7.368072986602783
Epoch 140, training loss: 7.378539085388184
Epoch 150, training loss: 7.275632381439209
Epoch 160, training loss: 7.272138595581055
Epoch 170, training loss: 7.3143696784973145
Epoch 180, training loss: 7.180859088897705
Epoch 190, training loss: 7.213619709014893
Epoch 200, training loss: 7.174413204193115
Epoch 210, training loss: 7.077062606811523
Epoch 220, training loss: 7.060783863067627
Epoch 230, training loss: 7.146327018737793
Epoch 240, training loss: 7.059854030609131
Epoch 250, training loss: 7.04684591293335
Epoch 260, training loss: 6.963823318481445
Epoch 270, training loss: 7.0190749168396
Epoch 280, training loss: 6.9182844161987305
Epoch 290, training loss: 7.0017595291137695
Epoch 300, training loss: 6.9676055908203125
Epoch 310, training loss: 6.859889984130859
Epoch 320, training loss: 6.886931419372559
Epoch 330, training loss: 6.873292922973633
Epoch 340, training loss: 6.8066253662109375
Epoch 350, training loss: 6.86281681060791
Epoch 360, training loss: 6.849133491516113
Epoch 370, training loss: 6.8006591796875
Epoch 380, training loss: 6.714715003967285
Epoch 390, training loss: 6.793051242828369
Epoch 400, training loss: 6.734426498413086
Epoch 410, training loss: 6.6601996421813965
Epoch 420, training loss: 6.6554036140441895
Epoch 430, training loss: 6.749429702758789
Epoch 440, training loss: 6.667714595794678
Epoch 450, training loss: 6.665187358856201
Epoch 460, training loss: 6.643937587738037
Epoch 470, training loss: 6.677156925201416
Epoch 480, training loss: 6.544280052185059
Epoch 490, training loss: 6.595651149749756
random
Accuracy: 0.785
Accuracy: 0.774
Accuracy: 0.743
Accuracy: 0.733
Accuracy: 0.698
Accuracy: 0.675
Accuracy: 0.653
Accuracy: 0.611
Accuracy: 0.605
Accuracy: 0.607
Accuracy: 0.577
Accuracy: 0.555
Accuracy: 0.558
Accuracy: 0.557
Accuracy: 0.565
Accuracy: 0.551
Accuracy: 0.55
Accuracy: 0.555
Accuracy: 0.545
Accuracy: 0.54
Accuracy: 0.53
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581603050231934
Epoch 10, training loss: 9.775721549987793
Epoch 20, training loss: 9.217150688171387
Epoch 30, training loss: 8.877435684204102
Epoch 40, training loss: 8.418537139892578
Epoch 50, training loss: 8.17281723022461
Epoch 60, training loss: 7.9636616706848145
Epoch 70, training loss: 7.853429317474365
Epoch 80, training loss: 7.710876941680908
Epoch 90, training loss: 7.673613548278809
Epoch 100, training loss: 7.562359809875488
Epoch 110, training loss: 7.600642204284668
Epoch 120, training loss: 7.538806438446045
Epoch 130, training loss: 7.483486175537109
Epoch 140, training loss: 7.453663349151611
Epoch 150, training loss: 7.44221830368042
Epoch 160, training loss: 7.353616237640381
Epoch 170, training loss: 7.376197338104248
Epoch 180, training loss: 7.234348297119141
Epoch 190, training loss: 7.241444110870361
Epoch 200, training loss: 7.1473188400268555
Epoch 210, training loss: 7.1788105964660645
Epoch 220, training loss: 7.143070697784424
Epoch 230, training loss: 7.137700080871582
Epoch 240, training loss: 7.111032009124756
Epoch 250, training loss: 7.115664958953857
Epoch 260, training loss: 6.98424768447876
Epoch 270, training loss: 7.005774021148682
Epoch 280, training loss: 7.005656719207764
Epoch 290, training loss: 6.979979515075684
Epoch 300, training loss: 7.022851467132568
Epoch 310, training loss: 6.977295875549316
Epoch 320, training loss: 6.981739521026611
Epoch 330, training loss: 6.915751934051514
Epoch 340, training loss: 6.862789630889893
Epoch 350, training loss: 6.891313552856445
Epoch 360, training loss: 6.840121269226074
Epoch 370, training loss: 6.83900785446167
Epoch 380, training loss: 6.766147136688232
Epoch 390, training loss: 6.822556495666504
Epoch 400, training loss: 6.8255085945129395
Epoch 410, training loss: 6.764581203460693
Epoch 420, training loss: 6.778604030609131
Epoch 430, training loss: 6.7551350593566895
Epoch 440, training loss: 6.682804584503174
Epoch 450, training loss: 6.726216793060303
Epoch 460, training loss: 6.79734992980957
Epoch 470, training loss: 6.683739185333252
Epoch 480, training loss: 6.673216819763184
Epoch 490, training loss: 6.669553756713867
random
Accuracy: 0.756
Accuracy: 0.748
Accuracy: 0.735
Accuracy: 0.733
Accuracy: 0.698
Accuracy: 0.669
Accuracy: 0.641
Accuracy: 0.613
Accuracy: 0.59
Accuracy: 0.592
Accuracy: 0.574
Accuracy: 0.541
Accuracy: 0.545
Accuracy: 0.542
Accuracy: 0.547
Accuracy: 0.537
Accuracy: 0.537
Accuracy: 0.548
Accuracy: 0.552
Accuracy: 0.559
Accuracy: 0.564
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581734657287598
Epoch 10, training loss: 9.773051261901855
Epoch 20, training loss: 9.164246559143066
Epoch 30, training loss: 8.760743141174316
Epoch 40, training loss: 8.440057754516602
Epoch 50, training loss: 8.269221305847168
Epoch 60, training loss: 8.097171783447266
Epoch 70, training loss: 7.902595043182373
Epoch 80, training loss: 7.825534343719482
Epoch 90, training loss: 7.6768412590026855
Epoch 100, training loss: 7.522575855255127
Epoch 110, training loss: 7.463950157165527
Epoch 120, training loss: 7.377024173736572
Epoch 130, training loss: 7.320982456207275
Epoch 140, training loss: 7.2746148109436035
Epoch 150, training loss: 7.253674030303955
Epoch 160, training loss: 7.15201997756958
Epoch 170, training loss: 7.012203216552734
Epoch 180, training loss: 7.015939712524414
Epoch 190, training loss: 7.054201602935791
Epoch 200, training loss: 7.069066524505615
Epoch 210, training loss: 6.9788103103637695
Epoch 220, training loss: 6.986935615539551
Epoch 230, training loss: 6.944716930389404
Epoch 240, training loss: 6.879566192626953
Epoch 250, training loss: 6.868515968322754
Epoch 260, training loss: 6.94736385345459
Epoch 270, training loss: 6.837120532989502
Epoch 280, training loss: 6.768852710723877
Epoch 290, training loss: 6.765766143798828
Epoch 300, training loss: 6.7502031326293945
Epoch 310, training loss: 6.725040435791016
Epoch 320, training loss: 6.68715763092041
Epoch 330, training loss: 6.748569011688232
Epoch 340, training loss: 6.683592319488525
Epoch 350, training loss: 6.702935695648193
Epoch 360, training loss: 6.65791654586792
Epoch 370, training loss: 6.644948959350586
Epoch 380, training loss: 6.6798553466796875
Epoch 390, training loss: 6.680624008178711
Epoch 400, training loss: 6.624608039855957
Epoch 410, training loss: 6.767536640167236
Epoch 420, training loss: 6.643800735473633
Epoch 430, training loss: 6.656563758850098
Epoch 440, training loss: 6.598708629608154
Epoch 450, training loss: 6.638449192047119
Epoch 460, training loss: 6.592492580413818
Epoch 470, training loss: 6.624119758605957
Epoch 480, training loss: 6.612060546875
Epoch 490, training loss: 6.524801254272461
random
Accuracy: 0.732
Accuracy: 0.731
Accuracy: 0.723
Accuracy: 0.722
Accuracy: 0.672
Accuracy: 0.657
Accuracy: 0.61
Accuracy: 0.574
Accuracy: 0.555
Accuracy: 0.547
Accuracy: 0.509
Accuracy: 0.468
Accuracy: 0.468
Accuracy: 0.468
Accuracy: 0.466
Accuracy: 0.442
Accuracy: 0.437
Accuracy: 0.434
Accuracy: 0.426
Accuracy: 0.42
Accuracy: 0.421
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.581780433654785
Epoch 10, training loss: 9.90430736541748
Epoch 20, training loss: 9.165265083312988
Epoch 30, training loss: 8.644149780273438
Epoch 40, training loss: 8.313962936401367
Epoch 50, training loss: 8.08094596862793
Epoch 60, training loss: 7.900805950164795
Epoch 70, training loss: 7.806305408477783
Epoch 80, training loss: 7.646998882293701
Epoch 90, training loss: 7.6740522384643555
Epoch 100, training loss: 7.567094802856445
Epoch 110, training loss: 7.590551853179932
Epoch 120, training loss: 7.498030662536621
Epoch 130, training loss: 7.488160133361816
Epoch 140, training loss: 7.5584940910339355
Epoch 150, training loss: 7.450512409210205
Epoch 160, training loss: 7.432619094848633
Epoch 170, training loss: 7.385065078735352
Epoch 180, training loss: 7.253508567810059
Epoch 190, training loss: 7.30308723449707
Epoch 200, training loss: 7.230695724487305
Epoch 210, training loss: 7.149501323699951
Epoch 220, training loss: 7.192306995391846
Epoch 230, training loss: 7.142153739929199
Epoch 240, training loss: 7.158736705780029
Epoch 250, training loss: 7.073159694671631
Epoch 260, training loss: 7.115553855895996
Epoch 270, training loss: 7.030311107635498
Epoch 280, training loss: 7.012009143829346
Epoch 290, training loss: 7.02768087387085
Epoch 300, training loss: 7.009061336517334
Epoch 310, training loss: 6.996926307678223
Epoch 320, training loss: 6.9474568367004395
Epoch 330, training loss: 6.916156768798828
Epoch 340, training loss: 6.945899486541748
Epoch 350, training loss: 6.924647808074951
Epoch 360, training loss: 6.969693183898926
Epoch 370, training loss: 6.873725891113281
Epoch 380, training loss: 6.882361888885498
Epoch 390, training loss: 6.895409107208252
Epoch 400, training loss: 6.934341907501221
Epoch 410, training loss: 6.833689212799072
Epoch 420, training loss: 6.874047756195068
Epoch 430, training loss: 6.825222492218018
Epoch 440, training loss: 6.801738262176514
Epoch 450, training loss: 6.737591743469238
Epoch 460, training loss: 6.807592391967773
Epoch 470, training loss: 6.781355381011963
Epoch 480, training loss: 6.691623210906982
Epoch 490, training loss: 6.732852935791016
random
Accuracy: 0.806
Accuracy: 0.8
Accuracy: 0.787
Accuracy: 0.783
Accuracy: 0.775
Accuracy: 0.769
Accuracy: 0.76
Accuracy: 0.713
Accuracy: 0.716
Accuracy: 0.709
Accuracy: 0.69
Accuracy: 0.66
Accuracy: 0.66
Accuracy: 0.664
Accuracy: 0.657
Accuracy: 0.652
Accuracy: 0.646
Accuracy: 0.646
Accuracy: 0.639
Accuracy: 0.63
Accuracy: 0.623
Beta:0.3 Ptb size:0 Accuracy:0.7702+-0.0252
Beta:0.3 Ptb size:1 Accuracy:0.7632+-0.0234
Beta:0.3 Ptb size:2 Accuracy:0.7498+-0.0223
Beta:0.3 Ptb size:3 Accuracy:0.7440+-0.0213
Beta:0.3 Ptb size:4 Accuracy:0.7118+-0.0346
Beta:0.3 Ptb size:5 Accuracy:0.6950+-0.0402
Beta:0.3 Ptb size:6 Accuracy:0.6698+-0.0511
Beta:0.3 Ptb size:7 Accuracy:0.6300+-0.0464
Beta:0.3 Ptb size:8 Accuracy:0.6164+-0.0539
Beta:0.3 Ptb size:9 Accuracy:0.6122+-0.0531
Beta:0.3 Ptb size:10 Accuracy:0.5850+-0.0585
Beta:0.3 Ptb size:11 Accuracy:0.5538+-0.0615
Beta:0.3 Ptb size:12 Accuracy:0.5538+-0.0616
Beta:0.3 Ptb size:13 Accuracy:0.5528+-0.0634
Beta:0.3 Ptb size:14 Accuracy:0.5518+-0.0623
Beta:0.3 Ptb size:15 Accuracy:0.5368+-0.0688
Beta:0.3 Ptb size:16 Accuracy:0.5322+-0.0694
Beta:0.3 Ptb size:17 Accuracy:0.5342+-0.0711
Beta:0.3 Ptb size:18 Accuracy:0.5300+-0.0710
Beta:0.3 Ptb size:19 Accuracy:0.5264+-0.0710
Beta:0.3 Ptb size:20 Accuracy:0.5234+-0.0694
beta 0.4
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581696510314941
Epoch 10, training loss: 9.764557838439941
Epoch 20, training loss: 9.12055492401123
Epoch 30, training loss: 8.815322875976562
Epoch 40, training loss: 8.429899215698242
Epoch 50, training loss: 8.282258033752441
Epoch 60, training loss: 8.111984252929688
Epoch 70, training loss: 7.914516925811768
Epoch 80, training loss: 7.787899017333984
Epoch 90, training loss: 7.712059497833252
Epoch 100, training loss: 7.57932710647583
Epoch 110, training loss: 7.509823322296143
Epoch 120, training loss: 7.543095111846924
Epoch 130, training loss: 7.494643211364746
Epoch 140, training loss: 7.458754062652588
Epoch 150, training loss: 7.406188488006592
Epoch 160, training loss: 7.36268424987793
Epoch 170, training loss: 7.337886810302734
Epoch 180, training loss: 7.333700180053711
Epoch 190, training loss: 7.235248565673828
Epoch 200, training loss: 7.25214147567749
Epoch 210, training loss: 7.184694766998291
Epoch 220, training loss: 7.154704570770264
Epoch 230, training loss: 7.170032501220703
Epoch 240, training loss: 7.040338039398193
Epoch 250, training loss: 6.988154411315918
Epoch 260, training loss: 6.976263999938965
Epoch 270, training loss: 7.03081750869751
Epoch 280, training loss: 6.973164081573486
Epoch 290, training loss: 7.043422222137451
Epoch 300, training loss: 6.920205593109131
Epoch 310, training loss: 6.896955966949463
Epoch 320, training loss: 6.838315963745117
Epoch 330, training loss: 6.876784801483154
Epoch 340, training loss: 6.817439556121826
Epoch 350, training loss: 6.789652347564697
Epoch 360, training loss: 6.753759384155273
Epoch 370, training loss: 6.770911693572998
Epoch 380, training loss: 6.7770795822143555
Epoch 390, training loss: 6.695171356201172
Epoch 400, training loss: 6.771177768707275
Epoch 410, training loss: 6.702544212341309
Epoch 420, training loss: 6.712763786315918
Epoch 430, training loss: 6.668877124786377
Epoch 440, training loss: 6.655803203582764
Epoch 450, training loss: 6.741302967071533
Epoch 460, training loss: 6.606732368469238
Epoch 470, training loss: 6.625002861022949
Epoch 480, training loss: 6.584291934967041
Epoch 490, training loss: 6.562825679779053
random
Accuracy: 0.785
Accuracy: 0.777
Accuracy: 0.767
Accuracy: 0.755
Accuracy: 0.729
Accuracy: 0.722
Accuracy: 0.69
Accuracy: 0.653
Accuracy: 0.641
Accuracy: 0.627
Accuracy: 0.595
Accuracy: 0.558
Accuracy: 0.549
Accuracy: 0.546
Accuracy: 0.537
Accuracy: 0.513
Accuracy: 0.512
Accuracy: 0.51
Accuracy: 0.501
Accuracy: 0.497
Accuracy: 0.496
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581671714782715
Epoch 10, training loss: 9.856223106384277
Epoch 20, training loss: 9.275917053222656
Epoch 30, training loss: 8.950994491577148
Epoch 40, training loss: 8.593082427978516
Epoch 50, training loss: 8.30526351928711
Epoch 60, training loss: 8.14111042022705
Epoch 70, training loss: 7.864243030548096
Epoch 80, training loss: 7.671972751617432
Epoch 90, training loss: 7.545367240905762
Epoch 100, training loss: 7.453195571899414
Epoch 110, training loss: 7.419383525848389
Epoch 120, training loss: 7.33570671081543
Epoch 130, training loss: 7.269608974456787
Epoch 140, training loss: 7.29807186126709
Epoch 150, training loss: 7.218025207519531
Epoch 160, training loss: 7.223388195037842
Epoch 170, training loss: 7.246506690979004
Epoch 180, training loss: 7.117611408233643
Epoch 190, training loss: 7.182550430297852
Epoch 200, training loss: 7.134913921356201
Epoch 210, training loss: 7.032526969909668
Epoch 220, training loss: 7.020483016967773
Epoch 230, training loss: 7.121321678161621
Epoch 240, training loss: 7.025347709655762
Epoch 250, training loss: 7.021057605743408
Epoch 260, training loss: 6.9486517906188965
Epoch 270, training loss: 7.0269389152526855
Epoch 280, training loss: 6.9176130294799805
Epoch 290, training loss: 7.005481719970703
Epoch 300, training loss: 6.967623233795166
Epoch 310, training loss: 6.865902423858643
Epoch 320, training loss: 6.891487121582031
Epoch 330, training loss: 6.878596305847168
Epoch 340, training loss: 6.810433387756348
Epoch 350, training loss: 6.85513162612915
Epoch 360, training loss: 6.859871864318848
Epoch 370, training loss: 6.797116756439209
Epoch 380, training loss: 6.720062255859375
Epoch 390, training loss: 6.778336048126221
Epoch 400, training loss: 6.725465297698975
Epoch 410, training loss: 6.663887023925781
Epoch 420, training loss: 6.6483540534973145
Epoch 430, training loss: 6.735764503479004
Epoch 440, training loss: 6.66777229309082
Epoch 450, training loss: 6.653238773345947
Epoch 460, training loss: 6.637172698974609
Epoch 470, training loss: 6.651701927185059
Epoch 480, training loss: 6.52604341506958
Epoch 490, training loss: 6.586820602416992
random
Accuracy: 0.769
Accuracy: 0.772
Accuracy: 0.748
Accuracy: 0.744
Accuracy: 0.72
Accuracy: 0.706
Accuracy: 0.687
Accuracy: 0.65
Accuracy: 0.633
Accuracy: 0.636
Accuracy: 0.606
Accuracy: 0.57
Accuracy: 0.558
Accuracy: 0.56
Accuracy: 0.562
Accuracy: 0.534
Accuracy: 0.544
Accuracy: 0.539
Accuracy: 0.53
Accuracy: 0.542
Accuracy: 0.529
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581528663635254
Epoch 10, training loss: 9.766277313232422
Epoch 20, training loss: 9.190363883972168
Epoch 30, training loss: 8.833744049072266
Epoch 40, training loss: 8.36497688293457
Epoch 50, training loss: 8.131672859191895
Epoch 60, training loss: 7.913589954376221
Epoch 70, training loss: 7.807958602905273
Epoch 80, training loss: 7.661141872406006
Epoch 90, training loss: 7.631924629211426
Epoch 100, training loss: 7.51719331741333
Epoch 110, training loss: 7.557127952575684
Epoch 120, training loss: 7.4898223876953125
Epoch 130, training loss: 7.4416399002075195
Epoch 140, training loss: 7.408281326293945
Epoch 150, training loss: 7.409451484680176
Epoch 160, training loss: 7.313487529754639
Epoch 170, training loss: 7.344280242919922
Epoch 180, training loss: 7.200967311859131
Epoch 190, training loss: 7.207996368408203
Epoch 200, training loss: 7.119180202484131
Epoch 210, training loss: 7.129338264465332
Epoch 220, training loss: 7.104226589202881
Epoch 230, training loss: 7.109255313873291
Epoch 240, training loss: 7.06938362121582
Epoch 250, training loss: 7.081035614013672
Epoch 260, training loss: 6.939711093902588
Epoch 270, training loss: 6.973296642303467
Epoch 280, training loss: 6.973336696624756
Epoch 290, training loss: 6.942070960998535
Epoch 300, training loss: 6.9761152267456055
Epoch 310, training loss: 6.932087421417236
Epoch 320, training loss: 6.938626766204834
Epoch 330, training loss: 6.86143159866333
Epoch 340, training loss: 6.822004795074463
Epoch 350, training loss: 6.855332851409912
Epoch 360, training loss: 6.792525291442871
Epoch 370, training loss: 6.799778461456299
Epoch 380, training loss: 6.723641395568848
Epoch 390, training loss: 6.785760879516602
Epoch 400, training loss: 6.787632465362549
Epoch 410, training loss: 6.72171688079834
Epoch 420, training loss: 6.74032735824585
Epoch 430, training loss: 6.7201409339904785
Epoch 440, training loss: 6.641323566436768
Epoch 450, training loss: 6.686493873596191
Epoch 460, training loss: 6.744028091430664
Epoch 470, training loss: 6.639501571655273
Epoch 480, training loss: 6.620902061462402
Epoch 490, training loss: 6.625143051147461
random
Accuracy: 0.758
Accuracy: 0.752
Accuracy: 0.74
Accuracy: 0.738
Accuracy: 0.694
Accuracy: 0.673
Accuracy: 0.647
Accuracy: 0.608
Accuracy: 0.606
Accuracy: 0.586
Accuracy: 0.572
Accuracy: 0.541
Accuracy: 0.542
Accuracy: 0.513
Accuracy: 0.522
Accuracy: 0.516
Accuracy: 0.518
Accuracy: 0.527
Accuracy: 0.531
Accuracy: 0.536
Accuracy: 0.545
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.58166217803955
Epoch 10, training loss: 9.753898620605469
Epoch 20, training loss: 9.138757705688477
Epoch 30, training loss: 8.726234436035156
Epoch 40, training loss: 8.376899719238281
Epoch 50, training loss: 8.17147445678711
Epoch 60, training loss: 7.952881813049316
Epoch 70, training loss: 7.799255847930908
Epoch 80, training loss: 7.716833114624023
Epoch 90, training loss: 7.622746467590332
Epoch 100, training loss: 7.474483013153076
Epoch 110, training loss: 7.437440872192383
Epoch 120, training loss: 7.387436866760254
Epoch 130, training loss: 7.333215236663818
Epoch 140, training loss: 7.29362678527832
Epoch 150, training loss: 7.233322620391846
Epoch 160, training loss: 7.1866774559021
Epoch 170, training loss: 7.003605842590332
Epoch 180, training loss: 7.022614479064941
Epoch 190, training loss: 7.029606342315674
Epoch 200, training loss: 7.023341178894043
Epoch 210, training loss: 6.9464850425720215
Epoch 220, training loss: 6.921309947967529
Epoch 230, training loss: 6.8841657638549805
Epoch 240, training loss: 6.822846412658691
Epoch 250, training loss: 6.802529335021973
Epoch 260, training loss: 6.8766865730285645
Epoch 270, training loss: 6.779574871063232
Epoch 280, training loss: 6.693719387054443
Epoch 290, training loss: 6.67957878112793
Epoch 300, training loss: 6.668719291687012
Epoch 310, training loss: 6.637399673461914
Epoch 320, training loss: 6.62095308303833
Epoch 330, training loss: 6.683814525604248
Epoch 340, training loss: 6.601553916931152
Epoch 350, training loss: 6.634381294250488
Epoch 360, training loss: 6.602232933044434
Epoch 370, training loss: 6.589717864990234
Epoch 380, training loss: 6.606212139129639
Epoch 390, training loss: 6.629561424255371
Epoch 400, training loss: 6.56300163269043
Epoch 410, training loss: 6.708151817321777
Epoch 420, training loss: 6.579616069793701
Epoch 430, training loss: 6.612569332122803
Epoch 440, training loss: 6.565101146697998
Epoch 450, training loss: 6.58193826675415
Epoch 460, training loss: 6.532498359680176
Epoch 470, training loss: 6.574844837188721
Epoch 480, training loss: 6.562852382659912
Epoch 490, training loss: 6.501271724700928
random
Accuracy: 0.741
Accuracy: 0.735
Accuracy: 0.724
Accuracy: 0.72
Accuracy: 0.69
Accuracy: 0.673
Accuracy: 0.644
Accuracy: 0.602
Accuracy: 0.59
Accuracy: 0.575
Accuracy: 0.542
Accuracy: 0.505
Accuracy: 0.503
Accuracy: 0.498
Accuracy: 0.493
Accuracy: 0.472
Accuracy: 0.466
Accuracy: 0.466
Accuracy: 0.451
Accuracy: 0.445
Accuracy: 0.444
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.581714630126953
Epoch 10, training loss: 9.898961067199707
Epoch 20, training loss: 9.153960227966309
Epoch 30, training loss: 8.594884872436523
Epoch 40, training loss: 8.185883522033691
Epoch 50, training loss: 7.960814476013184
Epoch 60, training loss: 7.789218902587891
Epoch 70, training loss: 7.733348846435547
Epoch 80, training loss: 7.576913356781006
Epoch 90, training loss: 7.613882064819336
Epoch 100, training loss: 7.509211540222168
Epoch 110, training loss: 7.5335893630981445
Epoch 120, training loss: 7.451477527618408
Epoch 130, training loss: 7.447171211242676
Epoch 140, training loss: 7.524658203125
Epoch 150, training loss: 7.4125075340271
Epoch 160, training loss: 7.3899078369140625
Epoch 170, training loss: 7.363853454589844
Epoch 180, training loss: 7.2335896492004395
Epoch 190, training loss: 7.291128158569336
Epoch 200, training loss: 7.217291831970215
Epoch 210, training loss: 7.1255784034729
Epoch 220, training loss: 7.177038192749023
Epoch 230, training loss: 7.118499755859375
Epoch 240, training loss: 7.12739896774292
Epoch 250, training loss: 7.037161827087402
Epoch 260, training loss: 7.083675384521484
Epoch 270, training loss: 6.986900806427002
Epoch 280, training loss: 6.965278148651123
Epoch 290, training loss: 6.980008602142334
Epoch 300, training loss: 6.948360919952393
Epoch 310, training loss: 6.942996025085449
Epoch 320, training loss: 6.874892234802246
Epoch 330, training loss: 6.836019039154053
Epoch 340, training loss: 6.873604774475098
Epoch 350, training loss: 6.83521032333374
Epoch 360, training loss: 6.873898506164551
Epoch 370, training loss: 6.775872230529785
Epoch 380, training loss: 6.788363456726074
Epoch 390, training loss: 6.807736396789551
Epoch 400, training loss: 6.833600044250488
Epoch 410, training loss: 6.72268533706665
Epoch 420, training loss: 6.7840681076049805
Epoch 430, training loss: 6.7152099609375
Epoch 440, training loss: 6.691697597503662
Epoch 450, training loss: 6.631841659545898
Epoch 460, training loss: 6.695283889770508
Epoch 470, training loss: 6.6750102043151855
Epoch 480, training loss: 6.593705654144287
Epoch 490, training loss: 6.6217145919799805
random
Accuracy: 0.783
Accuracy: 0.782
Accuracy: 0.769
Accuracy: 0.765
Accuracy: 0.758
Accuracy: 0.747
Accuracy: 0.734
Accuracy: 0.702
Accuracy: 0.689
Accuracy: 0.691
Accuracy: 0.663
Accuracy: 0.637
Accuracy: 0.632
Accuracy: 0.634
Accuracy: 0.634
Accuracy: 0.612
Accuracy: 0.617
Accuracy: 0.621
Accuracy: 0.607
Accuracy: 0.612
Accuracy: 0.605
Beta:0.4 Ptb size:0 Accuracy:0.7672+-0.0164
Beta:0.4 Ptb size:1 Accuracy:0.7636+-0.0176
Beta:0.4 Ptb size:2 Accuracy:0.7496+-0.0169
Beta:0.4 Ptb size:3 Accuracy:0.7444+-0.0153
Beta:0.4 Ptb size:4 Accuracy:0.7182+-0.0248
Beta:0.4 Ptb size:5 Accuracy:0.7042+-0.0286
Beta:0.4 Ptb size:6 Accuracy:0.6804+-0.0330
Beta:0.4 Ptb size:7 Accuracy:0.6430+-0.0362
Beta:0.4 Ptb size:8 Accuracy:0.6318+-0.0340
Beta:0.4 Ptb size:9 Accuracy:0.6230+-0.0412
Beta:0.4 Ptb size:10 Accuracy:0.5956+-0.0402
Beta:0.4 Ptb size:11 Accuracy:0.5622+-0.0433
Beta:0.4 Ptb size:12 Accuracy:0.5568+-0.0420
Beta:0.4 Ptb size:13 Accuracy:0.5502+-0.0474
Beta:0.4 Ptb size:14 Accuracy:0.5496+-0.0478
Beta:0.4 Ptb size:15 Accuracy:0.5294+-0.0460
Beta:0.4 Ptb size:16 Accuracy:0.5314+-0.0496
Beta:0.4 Ptb size:17 Accuracy:0.5326+-0.0507
Beta:0.4 Ptb size:18 Accuracy:0.5240+-0.0507
Beta:0.4 Ptb size:19 Accuracy:0.5264+-0.0551
Beta:0.4 Ptb size:20 Accuracy:0.5238+-0.0533
beta 0.5
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581624031066895
Epoch 10, training loss: 9.769323348999023
Epoch 20, training loss: 9.083711624145508
Epoch 30, training loss: 8.749465942382812
Epoch 40, training loss: 8.38382625579834
Epoch 50, training loss: 8.23733139038086
Epoch 60, training loss: 8.009896278381348
Epoch 70, training loss: 7.815730094909668
Epoch 80, training loss: 7.6933913230896
Epoch 90, training loss: 7.648702621459961
Epoch 100, training loss: 7.52631950378418
Epoch 110, training loss: 7.458630561828613
Epoch 120, training loss: 7.48844051361084
Epoch 130, training loss: 7.427147388458252
Epoch 140, training loss: 7.395773887634277
Epoch 150, training loss: 7.304965972900391
Epoch 160, training loss: 7.228053569793701
Epoch 170, training loss: 7.204539775848389
Epoch 180, training loss: 7.166276931762695
Epoch 190, training loss: 7.085086822509766
Epoch 200, training loss: 7.102449893951416
Epoch 210, training loss: 7.056007385253906
Epoch 220, training loss: 7.048705577850342
Epoch 230, training loss: 7.069265365600586
Epoch 240, training loss: 6.9583964347839355
Epoch 250, training loss: 6.911983013153076
Epoch 260, training loss: 6.9035420417785645
Epoch 270, training loss: 6.978224754333496
Epoch 280, training loss: 6.9074387550354
Epoch 290, training loss: 6.968158721923828
Epoch 300, training loss: 6.847589492797852
Epoch 310, training loss: 6.840258598327637
Epoch 320, training loss: 6.780279159545898
Epoch 330, training loss: 6.817793846130371
Epoch 340, training loss: 6.755983352661133
Epoch 350, training loss: 6.740175247192383
Epoch 360, training loss: 6.701425075531006
Epoch 370, training loss: 6.718385696411133
Epoch 380, training loss: 6.727792263031006
Epoch 390, training loss: 6.653107166290283
Epoch 400, training loss: 6.717679500579834
Epoch 410, training loss: 6.664513111114502
Epoch 420, training loss: 6.6821160316467285
Epoch 430, training loss: 6.6208176612854
Epoch 440, training loss: 6.608814716339111
Epoch 450, training loss: 6.689164161682129
Epoch 460, training loss: 6.561182022094727
Epoch 470, training loss: 6.585937023162842
Epoch 480, training loss: 6.546797275543213
Epoch 490, training loss: 6.528467178344727
random
Accuracy: 0.781
Accuracy: 0.778
Accuracy: 0.759
Accuracy: 0.749
Accuracy: 0.72
Accuracy: 0.684
Accuracy: 0.656
Accuracy: 0.623
Accuracy: 0.613
Accuracy: 0.613
Accuracy: 0.585
Accuracy: 0.564
Accuracy: 0.546
Accuracy: 0.544
Accuracy: 0.535
Accuracy: 0.523
Accuracy: 0.51
Accuracy: 0.524
Accuracy: 0.518
Accuracy: 0.511
Accuracy: 0.512
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.58161735534668
Epoch 10, training loss: 9.834747314453125
Epoch 20, training loss: 9.23812484741211
Epoch 30, training loss: 8.918331146240234
Epoch 40, training loss: 8.552034378051758
Epoch 50, training loss: 8.278337478637695
Epoch 60, training loss: 8.076781272888184
Epoch 70, training loss: 7.844539642333984
Epoch 80, training loss: 7.659549236297607
Epoch 90, training loss: 7.519295692443848
Epoch 100, training loss: 7.432205677032471
Epoch 110, training loss: 7.392435073852539
Epoch 120, training loss: 7.305210113525391
Epoch 130, training loss: 7.225977420806885
Epoch 140, training loss: 7.256964206695557
Epoch 150, training loss: 7.176719665527344
Epoch 160, training loss: 7.194386005401611
Epoch 170, training loss: 7.211982250213623
Epoch 180, training loss: 7.073008060455322
Epoch 190, training loss: 7.146902084350586
Epoch 200, training loss: 7.088149070739746
Epoch 210, training loss: 6.992668151855469
Epoch 220, training loss: 6.982082366943359
Epoch 230, training loss: 7.069301128387451
Epoch 240, training loss: 6.970292091369629
Epoch 250, training loss: 6.9710798263549805
Epoch 260, training loss: 6.891655921936035
Epoch 270, training loss: 6.963093280792236
Epoch 280, training loss: 6.859764099121094
Epoch 290, training loss: 6.944375514984131
Epoch 300, training loss: 6.892661094665527
Epoch 310, training loss: 6.800095081329346
Epoch 320, training loss: 6.821610450744629
Epoch 330, training loss: 6.7989349365234375
Epoch 340, training loss: 6.732800483703613
Epoch 350, training loss: 6.789726257324219
Epoch 360, training loss: 6.773088455200195
Epoch 370, training loss: 6.7176127433776855
Epoch 380, training loss: 6.632484436035156
Epoch 390, training loss: 6.701837539672852
Epoch 400, training loss: 6.645831108093262
Epoch 410, training loss: 6.587645530700684
Epoch 420, training loss: 6.580405235290527
Epoch 430, training loss: 6.663034439086914
Epoch 440, training loss: 6.584676742553711
Epoch 450, training loss: 6.594236373901367
Epoch 460, training loss: 6.583160400390625
Epoch 470, training loss: 6.587639331817627
Epoch 480, training loss: 6.476531505584717
Epoch 490, training loss: 6.517143249511719
random
Accuracy: 0.768
Accuracy: 0.77
Accuracy: 0.753
Accuracy: 0.749
Accuracy: 0.732
Accuracy: 0.713
Accuracy: 0.7
Accuracy: 0.673
Accuracy: 0.656
Accuracy: 0.658
Accuracy: 0.625
Accuracy: 0.579
Accuracy: 0.566
Accuracy: 0.57
Accuracy: 0.563
Accuracy: 0.551
Accuracy: 0.551
Accuracy: 0.541
Accuracy: 0.539
Accuracy: 0.549
Accuracy: 0.532
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581475257873535
Epoch 10, training loss: 9.765806198120117
Epoch 20, training loss: 9.162654876708984
Epoch 30, training loss: 8.803743362426758
Epoch 40, training loss: 8.354963302612305
Epoch 50, training loss: 8.118064880371094
Epoch 60, training loss: 7.8835062980651855
Epoch 70, training loss: 7.772624969482422
Epoch 80, training loss: 7.622788429260254
Epoch 90, training loss: 7.581035614013672
Epoch 100, training loss: 7.469978332519531
Epoch 110, training loss: 7.514139175415039
Epoch 120, training loss: 7.444468975067139
Epoch 130, training loss: 7.3853559494018555
Epoch 140, training loss: 7.342784881591797
Epoch 150, training loss: 7.3490705490112305
Epoch 160, training loss: 7.260448932647705
Epoch 170, training loss: 7.278761863708496
Epoch 180, training loss: 7.150108337402344
Epoch 190, training loss: 7.142886161804199
Epoch 200, training loss: 7.054304599761963
Epoch 210, training loss: 7.062108516693115
Epoch 220, training loss: 7.047357559204102
Epoch 230, training loss: 7.052739143371582
Epoch 240, training loss: 6.989156723022461
Epoch 250, training loss: 7.004916667938232
Epoch 260, training loss: 6.861616134643555
Epoch 270, training loss: 6.891058444976807
Epoch 280, training loss: 6.892987251281738
Epoch 290, training loss: 6.846367835998535
Epoch 300, training loss: 6.852792263031006
Epoch 310, training loss: 6.805819034576416
Epoch 320, training loss: 6.785658359527588
Epoch 330, training loss: 6.719926834106445
Epoch 340, training loss: 6.700253009796143
Epoch 350, training loss: 6.744504928588867
Epoch 360, training loss: 6.659847736358643
Epoch 370, training loss: 6.648994445800781
Epoch 380, training loss: 6.589111804962158
Epoch 390, training loss: 6.666944980621338
Epoch 400, training loss: 6.64503288269043
Epoch 410, training loss: 6.5824480056762695
Epoch 420, training loss: 6.593873500823975
Epoch 430, training loss: 6.594919204711914
Epoch 440, training loss: 6.508229732513428
Epoch 450, training loss: 6.5684638023376465
Epoch 460, training loss: 6.615811824798584
Epoch 470, training loss: 6.52014684677124
Epoch 480, training loss: 6.5005574226379395
Epoch 490, training loss: 6.483544826507568
random
Accuracy: 0.74
Accuracy: 0.736
Accuracy: 0.711
Accuracy: 0.708
Accuracy: 0.68
Accuracy: 0.64
Accuracy: 0.622
Accuracy: 0.578
Accuracy: 0.561
Accuracy: 0.557
Accuracy: 0.526
Accuracy: 0.49
Accuracy: 0.483
Accuracy: 0.473
Accuracy: 0.465
Accuracy: 0.45
Accuracy: 0.455
Accuracy: 0.45
Accuracy: 0.446
Accuracy: 0.453
Accuracy: 0.455
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581604957580566
Epoch 10, training loss: 9.75312328338623
Epoch 20, training loss: 9.112471580505371
Epoch 30, training loss: 8.688227653503418
Epoch 40, training loss: 8.29837703704834
Epoch 50, training loss: 8.0172758102417
Epoch 60, training loss: 7.840695858001709
Epoch 70, training loss: 7.706596851348877
Epoch 80, training loss: 7.65498161315918
Epoch 90, training loss: 7.570859909057617
Epoch 100, training loss: 7.45481538772583
Epoch 110, training loss: 7.441567897796631
Epoch 120, training loss: 7.429742813110352
Epoch 130, training loss: 7.345658302307129
Epoch 140, training loss: 7.307403087615967
Epoch 150, training loss: 7.229979991912842
Epoch 160, training loss: 7.197352886199951
Epoch 170, training loss: 7.002275466918945
Epoch 180, training loss: 7.013153553009033
Epoch 190, training loss: 7.0072526931762695
Epoch 200, training loss: 6.978299140930176
Epoch 210, training loss: 6.92336893081665
Epoch 220, training loss: 6.8624982833862305
Epoch 230, training loss: 6.8303446769714355
Epoch 240, training loss: 6.77769660949707
Epoch 250, training loss: 6.755320072174072
Epoch 260, training loss: 6.781012535095215
Epoch 270, training loss: 6.725837230682373
Epoch 280, training loss: 6.625338077545166
Epoch 290, training loss: 6.6218791007995605
Epoch 300, training loss: 6.611748695373535
Epoch 310, training loss: 6.576802730560303
Epoch 320, training loss: 6.573823928833008
Epoch 330, training loss: 6.633437633514404
Epoch 340, training loss: 6.546821117401123
Epoch 350, training loss: 6.566929817199707
Epoch 360, training loss: 6.538846492767334
Epoch 370, training loss: 6.535489559173584
Epoch 380, training loss: 6.55322790145874
Epoch 390, training loss: 6.5820136070251465
Epoch 400, training loss: 6.494468688964844
Epoch 410, training loss: 6.600283145904541
Epoch 420, training loss: 6.491572856903076
Epoch 430, training loss: 6.530422210693359
Epoch 440, training loss: 6.457588195800781
Epoch 450, training loss: 6.492821216583252
Epoch 460, training loss: 6.453680515289307
Epoch 470, training loss: 6.480649948120117
Epoch 480, training loss: 6.476831912994385
Epoch 490, training loss: 6.415324687957764
random
Accuracy: 0.75
Accuracy: 0.742
Accuracy: 0.728
Accuracy: 0.712
Accuracy: 0.663
Accuracy: 0.649
Accuracy: 0.607
Accuracy: 0.578
Accuracy: 0.551
Accuracy: 0.521
Accuracy: 0.502
Accuracy: 0.476
Accuracy: 0.45
Accuracy: 0.458
Accuracy: 0.439
Accuracy: 0.426
Accuracy: 0.435
Accuracy: 0.417
Accuracy: 0.41
Accuracy: 0.406
Accuracy: 0.412
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.581658363342285
Epoch 10, training loss: 9.90641975402832
Epoch 20, training loss: 9.144876480102539
Epoch 30, training loss: 8.515032768249512
Epoch 40, training loss: 8.058935165405273
Epoch 50, training loss: 7.891450881958008
Epoch 60, training loss: 7.695784568786621
Epoch 70, training loss: 7.669622898101807
Epoch 80, training loss: 7.52852725982666
Epoch 90, training loss: 7.56315803527832
Epoch 100, training loss: 7.4513983726501465
Epoch 110, training loss: 7.467363357543945
Epoch 120, training loss: 7.4023051261901855
Epoch 130, training loss: 7.398416042327881
Epoch 140, training loss: 7.467973709106445
Epoch 150, training loss: 7.343935489654541
Epoch 160, training loss: 7.342867374420166
Epoch 170, training loss: 7.300537109375
Epoch 180, training loss: 7.163344383239746
Epoch 190, training loss: 7.212615489959717
Epoch 200, training loss: 7.149786949157715
Epoch 210, training loss: 7.068814277648926
Epoch 220, training loss: 7.104744911193848
Epoch 230, training loss: 7.061043739318848
Epoch 240, training loss: 7.052493095397949
Epoch 250, training loss: 6.980317115783691
Epoch 260, training loss: 7.017399311065674
Epoch 270, training loss: 6.896722316741943
Epoch 280, training loss: 6.8599324226379395
Epoch 290, training loss: 6.880815029144287
Epoch 300, training loss: 6.830069065093994
Epoch 310, training loss: 6.838031768798828
Epoch 320, training loss: 6.752470970153809
Epoch 330, training loss: 6.712894439697266
Epoch 340, training loss: 6.777202129364014
Epoch 350, training loss: 6.727842807769775
Epoch 360, training loss: 6.766460418701172
Epoch 370, training loss: 6.654693603515625
Epoch 380, training loss: 6.667100429534912
Epoch 390, training loss: 6.684013843536377
Epoch 400, training loss: 6.717947959899902
Epoch 410, training loss: 6.616138935089111
Epoch 420, training loss: 6.6790080070495605
Epoch 430, training loss: 6.605957984924316
Epoch 440, training loss: 6.591527938842773
Epoch 450, training loss: 6.527163982391357
Epoch 460, training loss: 6.591733932495117
Epoch 470, training loss: 6.571634292602539
Epoch 480, training loss: 6.497678756713867
Epoch 490, training loss: 6.536560535430908
random
Accuracy: 0.78
Accuracy: 0.764
Accuracy: 0.758
Accuracy: 0.748
Accuracy: 0.742
Accuracy: 0.727
Accuracy: 0.719
Accuracy: 0.681
Accuracy: 0.672
Accuracy: 0.657
Accuracy: 0.642
Accuracy: 0.61
Accuracy: 0.602
Accuracy: 0.6
Accuracy: 0.606
Accuracy: 0.578
Accuracy: 0.569
Accuracy: 0.586
Accuracy: 0.581
Accuracy: 0.579
Accuracy: 0.568
Beta:0.5 Ptb size:0 Accuracy:0.7638+-0.0163
Beta:0.5 Ptb size:1 Accuracy:0.7580+-0.0162
Beta:0.5 Ptb size:2 Accuracy:0.7418+-0.0191
Beta:0.5 Ptb size:3 Accuracy:0.7332+-0.0190
Beta:0.5 Ptb size:4 Accuracy:0.7074+-0.0306
Beta:0.5 Ptb size:5 Accuracy:0.6826+-0.0342
Beta:0.5 Ptb size:6 Accuracy:0.6608+-0.0432
Beta:0.5 Ptb size:7 Accuracy:0.6266+-0.0444
Beta:0.5 Ptb size:8 Accuracy:0.6106+-0.0487
Beta:0.5 Ptb size:9 Accuracy:0.6012+-0.0545
Beta:0.5 Ptb size:10 Accuracy:0.5760+-0.0544
Beta:0.5 Ptb size:11 Accuracy:0.5438+-0.0520
Beta:0.5 Ptb size:12 Accuracy:0.5294+-0.0554
Beta:0.5 Ptb size:13 Accuracy:0.5290+-0.0550
Beta:0.5 Ptb size:14 Accuracy:0.5216+-0.0617
Beta:0.5 Ptb size:15 Accuracy:0.5056+-0.0584
Beta:0.5 Ptb size:16 Accuracy:0.5040+-0.0522
Beta:0.5 Ptb size:17 Accuracy:0.5036+-0.0616
Beta:0.5 Ptb size:18 Accuracy:0.4988+-0.0623
Beta:0.5 Ptb size:19 Accuracy:0.4996+-0.0629
Beta:0.5 Ptb size:20 Accuracy:0.4958+-0.0556
beta 0.6
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.58155632019043
Epoch 10, training loss: 9.811734199523926
Epoch 20, training loss: 9.04516315460205
Epoch 30, training loss: 8.696619033813477
Epoch 40, training loss: 8.342531204223633
Epoch 50, training loss: 8.220593452453613
Epoch 60, training loss: 7.926229476928711
Epoch 70, training loss: 7.7412800788879395
Epoch 80, training loss: 7.619080543518066
Epoch 90, training loss: 7.5880303382873535
Epoch 100, training loss: 7.463236331939697
Epoch 110, training loss: 7.372309684753418
Epoch 120, training loss: 7.378344535827637
Epoch 130, training loss: 7.293649196624756
Epoch 140, training loss: 7.243756294250488
Epoch 150, training loss: 7.151188850402832
Epoch 160, training loss: 7.0914812088012695
Epoch 170, training loss: 7.073092937469482
Epoch 180, training loss: 7.063417911529541
Epoch 190, training loss: 6.989243984222412
Epoch 200, training loss: 7.019046306610107
Epoch 210, training loss: 6.97636079788208
Epoch 220, training loss: 6.992579460144043
Epoch 230, training loss: 7.002735614776611
Epoch 240, training loss: 6.9051032066345215
Epoch 250, training loss: 6.851043701171875
Epoch 260, training loss: 6.853957176208496
Epoch 270, training loss: 6.925719261169434
Epoch 280, training loss: 6.871008396148682
Epoch 290, training loss: 6.9267354011535645
Epoch 300, training loss: 6.805119037628174
Epoch 310, training loss: 6.8053107261657715
Epoch 320, training loss: 6.750103950500488
Epoch 330, training loss: 6.780226230621338
Epoch 340, training loss: 6.71939754486084
Epoch 350, training loss: 6.702794551849365
Epoch 360, training loss: 6.66398286819458
Epoch 370, training loss: 6.685515880584717
Epoch 380, training loss: 6.6879401206970215
Epoch 390, training loss: 6.616514205932617
Epoch 400, training loss: 6.682971954345703
Epoch 410, training loss: 6.624663352966309
Epoch 420, training loss: 6.640477657318115
Epoch 430, training loss: 6.5817437171936035
Epoch 440, training loss: 6.557785511016846
Epoch 450, training loss: 6.64293909072876
Epoch 460, training loss: 6.520115375518799
Epoch 470, training loss: 6.545955657958984
Epoch 480, training loss: 6.501347064971924
Epoch 490, training loss: 6.489861965179443
random
Accuracy: 0.781
Accuracy: 0.781
Accuracy: 0.757
Accuracy: 0.744
Accuracy: 0.723
Accuracy: 0.697
Accuracy: 0.676
Accuracy: 0.643
Accuracy: 0.626
Accuracy: 0.625
Accuracy: 0.605
Accuracy: 0.582
Accuracy: 0.584
Accuracy: 0.579
Accuracy: 0.57
Accuracy: 0.564
Accuracy: 0.559
Accuracy: 0.564
Accuracy: 0.552
Accuracy: 0.567
Accuracy: 0.558
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581573486328125
Epoch 10, training loss: 9.825295448303223
Epoch 20, training loss: 9.201921463012695
Epoch 30, training loss: 8.889381408691406
Epoch 40, training loss: 8.522388458251953
Epoch 50, training loss: 8.241413116455078
Epoch 60, training loss: 8.033836364746094
Epoch 70, training loss: 7.809258937835693
Epoch 80, training loss: 7.625821113586426
Epoch 90, training loss: 7.479751110076904
Epoch 100, training loss: 7.404078960418701
Epoch 110, training loss: 7.369054317474365
Epoch 120, training loss: 7.270898818969727
Epoch 130, training loss: 7.1793646812438965
Epoch 140, training loss: 7.215819358825684
Epoch 150, training loss: 7.139077186584473
Epoch 160, training loss: 7.160639762878418
Epoch 170, training loss: 7.162699222564697
Epoch 180, training loss: 7.029630184173584
Epoch 190, training loss: 7.091944217681885
Epoch 200, training loss: 7.0318989753723145
Epoch 210, training loss: 6.943524360656738
Epoch 220, training loss: 6.934958457946777
Epoch 230, training loss: 7.007509708404541
Epoch 240, training loss: 6.896595478057861
Epoch 250, training loss: 6.8895697593688965
Epoch 260, training loss: 6.807919502258301
Epoch 270, training loss: 6.8756022453308105
Epoch 280, training loss: 6.7574968338012695
Epoch 290, training loss: 6.855494499206543
Epoch 300, training loss: 6.790487766265869
Epoch 310, training loss: 6.704490661621094
Epoch 320, training loss: 6.717864990234375
Epoch 330, training loss: 6.681840896606445
Epoch 340, training loss: 6.634652614593506
Epoch 350, training loss: 6.679618835449219
Epoch 360, training loss: 6.676337242126465
Epoch 370, training loss: 6.614874839782715
Epoch 380, training loss: 6.544642925262451
Epoch 390, training loss: 6.598002910614014
Epoch 400, training loss: 6.52815055847168
Epoch 410, training loss: 6.491601943969727
Epoch 420, training loss: 6.480139255523682
Epoch 430, training loss: 6.559304237365723
Epoch 440, training loss: 6.477686882019043
Epoch 450, training loss: 6.492534637451172
Epoch 460, training loss: 6.4946208000183105
Epoch 470, training loss: 6.487874507904053
Epoch 480, training loss: 6.383018493652344
Epoch 490, training loss: 6.4206037521362305
random
Accuracy: 0.769
Accuracy: 0.769
Accuracy: 0.75
Accuracy: 0.744
Accuracy: 0.723
Accuracy: 0.702
Accuracy: 0.689
Accuracy: 0.667
Accuracy: 0.665
Accuracy: 0.649
Accuracy: 0.628
Accuracy: 0.584
Accuracy: 0.565
Accuracy: 0.547
Accuracy: 0.538
Accuracy: 0.523
Accuracy: 0.526
Accuracy: 0.524
Accuracy: 0.518
Accuracy: 0.529
Accuracy: 0.528
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581432342529297
Epoch 10, training loss: 9.789836883544922
Epoch 20, training loss: 9.135930061340332
Epoch 30, training loss: 8.765998840332031
Epoch 40, training loss: 8.309784889221191
Epoch 50, training loss: 8.061430931091309
Epoch 60, training loss: 7.828433990478516
Epoch 70, training loss: 7.713294982910156
Epoch 80, training loss: 7.576873779296875
Epoch 90, training loss: 7.528162479400635
Epoch 100, training loss: 7.408451557159424
Epoch 110, training loss: 7.438473224639893
Epoch 120, training loss: 7.342267990112305
Epoch 130, training loss: 7.266892910003662
Epoch 140, training loss: 7.1721062660217285
Epoch 150, training loss: 7.154688358306885
Epoch 160, training loss: 7.065064430236816
Epoch 170, training loss: 7.076968669891357
Epoch 180, training loss: 6.933608531951904
Epoch 190, training loss: 6.931102752685547
Epoch 200, training loss: 6.838367462158203
Epoch 210, training loss: 6.884907245635986
Epoch 220, training loss: 6.804586410522461
Epoch 230, training loss: 6.8386149406433105
Epoch 240, training loss: 6.784354209899902
Epoch 250, training loss: 6.811465263366699
Epoch 260, training loss: 6.664017677307129
Epoch 270, training loss: 6.715895652770996
Epoch 280, training loss: 6.721261501312256
Epoch 290, training loss: 6.683827877044678
Epoch 300, training loss: 6.714223384857178
Epoch 310, training loss: 6.700528144836426
Epoch 320, training loss: 6.674960136413574
Epoch 330, training loss: 6.6380295753479
Epoch 340, training loss: 6.59962797164917
Epoch 350, training loss: 6.643945693969727
Epoch 360, training loss: 6.5499444007873535
Epoch 370, training loss: 6.553432941436768
Epoch 380, training loss: 6.497994899749756
Epoch 390, training loss: 6.589407444000244
Epoch 400, training loss: 6.576303958892822
Epoch 410, training loss: 6.516057968139648
Epoch 420, training loss: 6.520702362060547
Epoch 430, training loss: 6.5217156410217285
Epoch 440, training loss: 6.4759321212768555
Epoch 450, training loss: 6.499251842498779
Epoch 460, training loss: 6.581732273101807
Epoch 470, training loss: 6.478572845458984
Epoch 480, training loss: 6.487874507904053
Epoch 490, training loss: 6.457512378692627
random
Accuracy: 0.76
Accuracy: 0.76
Accuracy: 0.73
Accuracy: 0.727
Accuracy: 0.702
Accuracy: 0.666
Accuracy: 0.637
Accuracy: 0.611
Accuracy: 0.6
Accuracy: 0.599
Accuracy: 0.571
Accuracy: 0.525
Accuracy: 0.532
Accuracy: 0.523
Accuracy: 0.504
Accuracy: 0.501
Accuracy: 0.513
Accuracy: 0.517
Accuracy: 0.521
Accuracy: 0.523
Accuracy: 0.522
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581560134887695
Epoch 10, training loss: 9.781018257141113
Epoch 20, training loss: 9.085999488830566
Epoch 30, training loss: 8.646985054016113
Epoch 40, training loss: 8.1947603225708
Epoch 50, training loss: 7.889692306518555
Epoch 60, training loss: 7.763485431671143
Epoch 70, training loss: 7.631104469299316
Epoch 80, training loss: 7.594325542449951
Epoch 90, training loss: 7.495666027069092
Epoch 100, training loss: 7.416225433349609
Epoch 110, training loss: 7.4068684577941895
Epoch 120, training loss: 7.414036750793457
Epoch 130, training loss: 7.345892906188965
Epoch 140, training loss: 7.289220809936523
Epoch 150, training loss: 7.227299213409424
Epoch 160, training loss: 7.18842077255249
Epoch 170, training loss: 6.992585182189941
Epoch 180, training loss: 7.010154724121094
Epoch 190, training loss: 7.004607677459717
Epoch 200, training loss: 6.9774298667907715
Epoch 210, training loss: 6.908523082733154
Epoch 220, training loss: 6.844717502593994
Epoch 230, training loss: 6.7978901863098145
Epoch 240, training loss: 6.752741813659668
Epoch 250, training loss: 6.72996187210083
Epoch 260, training loss: 6.741816997528076
Epoch 270, training loss: 6.667541980743408
Epoch 280, training loss: 6.583244323730469
Epoch 290, training loss: 6.579272747039795
Epoch 300, training loss: 6.570914268493652
Epoch 310, training loss: 6.517533302307129
Epoch 320, training loss: 6.51284122467041
Epoch 330, training loss: 6.564600467681885
Epoch 340, training loss: 6.4958109855651855
Epoch 350, training loss: 6.515806674957275
Epoch 360, training loss: 6.471104145050049
Epoch 370, training loss: 6.478151798248291
Epoch 380, training loss: 6.511859893798828
Epoch 390, training loss: 6.519199848175049
Epoch 400, training loss: 6.420652389526367
Epoch 410, training loss: 6.511751651763916
Epoch 420, training loss: 6.42188024520874
Epoch 430, training loss: 6.4575042724609375
Epoch 440, training loss: 6.378203868865967
Epoch 450, training loss: 6.421595573425293
Epoch 460, training loss: 6.394597053527832
Epoch 470, training loss: 6.386990070343018
Epoch 480, training loss: 6.380765914916992
Epoch 490, training loss: 6.356084823608398
random
Accuracy: 0.749
Accuracy: 0.746
Accuracy: 0.729
Accuracy: 0.725
Accuracy: 0.691
Accuracy: 0.675
Accuracy: 0.642
Accuracy: 0.603
Accuracy: 0.593
Accuracy: 0.577
Accuracy: 0.554
Accuracy: 0.524
Accuracy: 0.515
Accuracy: 0.524
Accuracy: 0.499
Accuracy: 0.495
Accuracy: 0.512
Accuracy: 0.512
Accuracy: 0.507
Accuracy: 0.489
Accuracy: 0.519
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.58161735534668
Epoch 10, training loss: 9.920829772949219
Epoch 20, training loss: 9.129264831542969
Epoch 30, training loss: 8.446538925170898
Epoch 40, training loss: 8.015534400939941
Epoch 50, training loss: 7.84127140045166
Epoch 60, training loss: 7.64857816696167
Epoch 70, training loss: 7.629829406738281
Epoch 80, training loss: 7.484947204589844
Epoch 90, training loss: 7.527565956115723
Epoch 100, training loss: 7.406235694885254
Epoch 110, training loss: 7.416332721710205
Epoch 120, training loss: 7.337604522705078
Epoch 130, training loss: 7.314734935760498
Epoch 140, training loss: 7.375391006469727
Epoch 150, training loss: 7.212562561035156
Epoch 160, training loss: 7.196336269378662
Epoch 170, training loss: 7.139416694641113
Epoch 180, training loss: 6.981057167053223
Epoch 190, training loss: 7.018710136413574
Epoch 200, training loss: 6.931621551513672
Epoch 210, training loss: 6.874704360961914
Epoch 220, training loss: 6.868684768676758
Epoch 230, training loss: 6.83970832824707
Epoch 240, training loss: 6.826723098754883
Epoch 250, training loss: 6.765161514282227
Epoch 260, training loss: 6.796363830566406
Epoch 270, training loss: 6.701778888702393
Epoch 280, training loss: 6.6754608154296875
Epoch 290, training loss: 6.702011585235596
Epoch 300, training loss: 6.67622184753418
Epoch 310, training loss: 6.704718589782715
Epoch 320, training loss: 6.628109931945801
Epoch 330, training loss: 6.602705955505371
Epoch 340, training loss: 6.713824272155762
Epoch 350, training loss: 6.603582859039307
Epoch 360, training loss: 6.685184478759766
Epoch 370, training loss: 6.569096565246582
Epoch 380, training loss: 6.5657525062561035
Epoch 390, training loss: 6.615170478820801
Epoch 400, training loss: 6.643327236175537
Epoch 410, training loss: 6.566129207611084
Epoch 420, training loss: 6.606151580810547
Epoch 430, training loss: 6.5627312660217285
Epoch 440, training loss: 6.539914131164551
Epoch 450, training loss: 6.490220069885254
Epoch 460, training loss: 6.543665409088135
Epoch 470, training loss: 6.535357475280762
Epoch 480, training loss: 6.469388008117676
Epoch 490, training loss: 6.516712188720703
random
Accuracy: 0.771
Accuracy: 0.758
Accuracy: 0.736
Accuracy: 0.735
Accuracy: 0.707
Accuracy: 0.685
Accuracy: 0.653
Accuracy: 0.626
Accuracy: 0.623
Accuracy: 0.607
Accuracy: 0.598
Accuracy: 0.575
Accuracy: 0.573
Accuracy: 0.568
Accuracy: 0.57
Accuracy: 0.558
Accuracy: 0.561
Accuracy: 0.566
Accuracy: 0.568
Accuracy: 0.568
Accuracy: 0.563
Beta:0.6 Ptb size:0 Accuracy:0.7660+-0.0108
Beta:0.6 Ptb size:1 Accuracy:0.7628+-0.0117
Beta:0.6 Ptb size:2 Accuracy:0.7404+-0.0112
Beta:0.6 Ptb size:3 Accuracy:0.7350+-0.0081
Beta:0.6 Ptb size:4 Accuracy:0.7092+-0.0124
Beta:0.6 Ptb size:5 Accuracy:0.6850+-0.0134
Beta:0.6 Ptb size:6 Accuracy:0.6594+-0.0200
Beta:0.6 Ptb size:7 Accuracy:0.6300+-0.0230
Beta:0.6 Ptb size:8 Accuracy:0.6214+-0.0253
Beta:0.6 Ptb size:9 Accuracy:0.6114+-0.0243
Beta:0.6 Ptb size:10 Accuracy:0.5912+-0.0260
Beta:0.6 Ptb size:11 Accuracy:0.5580+-0.0275
Beta:0.6 Ptb size:12 Accuracy:0.5538+-0.0260
Beta:0.6 Ptb size:13 Accuracy:0.5482+-0.0226
Beta:0.6 Ptb size:14 Accuracy:0.5362+-0.0307
Beta:0.6 Ptb size:15 Accuracy:0.5282+-0.0284
Beta:0.6 Ptb size:16 Accuracy:0.5342+-0.0216
Beta:0.6 Ptb size:17 Accuracy:0.5366+-0.0235
Beta:0.6 Ptb size:18 Accuracy:0.5332+-0.0229
Beta:0.6 Ptb size:19 Accuracy:0.5352+-0.0297
Beta:0.6 Ptb size:20 Accuracy:0.5380+-0.0187
beta 0.7
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581503868103027
Epoch 10, training loss: 9.88570785522461
Epoch 20, training loss: 9.007410049438477
Epoch 30, training loss: 8.659790992736816
Epoch 40, training loss: 8.306710243225098
Epoch 50, training loss: 8.245396614074707
Epoch 60, training loss: 7.882829666137695
Epoch 70, training loss: 7.703392028808594
Epoch 80, training loss: 7.5783915519714355
Epoch 90, training loss: 7.531090259552002
Epoch 100, training loss: 7.383376598358154
Epoch 110, training loss: 7.261519908905029
Epoch 120, training loss: 7.273996829986572
Epoch 130, training loss: 7.1873393058776855
Epoch 140, training loss: 7.145504474639893
Epoch 150, training loss: 7.088261604309082
Epoch 160, training loss: 7.018916130065918
Epoch 170, training loss: 7.00949764251709
Epoch 180, training loss: 7.001646995544434
Epoch 190, training loss: 6.927004814147949
Epoch 200, training loss: 6.9598002433776855
Epoch 210, training loss: 6.920837879180908
Epoch 220, training loss: 6.942877769470215
Epoch 230, training loss: 6.948457717895508
Epoch 240, training loss: 6.846723556518555
Epoch 250, training loss: 6.791939735412598
Epoch 260, training loss: 6.802248954772949
Epoch 270, training loss: 6.873876571655273
Epoch 280, training loss: 6.799215316772461
Epoch 290, training loss: 6.855381965637207
Epoch 300, training loss: 6.734955787658691
Epoch 310, training loss: 6.747000694274902
Epoch 320, training loss: 6.67966890335083
Epoch 330, training loss: 6.723531723022461
Epoch 340, training loss: 6.657205581665039
Epoch 350, training loss: 6.6397857666015625
Epoch 360, training loss: 6.601782321929932
Epoch 370, training loss: 6.61883544921875
Epoch 380, training loss: 6.609241008758545
Epoch 390, training loss: 6.5496296882629395
Epoch 400, training loss: 6.6287102699279785
Epoch 410, training loss: 6.5639424324035645
Epoch 420, training loss: 6.5739593505859375
Epoch 430, training loss: 6.509043216705322
Epoch 440, training loss: 6.482491493225098
Epoch 450, training loss: 6.560193061828613
Epoch 460, training loss: 6.461198806762695
Epoch 470, training loss: 6.488930702209473
Epoch 480, training loss: 6.431723117828369
Epoch 490, training loss: 6.42857551574707
random
Accuracy: 0.771
Accuracy: 0.767
Accuracy: 0.733
Accuracy: 0.723
Accuracy: 0.695
Accuracy: 0.69
Accuracy: 0.647
Accuracy: 0.626
Accuracy: 0.603
Accuracy: 0.605
Accuracy: 0.569
Accuracy: 0.55
Accuracy: 0.547
Accuracy: 0.54
Accuracy: 0.557
Accuracy: 0.534
Accuracy: 0.532
Accuracy: 0.529
Accuracy: 0.525
Accuracy: 0.523
Accuracy: 0.525
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581544876098633
Epoch 10, training loss: 9.827709197998047
Epoch 20, training loss: 9.156017303466797
Epoch 30, training loss: 8.839611053466797
Epoch 40, training loss: 8.484950065612793
Epoch 50, training loss: 8.20433521270752
Epoch 60, training loss: 8.022509574890137
Epoch 70, training loss: 7.791561603546143
Epoch 80, training loss: 7.597511291503906
Epoch 90, training loss: 7.457033634185791
Epoch 100, training loss: 7.365712642669678
Epoch 110, training loss: 7.3338704109191895
Epoch 120, training loss: 7.237431049346924
Epoch 130, training loss: 7.143093585968018
Epoch 140, training loss: 7.170111656188965
Epoch 150, training loss: 7.10575532913208
Epoch 160, training loss: 7.123000144958496
Epoch 170, training loss: 7.1036505699157715
Epoch 180, training loss: 6.98884391784668
Epoch 190, training loss: 7.043527126312256
Epoch 200, training loss: 6.974644660949707
Epoch 210, training loss: 6.882393836975098
Epoch 220, training loss: 6.8586554527282715
Epoch 230, training loss: 6.924471855163574
Epoch 240, training loss: 6.795055389404297
Epoch 250, training loss: 6.783514976501465
Epoch 260, training loss: 6.701837539672852
Epoch 270, training loss: 6.759215831756592
Epoch 280, training loss: 6.659294128417969
Epoch 290, training loss: 6.748802661895752
Epoch 300, training loss: 6.686867713928223
Epoch 310, training loss: 6.582840442657471
Epoch 320, training loss: 6.618647575378418
Epoch 330, training loss: 6.580496311187744
Epoch 340, training loss: 6.527449131011963
Epoch 350, training loss: 6.560059070587158
Epoch 360, training loss: 6.57405424118042
Epoch 370, training loss: 6.5205535888671875
Epoch 380, training loss: 6.453243732452393
Epoch 390, training loss: 6.51735258102417
Epoch 400, training loss: 6.425701141357422
Epoch 410, training loss: 6.396389484405518
Epoch 420, training loss: 6.387781143188477
Epoch 430, training loss: 6.461211204528809
Epoch 440, training loss: 6.399771690368652
Epoch 450, training loss: 6.414556503295898
Epoch 460, training loss: 6.427069187164307
Epoch 470, training loss: 6.395981311798096
Epoch 480, training loss: 6.325699806213379
Epoch 490, training loss: 6.339188575744629
random
Accuracy: 0.762
Accuracy: 0.761
Accuracy: 0.736
Accuracy: 0.73
Accuracy: 0.723
Accuracy: 0.693
Accuracy: 0.678
Accuracy: 0.653
Accuracy: 0.629
Accuracy: 0.626
Accuracy: 0.598
Accuracy: 0.562
Accuracy: 0.553
Accuracy: 0.547
Accuracy: 0.539
Accuracy: 0.526
Accuracy: 0.529
Accuracy: 0.53
Accuracy: 0.53
Accuracy: 0.541
Accuracy: 0.529
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581396102905273
Epoch 10, training loss: 9.825723648071289
Epoch 20, training loss: 9.107256889343262
Epoch 30, training loss: 8.744437217712402
Epoch 40, training loss: 8.293137550354004
Epoch 50, training loss: 8.034642219543457
Epoch 60, training loss: 7.816408634185791
Epoch 70, training loss: 7.622072696685791
Epoch 80, training loss: 7.421010494232178
Epoch 90, training loss: 7.3663129806518555
Epoch 100, training loss: 7.225400447845459
Epoch 110, training loss: 7.230690956115723
Epoch 120, training loss: 7.140329360961914
Epoch 130, training loss: 7.155015468597412
Epoch 140, training loss: 7.072875022888184
Epoch 150, training loss: 7.038909912109375
Epoch 160, training loss: 6.966266632080078
Epoch 170, training loss: 6.993687152862549
Epoch 180, training loss: 6.848095893859863
Epoch 190, training loss: 6.856353282928467
Epoch 200, training loss: 6.774216175079346
Epoch 210, training loss: 6.818397521972656
Epoch 220, training loss: 6.742851257324219
Epoch 230, training loss: 6.7870588302612305
Epoch 240, training loss: 6.734493255615234
Epoch 250, training loss: 6.762995719909668
Epoch 260, training loss: 6.628143787384033
Epoch 270, training loss: 6.661776542663574
Epoch 280, training loss: 6.674705982208252
Epoch 290, training loss: 6.62783145904541
Epoch 300, training loss: 6.675148963928223
Epoch 310, training loss: 6.663520812988281
Epoch 320, training loss: 6.634110450744629
Epoch 330, training loss: 6.608436584472656
Epoch 340, training loss: 6.559053421020508
Epoch 350, training loss: 6.586691856384277
Epoch 360, training loss: 6.505708694458008
Epoch 370, training loss: 6.526177406311035
Epoch 380, training loss: 6.457367897033691
Epoch 390, training loss: 6.5377068519592285
Epoch 400, training loss: 6.53013277053833
Epoch 410, training loss: 6.472108364105225
Epoch 420, training loss: 6.4758782386779785
Epoch 430, training loss: 6.48837947845459
Epoch 440, training loss: 6.427567005157471
Epoch 450, training loss: 6.456328868865967
Epoch 460, training loss: 6.527755260467529
Epoch 470, training loss: 6.43558931350708
Epoch 480, training loss: 6.428463459014893
Epoch 490, training loss: 6.365804195404053
random
Accuracy: 0.772
Accuracy: 0.762
Accuracy: 0.722
Accuracy: 0.699
Accuracy: 0.664
Accuracy: 0.645
Accuracy: 0.633
Accuracy: 0.607
Accuracy: 0.597
Accuracy: 0.593
Accuracy: 0.577
Accuracy: 0.567
Accuracy: 0.562
Accuracy: 0.56
Accuracy: 0.556
Accuracy: 0.553
Accuracy: 0.558
Accuracy: 0.559
Accuracy: 0.562
Accuracy: 0.564
Accuracy: 0.566
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581526756286621
Epoch 10, training loss: 9.825417518615723
Epoch 20, training loss: 9.060553550720215
Epoch 30, training loss: 8.61879825592041
Epoch 40, training loss: 8.140669822692871
Epoch 50, training loss: 7.83327054977417
Epoch 60, training loss: 7.734339237213135
Epoch 70, training loss: 7.57811164855957
Epoch 80, training loss: 7.548780918121338
Epoch 90, training loss: 7.4490180015563965
Epoch 100, training loss: 7.386012077331543
Epoch 110, training loss: 7.3675665855407715
Epoch 120, training loss: 7.382522106170654
Epoch 130, training loss: 7.313227653503418
Epoch 140, training loss: 7.265530109405518
Epoch 150, training loss: 7.209245204925537
Epoch 160, training loss: 7.13835334777832
Epoch 170, training loss: 6.9552226066589355
Epoch 180, training loss: 6.9720025062561035
Epoch 190, training loss: 6.950699329376221
Epoch 200, training loss: 6.934289932250977
Epoch 210, training loss: 6.863667964935303
Epoch 220, training loss: 6.793176651000977
Epoch 230, training loss: 6.7449140548706055
Epoch 240, training loss: 6.706460475921631
Epoch 250, training loss: 6.675744533538818
Epoch 260, training loss: 6.692808628082275
Epoch 270, training loss: 6.6090312004089355
Epoch 280, training loss: 6.537306308746338
Epoch 290, training loss: 6.530946731567383
Epoch 300, training loss: 6.528382778167725
Epoch 310, training loss: 6.470162868499756
Epoch 320, training loss: 6.46318244934082
Epoch 330, training loss: 6.512094020843506
Epoch 340, training loss: 6.452958106994629
Epoch 350, training loss: 6.485410690307617
Epoch 360, training loss: 6.428803443908691
Epoch 370, training loss: 6.442851543426514
Epoch 380, training loss: 6.47528076171875
Epoch 390, training loss: 6.4862775802612305
Epoch 400, training loss: 6.375847816467285
Epoch 410, training loss: 6.4677510261535645
Epoch 420, training loss: 6.386756896972656
Epoch 430, training loss: 6.408147811889648
Epoch 440, training loss: 6.336057662963867
Epoch 450, training loss: 6.38533878326416
Epoch 460, training loss: 6.347006320953369
Epoch 470, training loss: 6.320061683654785
Epoch 480, training loss: 6.32084321975708
Epoch 490, training loss: 6.303074359893799
random
Accuracy: 0.747
Accuracy: 0.745
Accuracy: 0.723
Accuracy: 0.707
Accuracy: 0.687
Accuracy: 0.682
Accuracy: 0.66
Accuracy: 0.632
Accuracy: 0.616
Accuracy: 0.61
Accuracy: 0.592
Accuracy: 0.576
Accuracy: 0.558
Accuracy: 0.562
Accuracy: 0.562
Accuracy: 0.547
Accuracy: 0.57
Accuracy: 0.551
Accuracy: 0.547
Accuracy: 0.582
Accuracy: 0.586
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.581592559814453
Epoch 10, training loss: 9.95849609375
Epoch 20, training loss: 9.111417770385742
Epoch 30, training loss: 8.489398956298828
Epoch 40, training loss: 8.040721893310547
Epoch 50, training loss: 7.826661586761475
Epoch 60, training loss: 7.620605945587158
Epoch 70, training loss: 7.591456890106201
Epoch 80, training loss: 7.452426910400391
Epoch 90, training loss: 7.476887226104736
Epoch 100, training loss: 7.345775604248047
Epoch 110, training loss: 7.325119972229004
Epoch 120, training loss: 7.221913814544678
Epoch 130, training loss: 7.146179676055908
Epoch 140, training loss: 7.154606342315674
Epoch 150, training loss: 7.028973579406738
Epoch 160, training loss: 6.976997375488281
Epoch 170, training loss: 6.951752662658691
Epoch 180, training loss: 6.814360618591309
Epoch 190, training loss: 6.859416484832764
Epoch 200, training loss: 6.787228584289551
Epoch 210, training loss: 6.7562479972839355
Epoch 220, training loss: 6.758834362030029
Epoch 230, training loss: 6.733438968658447
Epoch 240, training loss: 6.730579376220703
Epoch 250, training loss: 6.68031644821167
Epoch 260, training loss: 6.7019944190979
Epoch 270, training loss: 6.631917953491211
Epoch 280, training loss: 6.615625858306885
Epoch 290, training loss: 6.623952388763428
Epoch 300, training loss: 6.610481262207031
Epoch 310, training loss: 6.624320983886719
Epoch 320, training loss: 6.555861473083496
Epoch 330, training loss: 6.529088020324707
Epoch 340, training loss: 6.6380696296691895
Epoch 350, training loss: 6.51918888092041
Epoch 360, training loss: 6.599274158477783
Epoch 370, training loss: 6.486871242523193
Epoch 380, training loss: 6.479996681213379
Epoch 390, training loss: 6.543014049530029
Epoch 400, training loss: 6.567205905914307
Epoch 410, training loss: 6.499866008758545
Epoch 420, training loss: 6.524564743041992
Epoch 430, training loss: 6.483365535736084
Epoch 440, training loss: 6.482114791870117
Epoch 450, training loss: 6.432811737060547
Epoch 460, training loss: 6.488500118255615
Epoch 470, training loss: 6.469241142272949
Epoch 480, training loss: 6.409575462341309
Epoch 490, training loss: 6.475776672363281
random
Accuracy: 0.762
Accuracy: 0.757
Accuracy: 0.739
Accuracy: 0.732
Accuracy: 0.723
Accuracy: 0.712
Accuracy: 0.694
Accuracy: 0.672
Accuracy: 0.648
Accuracy: 0.639
Accuracy: 0.631
Accuracy: 0.612
Accuracy: 0.608
Accuracy: 0.605
Accuracy: 0.603
Accuracy: 0.586
Accuracy: 0.594
Accuracy: 0.594
Accuracy: 0.591
Accuracy: 0.582
Accuracy: 0.589
Beta:0.7 Ptb size:0 Accuracy:0.7628+-0.0090
Beta:0.7 Ptb size:1 Accuracy:0.7584+-0.0074
Beta:0.7 Ptb size:2 Accuracy:0.7306+-0.0069
Beta:0.7 Ptb size:3 Accuracy:0.7182+-0.0130
Beta:0.7 Ptb size:4 Accuracy:0.6984+-0.0225
Beta:0.7 Ptb size:5 Accuracy:0.6844+-0.0220
Beta:0.7 Ptb size:6 Accuracy:0.6624+-0.0217
Beta:0.7 Ptb size:7 Accuracy:0.6380+-0.0225
Beta:0.7 Ptb size:8 Accuracy:0.6186+-0.0184
Beta:0.7 Ptb size:9 Accuracy:0.6146+-0.0162
Beta:0.7 Ptb size:10 Accuracy:0.5934+-0.0215
Beta:0.7 Ptb size:11 Accuracy:0.5734+-0.0210
Beta:0.7 Ptb size:12 Accuracy:0.5656+-0.0218
Beta:0.7 Ptb size:13 Accuracy:0.5628+-0.0226
Beta:0.7 Ptb size:14 Accuracy:0.5634+-0.0213
Beta:0.7 Ptb size:15 Accuracy:0.5492+-0.0207
Beta:0.7 Ptb size:16 Accuracy:0.5566+-0.0243
Beta:0.7 Ptb size:17 Accuracy:0.5526+-0.0238
Beta:0.7 Ptb size:18 Accuracy:0.5510+-0.0239
Beta:0.7 Ptb size:19 Accuracy:0.5584+-0.0232
Beta:0.7 Ptb size:20 Accuracy:0.5590+-0.0273
beta 0.8
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581470489501953
Epoch 10, training loss: 9.974791526794434
Epoch 20, training loss: 8.959583282470703
Epoch 30, training loss: 8.656542778015137
Epoch 40, training loss: 8.283493995666504
Epoch 50, training loss: 8.248835563659668
Epoch 60, training loss: 7.977474212646484
Epoch 70, training loss: 7.7955827713012695
Epoch 80, training loss: 7.6330976486206055
Epoch 90, training loss: 7.567569732666016
Epoch 100, training loss: 7.401541233062744
Epoch 110, training loss: 7.270899772644043
Epoch 120, training loss: 7.270899772644043
Epoch 130, training loss: 7.1724162101745605
Epoch 140, training loss: 7.130995750427246
Epoch 150, training loss: 7.071427345275879
Epoch 160, training loss: 7.0053205490112305
Epoch 170, training loss: 7.002467155456543
Epoch 180, training loss: 6.971195697784424
Epoch 190, training loss: 6.9032135009765625
Epoch 200, training loss: 6.922976493835449
Epoch 210, training loss: 6.8947625160217285
Epoch 220, training loss: 6.912586688995361
Epoch 230, training loss: 6.926095962524414
Epoch 240, training loss: 6.8217973709106445
Epoch 250, training loss: 6.757457256317139
Epoch 260, training loss: 6.785451889038086
Epoch 270, training loss: 6.847073554992676
Epoch 280, training loss: 6.7653422355651855
Epoch 290, training loss: 6.824305534362793
Epoch 300, training loss: 6.705544471740723
Epoch 310, training loss: 6.708021640777588
Epoch 320, training loss: 6.653352737426758
Epoch 330, training loss: 6.683460235595703
Epoch 340, training loss: 6.633170127868652
Epoch 350, training loss: 6.606031894683838
Epoch 360, training loss: 6.566136360168457
Epoch 370, training loss: 6.591408729553223
Epoch 380, training loss: 6.578619003295898
Epoch 390, training loss: 6.521012306213379
Epoch 400, training loss: 6.600225925445557
Epoch 410, training loss: 6.536993980407715
Epoch 420, training loss: 6.545947074890137
Epoch 430, training loss: 6.481463432312012
Epoch 440, training loss: 6.45280647277832
Epoch 450, training loss: 6.5250372886657715
Epoch 460, training loss: 6.439734935760498
Epoch 470, training loss: 6.467597007751465
Epoch 480, training loss: 6.404537677764893
Epoch 490, training loss: 6.398570537567139
random
Accuracy: 0.758
Accuracy: 0.759
Accuracy: 0.727
Accuracy: 0.721
Accuracy: 0.698
Accuracy: 0.67
Accuracy: 0.639
Accuracy: 0.605
Accuracy: 0.59
Accuracy: 0.577
Accuracy: 0.557
Accuracy: 0.531
Accuracy: 0.526
Accuracy: 0.519
Accuracy: 0.506
Accuracy: 0.502
Accuracy: 0.494
Accuracy: 0.496
Accuracy: 0.484
Accuracy: 0.481
Accuracy: 0.473
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581525802612305
Epoch 10, training loss: 9.840097427368164
Epoch 20, training loss: 9.114147186279297
Epoch 30, training loss: 8.79458999633789
Epoch 40, training loss: 8.452119827270508
Epoch 50, training loss: 8.17099666595459
Epoch 60, training loss: 8.020777702331543
Epoch 70, training loss: 7.818587779998779
Epoch 80, training loss: 7.615771293640137
Epoch 90, training loss: 7.460598945617676
Epoch 100, training loss: 7.333982944488525
Epoch 110, training loss: 7.293724060058594
Epoch 120, training loss: 7.19854211807251
Epoch 130, training loss: 7.113203525543213
Epoch 140, training loss: 7.118888854980469
Epoch 150, training loss: 7.072432994842529
Epoch 160, training loss: 7.061890125274658
Epoch 170, training loss: 7.035251140594482
Epoch 180, training loss: 6.92580509185791
Epoch 190, training loss: 6.9727091789245605
Epoch 200, training loss: 6.907099723815918
Epoch 210, training loss: 6.792247772216797
Epoch 220, training loss: 6.764237403869629
Epoch 230, training loss: 6.827298641204834
Epoch 240, training loss: 6.698005199432373
Epoch 250, training loss: 6.686009407043457
Epoch 260, training loss: 6.604318141937256
Epoch 270, training loss: 6.665127277374268
Epoch 280, training loss: 6.568779468536377
Epoch 290, training loss: 6.65280294418335
Epoch 300, training loss: 6.598313331604004
Epoch 310, training loss: 6.48214054107666
Epoch 320, training loss: 6.543200492858887
Epoch 330, training loss: 6.50681209564209
Epoch 340, training loss: 6.451908111572266
Epoch 350, training loss: 6.475570201873779
Epoch 360, training loss: 6.503443241119385
Epoch 370, training loss: 6.450647830963135
Epoch 380, training loss: 6.383746147155762
Epoch 390, training loss: 6.454535961151123
Epoch 400, training loss: 6.349013805389404
Epoch 410, training loss: 6.332727909088135
Epoch 420, training loss: 6.316500663757324
Epoch 430, training loss: 6.397770881652832
Epoch 440, training loss: 6.347677707672119
Epoch 450, training loss: 6.360086441040039
Epoch 460, training loss: 6.386183261871338
Epoch 470, training loss: 6.323883056640625
Epoch 480, training loss: 6.281527042388916
Epoch 490, training loss: 6.290874004364014
random
Accuracy: 0.755
Accuracy: 0.747
Accuracy: 0.707
Accuracy: 0.698
Accuracy: 0.68
Accuracy: 0.645
Accuracy: 0.621
Accuracy: 0.603
Accuracy: 0.604
Accuracy: 0.597
Accuracy: 0.578
Accuracy: 0.551
Accuracy: 0.55
Accuracy: 0.553
Accuracy: 0.557
Accuracy: 0.546
Accuracy: 0.556
Accuracy: 0.561
Accuracy: 0.558
Accuracy: 0.555
Accuracy: 0.552
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.58137035369873
Epoch 10, training loss: 9.86921215057373
Epoch 20, training loss: 9.079938888549805
Epoch 30, training loss: 8.736745834350586
Epoch 40, training loss: 8.319289207458496
Epoch 50, training loss: 8.06700611114502
Epoch 60, training loss: 7.803497791290283
Epoch 70, training loss: 7.595583915710449
Epoch 80, training loss: 7.3457183837890625
Epoch 90, training loss: 7.284659385681152
Epoch 100, training loss: 7.160787105560303
Epoch 110, training loss: 7.170299530029297
Epoch 120, training loss: 7.095799446105957
Epoch 130, training loss: 7.096085548400879
Epoch 140, training loss: 7.037650108337402
Epoch 150, training loss: 6.988704204559326
Epoch 160, training loss: 6.924091815948486
Epoch 170, training loss: 6.944275856018066
Epoch 180, training loss: 6.794310092926025
Epoch 190, training loss: 6.810639381408691
Epoch 200, training loss: 6.7268524169921875
Epoch 210, training loss: 6.745530605316162
Epoch 220, training loss: 6.688150882720947
Epoch 230, training loss: 6.737949848175049
Epoch 240, training loss: 6.676547527313232
Epoch 250, training loss: 6.711212158203125
Epoch 260, training loss: 6.57765531539917
Epoch 270, training loss: 6.6000471115112305
Epoch 280, training loss: 6.5961408615112305
Epoch 290, training loss: 6.581509113311768
Epoch 300, training loss: 6.612247943878174
Epoch 310, training loss: 6.588934421539307
Epoch 320, training loss: 6.558873176574707
Epoch 330, training loss: 6.532121658325195
Epoch 340, training loss: 6.493654251098633
Epoch 350, training loss: 6.52343225479126
Epoch 360, training loss: 6.437628269195557
Epoch 370, training loss: 6.450020790100098
Epoch 380, training loss: 6.3884735107421875
Epoch 390, training loss: 6.472202777862549
Epoch 400, training loss: 6.463267803192139
Epoch 410, training loss: 6.40530252456665
Epoch 420, training loss: 6.414230823516846
Epoch 430, training loss: 6.443276405334473
Epoch 440, training loss: 6.363002777099609
Epoch 450, training loss: 6.411736011505127
Epoch 460, training loss: 6.477327823638916
Epoch 470, training loss: 6.403835296630859
Epoch 480, training loss: 6.396032810211182
Epoch 490, training loss: 6.342548847198486
random
Accuracy: 0.775
Accuracy: 0.762
Accuracy: 0.704
Accuracy: 0.687
Accuracy: 0.663
Accuracy: 0.644
Accuracy: 0.623
Accuracy: 0.6
Accuracy: 0.582
Accuracy: 0.57
Accuracy: 0.56
Accuracy: 0.545
Accuracy: 0.548
Accuracy: 0.543
Accuracy: 0.54
Accuracy: 0.532
Accuracy: 0.535
Accuracy: 0.536
Accuracy: 0.537
Accuracy: 0.545
Accuracy: 0.544
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.58150863647461
Epoch 10, training loss: 9.890412330627441
Epoch 20, training loss: 9.02631664276123
Epoch 30, training loss: 8.600343704223633
Epoch 40, training loss: 8.106682777404785
Epoch 50, training loss: 7.805325031280518
Epoch 60, training loss: 7.706801414489746
Epoch 70, training loss: 7.538614273071289
Epoch 80, training loss: 7.510154724121094
Epoch 90, training loss: 7.405508518218994
Epoch 100, training loss: 7.352175712585449
Epoch 110, training loss: 7.329062461853027
Epoch 120, training loss: 7.357015132904053
Epoch 130, training loss: 7.277692794799805
Epoch 140, training loss: 7.236111164093018
Epoch 150, training loss: 7.220225811004639
Epoch 160, training loss: 7.128153324127197
Epoch 170, training loss: 6.9712700843811035
Epoch 180, training loss: 6.990257740020752
Epoch 190, training loss: 6.973753929138184
Epoch 200, training loss: 6.938073635101318
Epoch 210, training loss: 6.856264114379883
Epoch 220, training loss: 6.763801574707031
Epoch 230, training loss: 6.73274564743042
Epoch 240, training loss: 6.6808085441589355
Epoch 250, training loss: 6.641110897064209
Epoch 260, training loss: 6.651106834411621
Epoch 270, training loss: 6.579555511474609
Epoch 280, training loss: 6.4988555908203125
Epoch 290, training loss: 6.496188163757324
Epoch 300, training loss: 6.4893574714660645
Epoch 310, training loss: 6.433404445648193
Epoch 320, training loss: 6.429254055023193
Epoch 330, training loss: 6.469802379608154
Epoch 340, training loss: 6.4164838790893555
Epoch 350, training loss: 6.4658918380737305
Epoch 360, training loss: 6.405026435852051
Epoch 370, training loss: 6.410682201385498
Epoch 380, training loss: 6.455453395843506
Epoch 390, training loss: 6.453709125518799
Epoch 400, training loss: 6.347468376159668
Epoch 410, training loss: 6.441606521606445
Epoch 420, training loss: 6.353267192840576
Epoch 430, training loss: 6.366936206817627
Epoch 440, training loss: 6.302537441253662
Epoch 450, training loss: 6.356995105743408
Epoch 460, training loss: 6.3150954246521
Epoch 470, training loss: 6.277035236358643
Epoch 480, training loss: 6.2723774909973145
Epoch 490, training loss: 6.258199691772461
random
Accuracy: 0.752
Accuracy: 0.746
Accuracy: 0.734
Accuracy: 0.728
Accuracy: 0.702
Accuracy: 0.691
Accuracy: 0.677
Accuracy: 0.642
Accuracy: 0.638
Accuracy: 0.633
Accuracy: 0.616
Accuracy: 0.6
Accuracy: 0.597
Accuracy: 0.602
Accuracy: 0.586
Accuracy: 0.586
Accuracy: 0.59
Accuracy: 0.597
Accuracy: 0.592
Accuracy: 0.59
Accuracy: 0.591
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.58156967163086
Epoch 10, training loss: 10.018061637878418
Epoch 20, training loss: 9.094783782958984
Epoch 30, training loss: 8.59158706665039
Epoch 40, training loss: 8.120452880859375
Epoch 50, training loss: 7.832009792327881
Epoch 60, training loss: 7.608333110809326
Epoch 70, training loss: 7.577224254608154
Epoch 80, training loss: 7.382241725921631
Epoch 90, training loss: 7.3659162521362305
Epoch 100, training loss: 7.218360424041748
Epoch 110, training loss: 7.238557815551758
Epoch 120, training loss: 7.048547267913818
Epoch 130, training loss: 6.952482223510742
Epoch 140, training loss: 6.96091890335083
Epoch 150, training loss: 6.9109907150268555
Epoch 160, training loss: 6.842507362365723
Epoch 170, training loss: 6.836313724517822
Epoch 180, training loss: 6.709508419036865
Epoch 190, training loss: 6.7705278396606445
Epoch 200, training loss: 6.715009689331055
Epoch 210, training loss: 6.680209636688232
Epoch 220, training loss: 6.692122459411621
Epoch 230, training loss: 6.670985221862793
Epoch 240, training loss: 6.663433074951172
Epoch 250, training loss: 6.624553203582764
Epoch 260, training loss: 6.646286487579346
Epoch 270, training loss: 6.5738067626953125
Epoch 280, training loss: 6.55830717086792
Epoch 290, training loss: 6.569914817810059
Epoch 300, training loss: 6.563498020172119
Epoch 310, training loss: 6.569859504699707
Epoch 320, training loss: 6.5037078857421875
Epoch 330, training loss: 6.475493431091309
Epoch 340, training loss: 6.583983421325684
Epoch 350, training loss: 6.467226028442383
Epoch 360, training loss: 6.54213285446167
Epoch 370, training loss: 6.436577796936035
Epoch 380, training loss: 6.429843902587891
Epoch 390, training loss: 6.485616683959961
Epoch 400, training loss: 6.522735118865967
Epoch 410, training loss: 6.448395252227783
Epoch 420, training loss: 6.468850135803223
Epoch 430, training loss: 6.429104804992676
Epoch 440, training loss: 6.433621883392334
Epoch 450, training loss: 6.3792500495910645
Epoch 460, training loss: 6.438315391540527
Epoch 470, training loss: 6.418493747711182
Epoch 480, training loss: 6.3600172996521
Epoch 490, training loss: 6.430154800415039
random
Accuracy: 0.745
Accuracy: 0.746
Accuracy: 0.739
Accuracy: 0.733
Accuracy: 0.721
Accuracy: 0.697
Accuracy: 0.68
Accuracy: 0.662
Accuracy: 0.653
Accuracy: 0.637
Accuracy: 0.626
Accuracy: 0.601
Accuracy: 0.597
Accuracy: 0.596
Accuracy: 0.598
Accuracy: 0.569
Accuracy: 0.582
Accuracy: 0.578
Accuracy: 0.575
Accuracy: 0.565
Accuracy: 0.564
Beta:0.8 Ptb size:0 Accuracy:0.7570+-0.0100
Beta:0.8 Ptb size:1 Accuracy:0.7520+-0.0070
Beta:0.8 Ptb size:2 Accuracy:0.7222+-0.0142
Beta:0.8 Ptb size:3 Accuracy:0.7134+-0.0178
Beta:0.8 Ptb size:4 Accuracy:0.6928+-0.0198
Beta:0.8 Ptb size:5 Accuracy:0.6694+-0.0222
Beta:0.8 Ptb size:6 Accuracy:0.6480+-0.0257
Beta:0.8 Ptb size:7 Accuracy:0.6224+-0.0250
Beta:0.8 Ptb size:8 Accuracy:0.6134+-0.0276
Beta:0.8 Ptb size:9 Accuracy:0.6028+-0.0278
Beta:0.8 Ptb size:10 Accuracy:0.5874+-0.0285
Beta:0.8 Ptb size:11 Accuracy:0.5656+-0.0292
Beta:0.8 Ptb size:12 Accuracy:0.5636+-0.0285
Beta:0.8 Ptb size:13 Accuracy:0.5626+-0.0318
Beta:0.8 Ptb size:14 Accuracy:0.5574+-0.0329
Beta:0.8 Ptb size:15 Accuracy:0.5470+-0.0292
Beta:0.8 Ptb size:16 Accuracy:0.5514+-0.0347
Beta:0.8 Ptb size:17 Accuracy:0.5536+-0.0351
Beta:0.8 Ptb size:18 Accuracy:0.5492+-0.0373
Beta:0.8 Ptb size:19 Accuracy:0.5472+-0.0363
Beta:0.8 Ptb size:20 Accuracy:0.5448+-0.0393
beta 0.9
seed 265
=== training gcn model ===
Epoch 0, training loss: 10.581446647644043
Epoch 10, training loss: 10.049641609191895
Epoch 20, training loss: 8.928276062011719
Epoch 30, training loss: 8.653913497924805
Epoch 40, training loss: 8.272063255310059
Epoch 50, training loss: 8.213778495788574
Epoch 60, training loss: 7.9695210456848145
Epoch 70, training loss: 7.8928937911987305
Epoch 80, training loss: 7.7875518798828125
Epoch 90, training loss: 7.705564975738525
Epoch 100, training loss: 7.502384662628174
Epoch 110, training loss: 7.415468692779541
Epoch 120, training loss: 7.36945104598999
Epoch 130, training loss: 7.22626256942749
Epoch 140, training loss: 7.189611911773682
Epoch 150, training loss: 7.097189426422119
Epoch 160, training loss: 7.03580904006958
Epoch 170, training loss: 7.024775505065918
Epoch 180, training loss: 6.973827362060547
Epoch 190, training loss: 6.903012275695801
Epoch 200, training loss: 6.905706405639648
Epoch 210, training loss: 6.880715370178223
Epoch 220, training loss: 6.8888983726501465
Epoch 230, training loss: 6.901864528656006
Epoch 240, training loss: 6.7992262840271
Epoch 250, training loss: 6.7315802574157715
Epoch 260, training loss: 6.768848896026611
Epoch 270, training loss: 6.809818267822266
Epoch 280, training loss: 6.722875595092773
Epoch 290, training loss: 6.785231590270996
Epoch 300, training loss: 6.669760227203369
Epoch 310, training loss: 6.654688835144043
Epoch 320, training loss: 6.595388412475586
Epoch 330, training loss: 6.6277689933776855
Epoch 340, training loss: 6.608993053436279
Epoch 350, training loss: 6.5579657554626465
Epoch 360, training loss: 6.512030124664307
Epoch 370, training loss: 6.553311824798584
Epoch 380, training loss: 6.531888961791992
Epoch 390, training loss: 6.485457420349121
Epoch 400, training loss: 6.549045562744141
Epoch 410, training loss: 6.490661144256592
Epoch 420, training loss: 6.500053405761719
Epoch 430, training loss: 6.442039489746094
Epoch 440, training loss: 6.403905868530273
Epoch 450, training loss: 6.471620082855225
Epoch 460, training loss: 6.400798797607422
Epoch 470, training loss: 6.424436569213867
Epoch 480, training loss: 6.363584041595459
Epoch 490, training loss: 6.349820137023926
random
Accuracy: 0.76
Accuracy: 0.75
Accuracy: 0.734
Accuracy: 0.717
Accuracy: 0.702
Accuracy: 0.679
Accuracy: 0.652
Accuracy: 0.609
Accuracy: 0.593
Accuracy: 0.583
Accuracy: 0.562
Accuracy: 0.545
Accuracy: 0.534
Accuracy: 0.528
Accuracy: 0.521
Accuracy: 0.508
Accuracy: 0.5
Accuracy: 0.499
Accuracy: 0.49
Accuracy: 0.481
Accuracy: 0.473
seed 125
=== training gcn model ===
Epoch 0, training loss: 10.581510543823242
Epoch 10, training loss: 9.875667572021484
Epoch 20, training loss: 9.080034255981445
Epoch 30, training loss: 8.745521545410156
Epoch 40, training loss: 8.41556167602539
Epoch 50, training loss: 8.13418197631836
Epoch 60, training loss: 8.00105094909668
Epoch 70, training loss: 7.8349080085754395
Epoch 80, training loss: 7.6496124267578125
Epoch 90, training loss: 7.488244533538818
Epoch 100, training loss: 7.338603973388672
Epoch 110, training loss: 7.27644157409668
Epoch 120, training loss: 7.1638054847717285
Epoch 130, training loss: 7.092641353607178
Epoch 140, training loss: 7.074581146240234
Epoch 150, training loss: 7.036901950836182
Epoch 160, training loss: 7.013089179992676
Epoch 170, training loss: 6.976950645446777
Epoch 180, training loss: 6.861595630645752
Epoch 190, training loss: 6.90608549118042
Epoch 200, training loss: 6.8215556144714355
Epoch 210, training loss: 6.685914993286133
Epoch 220, training loss: 6.681189060211182
Epoch 230, training loss: 6.725710868835449
Epoch 240, training loss: 6.600164890289307
Epoch 250, training loss: 6.601903915405273
Epoch 260, training loss: 6.527978897094727
Epoch 270, training loss: 6.577605247497559
Epoch 280, training loss: 6.488771915435791
Epoch 290, training loss: 6.576174259185791
Epoch 300, training loss: 6.534694194793701
Epoch 310, training loss: 6.407631874084473
Epoch 320, training loss: 6.476798057556152
Epoch 330, training loss: 6.4394354820251465
Epoch 340, training loss: 6.379323959350586
Epoch 350, training loss: 6.415260314941406
Epoch 360, training loss: 6.449469089508057
Epoch 370, training loss: 6.393631935119629
Epoch 380, training loss: 6.320766925811768
Epoch 390, training loss: 6.389344215393066
Epoch 400, training loss: 6.281216621398926
Epoch 410, training loss: 6.269102573394775
Epoch 420, training loss: 6.241465091705322
Epoch 430, training loss: 6.3363494873046875
Epoch 440, training loss: 6.278925895690918
Epoch 450, training loss: 6.3133015632629395
Epoch 460, training loss: 6.331394672393799
Epoch 470, training loss: 6.260209560394287
Epoch 480, training loss: 6.215749740600586
Epoch 490, training loss: 6.227220058441162
random
Accuracy: 0.739
Accuracy: 0.749
Accuracy: 0.714
Accuracy: 0.688
Accuracy: 0.647
Accuracy: 0.618
Accuracy: 0.602
Accuracy: 0.566
Accuracy: 0.563
Accuracy: 0.556
Accuracy: 0.543
Accuracy: 0.516
Accuracy: 0.517
Accuracy: 0.516
Accuracy: 0.507
Accuracy: 0.502
Accuracy: 0.5
Accuracy: 0.498
Accuracy: 0.5
Accuracy: 0.503
Accuracy: 0.501
seed 996
=== training gcn model ===
Epoch 0, training loss: 10.581353187561035
Epoch 10, training loss: 9.932039260864258
Epoch 20, training loss: 9.047590255737305
Epoch 30, training loss: 8.708252906799316
Epoch 40, training loss: 8.311010360717773
Epoch 50, training loss: 8.067643165588379
Epoch 60, training loss: 7.768919467926025
Epoch 70, training loss: 7.600329875946045
Epoch 80, training loss: 7.342249870300293
Epoch 90, training loss: 7.264334201812744
Epoch 100, training loss: 7.154214859008789
Epoch 110, training loss: 7.14194917678833
Epoch 120, training loss: 7.067050457000732
Epoch 130, training loss: 7.061617374420166
Epoch 140, training loss: 7.0036115646362305
Epoch 150, training loss: 6.962259769439697
Epoch 160, training loss: 6.894009113311768
Epoch 170, training loss: 6.907421588897705
Epoch 180, training loss: 6.753897666931152
Epoch 190, training loss: 6.764584541320801
Epoch 200, training loss: 6.692216873168945
Epoch 210, training loss: 6.700379371643066
Epoch 220, training loss: 6.653635025024414
Epoch 230, training loss: 6.700505256652832
Epoch 240, training loss: 6.634067535400391
Epoch 250, training loss: 6.685419082641602
Epoch 260, training loss: 6.548065662384033
Epoch 270, training loss: 6.562817096710205
Epoch 280, training loss: 6.558178424835205
Epoch 290, training loss: 6.546792507171631
Epoch 300, training loss: 6.580865383148193
Epoch 310, training loss: 6.54789400100708
Epoch 320, training loss: 6.508659362792969
Epoch 330, training loss: 6.493076801300049
Epoch 340, training loss: 6.462869167327881
Epoch 350, training loss: 6.492597579956055
Epoch 360, training loss: 6.406490325927734
Epoch 370, training loss: 6.414940357208252
Epoch 380, training loss: 6.3488688468933105
Epoch 390, training loss: 6.4374189376831055
Epoch 400, training loss: 6.424155235290527
Epoch 410, training loss: 6.369709014892578
Epoch 420, training loss: 6.367344856262207
Epoch 430, training loss: 6.395148277282715
Epoch 440, training loss: 6.314118385314941
Epoch 450, training loss: 6.370113372802734
Epoch 460, training loss: 6.428582191467285
Epoch 470, training loss: 6.3706159591674805
Epoch 480, training loss: 6.352768898010254
Epoch 490, training loss: 6.300175666809082
random
Accuracy: 0.764
Accuracy: 0.751
Accuracy: 0.693
Accuracy: 0.669
Accuracy: 0.655
Accuracy: 0.628
Accuracy: 0.611
Accuracy: 0.589
Accuracy: 0.584
Accuracy: 0.577
Accuracy: 0.568
Accuracy: 0.559
Accuracy: 0.554
Accuracy: 0.551
Accuracy: 0.552
Accuracy: 0.542
Accuracy: 0.543
Accuracy: 0.548
Accuracy: 0.55
Accuracy: 0.557
Accuracy: 0.55
seed 527
=== training gcn model ===
Epoch 0, training loss: 10.581489562988281
Epoch 10, training loss: 9.960249900817871
Epoch 20, training loss: 8.987285614013672
Epoch 30, training loss: 8.603071212768555
Epoch 40, training loss: 8.1016206741333
Epoch 50, training loss: 7.798273086547852
Epoch 60, training loss: 7.680519104003906
Epoch 70, training loss: 7.502296447753906
Epoch 80, training loss: 7.47305965423584
Epoch 90, training loss: 7.375195026397705
Epoch 100, training loss: 7.330644130706787
Epoch 110, training loss: 7.3004255294799805
Epoch 120, training loss: 7.334394454956055
Epoch 130, training loss: 7.243132591247559
Epoch 140, training loss: 7.206604957580566
Epoch 150, training loss: 7.207516193389893
Epoch 160, training loss: 7.119134426116943
Epoch 170, training loss: 6.983444690704346
Epoch 180, training loss: 7.005862712860107
Epoch 190, training loss: 7.009124755859375
Epoch 200, training loss: 6.979515075683594
Epoch 210, training loss: 6.888667106628418
Epoch 220, training loss: 6.803730487823486
Epoch 230, training loss: 6.788377285003662
Epoch 240, training loss: 6.707390785217285
Epoch 250, training loss: 6.6839728355407715
Epoch 260, training loss: 6.671863079071045
Epoch 270, training loss: 6.604922771453857
Epoch 280, training loss: 6.507249355316162
Epoch 290, training loss: 6.51096773147583
Epoch 300, training loss: 6.494460582733154
Epoch 310, training loss: 6.431219100952148
Epoch 320, training loss: 6.404064655303955
Epoch 330, training loss: 6.443315029144287
Epoch 340, training loss: 6.399992942810059
Epoch 350, training loss: 6.457444190979004
Epoch 360, training loss: 6.393157958984375
Epoch 370, training loss: 6.379968643188477
Epoch 380, training loss: 6.439535617828369
Epoch 390, training loss: 6.433835506439209
Epoch 400, training loss: 6.326974391937256
Epoch 410, training loss: 6.418266296386719
Epoch 420, training loss: 6.330756187438965
Epoch 430, training loss: 6.345627307891846
Epoch 440, training loss: 6.284298419952393
Epoch 450, training loss: 6.352750301361084
Epoch 460, training loss: 6.299291133880615
Epoch 470, training loss: 6.256180286407471
Epoch 480, training loss: 6.242668151855469
Epoch 490, training loss: 6.232709884643555
random
Accuracy: 0.766
Accuracy: 0.755
Accuracy: 0.743
Accuracy: 0.739
Accuracy: 0.72
Accuracy: 0.692
Accuracy: 0.67
Accuracy: 0.633
Accuracy: 0.613
Accuracy: 0.6
Accuracy: 0.588
Accuracy: 0.566
Accuracy: 0.557
Accuracy: 0.554
Accuracy: 0.551
Accuracy: 0.526
Accuracy: 0.523
Accuracy: 0.528
Accuracy: 0.522
Accuracy: 0.519
Accuracy: 0.517
seed 320
=== training gcn model ===
Epoch 0, training loss: 10.581554412841797
Epoch 10, training loss: 10.077397346496582
Epoch 20, training loss: 9.097452163696289
Epoch 30, training loss: 8.6343355178833
Epoch 40, training loss: 8.271575927734375
Epoch 50, training loss: 7.908226490020752
Epoch 60, training loss: 7.614261627197266
Epoch 70, training loss: 7.565509796142578
Epoch 80, training loss: 7.3791890144348145
Epoch 90, training loss: 7.344091892242432
Epoch 100, training loss: 7.1546525955200195
Epoch 110, training loss: 7.167313098907471
Epoch 120, training loss: 6.9466681480407715
Epoch 130, training loss: 6.875479698181152
Epoch 140, training loss: 6.895035743713379
Epoch 150, training loss: 6.8512983322143555
Epoch 160, training loss: 6.79132604598999
Epoch 170, training loss: 6.794225692749023
Epoch 180, training loss: 6.637635231018066
Epoch 190, training loss: 6.714696884155273
Epoch 200, training loss: 6.66841459274292
Epoch 210, training loss: 6.6331305503845215
Epoch 220, training loss: 6.664279460906982
Epoch 230, training loss: 6.641615867614746
Epoch 240, training loss: 6.638721466064453
Epoch 250, training loss: 6.581048011779785
Epoch 260, training loss: 6.620299339294434
Epoch 270, training loss: 6.543059349060059
Epoch 280, training loss: 6.530162811279297
Epoch 290, training loss: 6.535271644592285
Epoch 300, training loss: 6.545183181762695
Epoch 310, training loss: 6.564036846160889
Epoch 320, training loss: 6.493505477905273
Epoch 330, training loss: 6.464699745178223
Epoch 340, training loss: 6.60184383392334
Epoch 350, training loss: 6.473143577575684
Epoch 360, training loss: 6.5544023513793945
Epoch 370, training loss: 6.448724269866943
Epoch 380, training loss: 6.458438396453857
Epoch 390, training loss: 6.48445463180542
Epoch 400, training loss: 6.54233980178833
Epoch 410, training loss: 6.474523067474365
Epoch 420, training loss: 6.4940876960754395
Epoch 430, training loss: 6.430110931396484
Epoch 440, training loss: 6.419544219970703
Epoch 450, training loss: 6.390765190124512
Epoch 460, training loss: 6.425539493560791
Epoch 470, training loss: 6.418849945068359
Epoch 480, training loss: 6.349727630615234
Epoch 490, training loss: 6.408208847045898
random
Accuracy: 0.746
Accuracy: 0.738
Accuracy: 0.731
Accuracy: 0.727
Accuracy: 0.705
Accuracy: 0.691
Accuracy: 0.679
Accuracy: 0.658
Accuracy: 0.637
Accuracy: 0.632
Accuracy: 0.608
Accuracy: 0.588
Accuracy: 0.576
Accuracy: 0.561
Accuracy: 0.564
Accuracy: 0.546
Accuracy: 0.543
Accuracy: 0.543
Accuracy: 0.535
Accuracy: 0.527
Accuracy: 0.515
Beta:0.9 Ptb size:0 Accuracy:0.7550+-0.0106
Beta:0.9 Ptb size:1 Accuracy:0.7486+-0.0057
Beta:0.9 Ptb size:2 Accuracy:0.7230+-0.0177
Beta:0.9 Ptb size:3 Accuracy:0.7080+-0.0258
Beta:0.9 Ptb size:4 Accuracy:0.6858+-0.0292
Beta:0.9 Ptb size:5 Accuracy:0.6616+-0.0320
Beta:0.9 Ptb size:6 Accuracy:0.6428+-0.0310
Beta:0.9 Ptb size:7 Accuracy:0.6110+-0.0323
Beta:0.9 Ptb size:8 Accuracy:0.5980+-0.0253
Beta:0.9 Ptb size:9 Accuracy:0.5896+-0.0254
Beta:0.9 Ptb size:10 Accuracy:0.5738+-0.0223
Beta:0.9 Ptb size:11 Accuracy:0.5548+-0.0239
Beta:0.9 Ptb size:12 Accuracy:0.5476+-0.0203
Beta:0.9 Ptb size:13 Accuracy:0.5420+-0.0171
Beta:0.9 Ptb size:14 Accuracy:0.5390+-0.0214
Beta:0.9 Ptb size:15 Accuracy:0.5248+-0.0176
Beta:0.9 Ptb size:16 Accuracy:0.5218+-0.0192
Beta:0.9 Ptb size:17 Accuracy:0.5232+-0.0212
Beta:0.9 Ptb size:18 Accuracy:0.5194+-0.0220
Beta:0.9 Ptb size:19 Accuracy:0.5174+-0.0253
Beta:0.9 Ptb size:20 Accuracy:0.5112+-0.0250
