nohup: ignoring input
run_gnn.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Namespace(add_edge_rate_1=0, add_edge_rate_2=0, attack='none', base_model='GCN', cl_activation='relu', cl_base_model='GCNConv', cl_lr=0.0005, cl_num_epochs=200, cl_num_layers=2, cl_num_proj_hidden=128, cl_weight_decay=1e-05, clf_weight=1, config='config.yaml', cont_batch_size=0, cont_weight=1, cuda=True, dataset='Citeseer', debug=True, device_id=2, drop_edge_rate_1=0.2, drop_edge_rate_2=0, drop_feat_rate_1=0.3, drop_feat_rate_2=0.2, dropout=0.5, hidden=128, if_smoothed=True, inv_weight=1, model='GCN', no_cuda=False, noisy_level=0.3, num_hidden=128, num_proj_hidden=128, num_repeat=5, prob=0.8, seed=10, select_target_ratio=0.1, tau=0.1, test_model='GCN', train_lr=0.01, weight_decay=0.0005)
=== training gcn model ===
Epoch 0, training loss: 1.7916218042373657
acc_val: 0.4720
Epoch 10, training loss: 1.531154990196228
acc_val: 0.6140
Epoch 20, training loss: 1.1601821184158325
acc_val: 0.7000
Epoch 30, training loss: 0.7769322991371155
acc_val: 0.7060
Epoch 40, training loss: 0.561577558517456
acc_val: 0.7100
Epoch 50, training loss: 0.46710407733917236
acc_val: 0.7040
Epoch 60, training loss: 0.3987734913825989
acc_val: 0.7200
Epoch 70, training loss: 0.3397555351257324
acc_val: 0.7100
Epoch 80, training loss: 0.2986336946487427
acc_val: 0.7160
Epoch 90, training loss: 0.2786570191383362
acc_val: 0.7120
Epoch 100, training loss: 0.2730715870857239
acc_val: 0.7100
Epoch 110, training loss: 0.24794812500476837
acc_val: 0.7080
Epoch 120, training loss: 0.2402379959821701
acc_val: 0.7000
Epoch 130, training loss: 0.22163425385951996
acc_val: 0.7120
Epoch 140, training loss: 0.2235431969165802
acc_val: 0.7200
Epoch 150, training loss: 0.22156289219856262
acc_val: 0.7100
Epoch 160, training loss: 0.1981835812330246
acc_val: 0.7140
Epoch 170, training loss: 0.19607391953468323
acc_val: 0.7160
Epoch 180, training loss: 0.20874817669391632
acc_val: 0.7140
Epoch 190, training loss: 0.19402462244033813
acc_val: 0.7040
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.714
=== training gcn model ===
Epoch 0, training loss: 1.7913774251937866
acc_val: 0.1900
Epoch 10, training loss: 1.5166467428207397
acc_val: 0.6560
Epoch 20, training loss: 1.1128464937210083
acc_val: 0.7100
Epoch 30, training loss: 0.7546427845954895
acc_val: 0.7080
Epoch 40, training loss: 0.5263909697532654
acc_val: 0.7120
Epoch 50, training loss: 0.43476197123527527
acc_val: 0.7180
Epoch 60, training loss: 0.371206670999527
acc_val: 0.7180
Epoch 70, training loss: 0.33160990476608276
acc_val: 0.7140
Epoch 80, training loss: 0.30186212062835693
acc_val: 0.7180
Epoch 90, training loss: 0.2532865107059479
acc_val: 0.7060
Epoch 100, training loss: 0.26091867685317993
acc_val: 0.7100
Epoch 110, training loss: 0.25442779064178467
acc_val: 0.7080
Epoch 120, training loss: 0.2284328043460846
acc_val: 0.7160
Epoch 130, training loss: 0.22518859803676605
acc_val: 0.7080
Epoch 140, training loss: 0.20836518704891205
acc_val: 0.7140
Epoch 150, training loss: 0.20275090634822845
acc_val: 0.7140
Epoch 160, training loss: 0.20467714965343475
acc_val: 0.7180
Epoch 170, training loss: 0.19289536774158478
acc_val: 0.7180
Epoch 180, training loss: 0.1983957588672638
acc_val: 0.7080
Epoch 190, training loss: 0.19204013049602509
acc_val: 0.7060
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.722
=== training gcn model ===
Epoch 0, training loss: 1.7919995784759521
acc_val: 0.4460
Epoch 10, training loss: 1.5406709909439087
acc_val: 0.6880
Epoch 20, training loss: 1.161729335784912
acc_val: 0.7100
Epoch 30, training loss: 0.817106306552887
acc_val: 0.7140
Epoch 40, training loss: 0.6133403778076172
acc_val: 0.7120
Epoch 50, training loss: 0.49083906412124634
acc_val: 0.7040
Epoch 60, training loss: 0.4198925793170929
acc_val: 0.7220
Epoch 70, training loss: 0.37304648756980896
acc_val: 0.7220
Epoch 80, training loss: 0.31022584438323975
acc_val: 0.7200
Epoch 90, training loss: 0.27435949444770813
acc_val: 0.7100
Epoch 100, training loss: 0.26720598340034485
acc_val: 0.7140
Epoch 110, training loss: 0.24451957643032074
acc_val: 0.7060
Epoch 120, training loss: 0.2503751516342163
acc_val: 0.7260
Epoch 130, training loss: 0.22711485624313354
acc_val: 0.7000
Epoch 140, training loss: 0.21586155891418457
acc_val: 0.7060
Epoch 150, training loss: 0.2194189429283142
acc_val: 0.7100
Epoch 160, training loss: 0.21160639822483063
acc_val: 0.7180
Epoch 170, training loss: 0.2124948799610138
acc_val: 0.7180
Epoch 180, training loss: 0.21461966633796692
acc_val: 0.7060
Epoch 190, training loss: 0.1825236678123474
acc_val: 0.7120
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.716
=== training gcn model ===
Epoch 0, training loss: 1.7916988134384155
acc_val: 0.1680
Epoch 10, training loss: 1.5485179424285889
acc_val: 0.6520
Epoch 20, training loss: 1.177954077720642
acc_val: 0.7240
Epoch 30, training loss: 0.7930660247802734
acc_val: 0.7200
Epoch 40, training loss: 0.5600106120109558
acc_val: 0.7200
Epoch 50, training loss: 0.44202959537506104
acc_val: 0.7100
Epoch 60, training loss: 0.37941157817840576
acc_val: 0.7080
Epoch 70, training loss: 0.3445068597793579
acc_val: 0.7160
Epoch 80, training loss: 0.29473116993904114
acc_val: 0.7140
Epoch 90, training loss: 0.27276724576950073
acc_val: 0.7200
Epoch 100, training loss: 0.27516528964042664
acc_val: 0.7080
Epoch 110, training loss: 0.26498696208000183
acc_val: 0.7200
Epoch 120, training loss: 0.22797413170337677
acc_val: 0.7140
Epoch 130, training loss: 0.22292852401733398
acc_val: 0.7160
Epoch 140, training loss: 0.21974079310894012
acc_val: 0.7060
Epoch 150, training loss: 0.2060171514749527
acc_val: 0.7160
Epoch 160, training loss: 0.2002289593219757
acc_val: 0.7160
Epoch 170, training loss: 0.1891135275363922
acc_val: 0.7040
Epoch 180, training loss: 0.19056397676467896
acc_val: 0.7080
Epoch 190, training loss: 0.18702439963817596
acc_val: 0.7180
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.6960000000000001
=== training gcn model ===
Epoch 0, training loss: 1.7916399240493774
acc_val: 0.1800
Epoch 10, training loss: 1.5229989290237427
acc_val: 0.6380
Epoch 20, training loss: 1.1465718746185303
acc_val: 0.7080
Epoch 30, training loss: 0.7900800704956055
acc_val: 0.7100
Epoch 40, training loss: 0.5770005583763123
acc_val: 0.7220
Epoch 50, training loss: 0.46206602454185486
acc_val: 0.7220
Epoch 60, training loss: 0.39542290568351746
acc_val: 0.7240
Epoch 70, training loss: 0.3445037007331848
acc_val: 0.7160
Epoch 80, training loss: 0.3022153973579407
acc_val: 0.7100
Epoch 90, training loss: 0.2811165452003479
acc_val: 0.7140
Epoch 100, training loss: 0.25598424673080444
acc_val: 0.7140
Epoch 110, training loss: 0.25643837451934814
acc_val: 0.7100
Epoch 120, training loss: 0.2500939965248108
acc_val: 0.7140
Epoch 130, training loss: 0.20846499502658844
acc_val: 0.7160
Epoch 140, training loss: 0.22141896188259125
acc_val: 0.7020
Epoch 150, training loss: 0.20975740253925323
acc_val: 0.7240
Epoch 160, training loss: 0.21290484070777893
acc_val: 0.7100
Epoch 170, training loss: 0.19320303201675415
acc_val: 0.7080
Epoch 180, training loss: 0.19230146706104279
acc_val: 0.7140
Epoch 190, training loss: 0.18828029930591583
acc_val: 0.7200
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.708
