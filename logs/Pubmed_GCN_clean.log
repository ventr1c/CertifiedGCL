nohup: ignoring input
run_gnn.py:14: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Namespace(add_edge_rate_1=0, add_edge_rate_2=0, attack='none', base_model='GCN', cl_activation='relu', cl_base_model='GCNConv', cl_lr=0.0005, cl_num_epochs=200, cl_num_layers=2, cl_num_proj_hidden=128, cl_weight_decay=1e-05, clf_weight=1, config='config.yaml', cont_batch_size=0, cont_weight=1, cuda=True, dataset='Pubmed', debug=True, device_id=1, drop_edge_rate_1=0.2, drop_edge_rate_2=0, drop_feat_rate_1=0.3, drop_feat_rate_2=0.2, dropout=0.5, hidden=128, if_smoothed=True, inv_weight=1, model='GCN', no_cuda=False, noisy_level=0.3, num_hidden=128, num_proj_hidden=128, num_repeat=5, prob=0.8, seed=10, select_target_ratio=0.1, tau=0.1, test_model='GCN', train_lr=0.01, weight_decay=0.0005)
=== training gcn model ===
Epoch 0, training loss: 1.0975215435028076
acc_val: 0.5320
Epoch 10, training loss: 0.7606118321418762
acc_val: 0.7420
Epoch 20, training loss: 0.3679981231689453
acc_val: 0.7520
Epoch 30, training loss: 0.1435493677854538
acc_val: 0.7720
Epoch 40, training loss: 0.07454697042703629
acc_val: 0.7840
Epoch 50, training loss: 0.03163131698966026
acc_val: 0.7840
Epoch 60, training loss: 0.02143171802163124
acc_val: 0.7720
Epoch 70, training loss: 0.01605275645852089
acc_val: 0.7800
Epoch 80, training loss: 0.012591380625963211
acc_val: 0.7740
Epoch 90, training loss: 0.006652111653238535
acc_val: 0.7700
Epoch 100, training loss: 0.008024726994335651
acc_val: 0.7720
Epoch 110, training loss: 0.007987244985997677
acc_val: 0.7720
Epoch 120, training loss: 0.006383497733622789
acc_val: 0.7700
Epoch 130, training loss: 0.007647639140486717
acc_val: 0.7720
Epoch 140, training loss: 0.004727424122393131
acc_val: 0.7740
Epoch 150, training loss: 0.0054105487652122974
acc_val: 0.7720
Epoch 160, training loss: 0.007493254262953997
acc_val: 0.7780
Epoch 170, training loss: 0.005285218358039856
acc_val: 0.7760
Epoch 180, training loss: 0.004215892869979143
acc_val: 0.7700
Epoch 190, training loss: 0.005357979331165552
acc_val: 0.7740
Epoch 200, training loss: 0.0058495053090155125
acc_val: 0.7740
Epoch 210, training loss: 0.005501430947333574
acc_val: 0.7720
Epoch 220, training loss: 0.004920487757772207
acc_val: 0.7780
Epoch 230, training loss: 0.004211415071040392
acc_val: 0.7780
Epoch 240, training loss: 0.0036857074592262506
acc_val: 0.7760
Epoch 250, training loss: 0.00419980101287365
acc_val: 0.7740
Epoch 260, training loss: 0.003703115275129676
acc_val: 0.7720
Epoch 270, training loss: 0.004468160681426525
acc_val: 0.7720
Epoch 280, training loss: 0.0033337995409965515
acc_val: 0.7700
Epoch 290, training loss: 0.0032718507573008537
acc_val: 0.7720
Epoch 300, training loss: 0.0038805410731583834
acc_val: 0.7760
Epoch 310, training loss: 0.003712531179189682
acc_val: 0.7760
Epoch 320, training loss: 0.004483391065150499
acc_val: 0.7760
Epoch 330, training loss: 0.0048468769527971745
acc_val: 0.7800
Epoch 340, training loss: 0.0033766254782676697
acc_val: 0.7720
Epoch 350, training loss: 0.0034495992586016655
acc_val: 0.7720
Epoch 360, training loss: 0.002662956714630127
acc_val: 0.7720
Epoch 370, training loss: 0.0035999712999910116
acc_val: 0.7720
Epoch 380, training loss: 0.0031023151241242886
acc_val: 0.7760
Epoch 390, training loss: 0.0033788946457207203
acc_val: 0.7800
Epoch 400, training loss: 0.0036653776187449694
acc_val: 0.7760
Epoch 410, training loss: 0.0027851576451212168
acc_val: 0.7760
Epoch 420, training loss: 0.0027675514575093985
acc_val: 0.7780
Epoch 430, training loss: 0.0025847803335636854
acc_val: 0.7780
Epoch 440, training loss: 0.005067138932645321
acc_val: 0.7780
Epoch 450, training loss: 0.003033552784472704
acc_val: 0.7760
Epoch 460, training loss: 0.0030940878205001354
acc_val: 0.7820
Epoch 470, training loss: 0.002885074121877551
acc_val: 0.7740
Epoch 480, training loss: 0.0025377189740538597
acc_val: 0.7780
Epoch 490, training loss: 0.0025620099622756243
acc_val: 0.7800
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.769
=== training gcn model ===
Epoch 0, training loss: 1.099029541015625
acc_val: 0.6720
Epoch 10, training loss: 0.765166699886322
acc_val: 0.7420
Epoch 20, training loss: 0.3503917455673218
acc_val: 0.7520
Epoch 30, training loss: 0.1543852984905243
acc_val: 0.7680
Epoch 40, training loss: 0.06609265506267548
acc_val: 0.7720
Epoch 50, training loss: 0.027013374492526054
acc_val: 0.7780
Epoch 60, training loss: 0.01983538642525673
acc_val: 0.7740
Epoch 70, training loss: 0.012693372555077076
acc_val: 0.7700
Epoch 80, training loss: 0.011039333418011665
acc_val: 0.7760
Epoch 90, training loss: 0.011526313610374928
acc_val: 0.7720
Epoch 100, training loss: 0.00853503867983818
acc_val: 0.7720
Epoch 110, training loss: 0.010491988621652126
acc_val: 0.7720
Epoch 120, training loss: 0.007138349115848541
acc_val: 0.7680
Epoch 130, training loss: 0.007743204943835735
acc_val: 0.7680
Epoch 140, training loss: 0.005559853278100491
acc_val: 0.7720
Epoch 150, training loss: 0.004686643369495869
acc_val: 0.7740
Epoch 160, training loss: 0.00546857388690114
acc_val: 0.7720
Epoch 170, training loss: 0.005280532408505678
acc_val: 0.7700
Epoch 180, training loss: 0.005467040464282036
acc_val: 0.7700
Epoch 190, training loss: 0.004759932868182659
acc_val: 0.7660
Epoch 200, training loss: 0.0047161816619336605
acc_val: 0.7720
Epoch 210, training loss: 0.0042114825919270515
acc_val: 0.7740
Epoch 220, training loss: 0.005003470461815596
acc_val: 0.7700
Epoch 230, training loss: 0.004518235567957163
acc_val: 0.7660
Epoch 240, training loss: 0.006079196464270353
acc_val: 0.7700
Epoch 250, training loss: 0.004071936476975679
acc_val: 0.7720
Epoch 260, training loss: 0.004304422065615654
acc_val: 0.7740
Epoch 270, training loss: 0.004787877667695284
acc_val: 0.7720
Epoch 280, training loss: 0.004239269532263279
acc_val: 0.7640
Epoch 290, training loss: 0.0031886601354926825
acc_val: 0.7700
Epoch 300, training loss: 0.004982566460967064
acc_val: 0.7660
Epoch 310, training loss: 0.0027924266178160906
acc_val: 0.7720
Epoch 320, training loss: 0.005142523907124996
acc_val: 0.7640
Epoch 330, training loss: 0.004101232625544071
acc_val: 0.7700
Epoch 340, training loss: 0.003784877248108387
acc_val: 0.7700
Epoch 350, training loss: 0.0042737978510558605
acc_val: 0.7680
Epoch 360, training loss: 0.0044928439892828465
acc_val: 0.7680
Epoch 370, training loss: 0.004032049793750048
acc_val: 0.7680
Epoch 380, training loss: 0.004238364286720753
acc_val: 0.7760
Epoch 390, training loss: 0.0035635409876704216
acc_val: 0.7680
Epoch 400, training loss: 0.0029989697504788637
acc_val: 0.7720
Epoch 410, training loss: 0.0036121036391705275
acc_val: 0.7700
Epoch 420, training loss: 0.004652963485568762
acc_val: 0.7720
Epoch 430, training loss: 0.0024883896112442017
acc_val: 0.7720
Epoch 440, training loss: 0.0032065659761428833
acc_val: 0.7660
Epoch 450, training loss: 0.002993058878928423
acc_val: 0.7780
Epoch 460, training loss: 0.0029701499734073877
acc_val: 0.7680
Epoch 470, training loss: 0.003351639723405242
acc_val: 0.7720
Epoch 480, training loss: 0.002747730351984501
acc_val: 0.7720
Epoch 490, training loss: 0.0032117830123752356
acc_val: 0.7700
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.767
=== training gcn model ===
Epoch 0, training loss: 1.0983976125717163
acc_val: 0.6660
Epoch 10, training loss: 0.7547131776809692
acc_val: 0.7520
Epoch 20, training loss: 0.37483495473861694
acc_val: 0.7580
Epoch 30, training loss: 0.14703519642353058
acc_val: 0.7680
Epoch 40, training loss: 0.055154163390398026
acc_val: 0.7780
Epoch 50, training loss: 0.027593079954385757
acc_val: 0.7760
Epoch 60, training loss: 0.019134199246764183
acc_val: 0.7700
Epoch 70, training loss: 0.013256669044494629
acc_val: 0.7700
Epoch 80, training loss: 0.009487769566476345
acc_val: 0.7680
Epoch 90, training loss: 0.007319780997931957
acc_val: 0.7680
Epoch 100, training loss: 0.00789975468069315
acc_val: 0.7700
Epoch 110, training loss: 0.008745876140892506
acc_val: 0.7660
Epoch 120, training loss: 0.006569647695869207
acc_val: 0.7720
Epoch 130, training loss: 0.006202444899827242
acc_val: 0.7680
Epoch 140, training loss: 0.006996815092861652
acc_val: 0.7740
Epoch 150, training loss: 0.007396422326564789
acc_val: 0.7720
Epoch 160, training loss: 0.004753785207867622
acc_val: 0.7740
Epoch 170, training loss: 0.006904588546603918
acc_val: 0.7700
Epoch 180, training loss: 0.006213220302015543
acc_val: 0.7740
Epoch 190, training loss: 0.005410185549408197
acc_val: 0.7720
Epoch 200, training loss: 0.004846473224461079
acc_val: 0.7740
Epoch 210, training loss: 0.0041757444851100445
acc_val: 0.7720
Epoch 220, training loss: 0.004618311766535044
acc_val: 0.7720
Epoch 230, training loss: 0.004651939962059259
acc_val: 0.7720
Epoch 240, training loss: 0.00338943675160408
acc_val: 0.7700
Epoch 250, training loss: 0.0037627124693244696
acc_val: 0.7720
Epoch 260, training loss: 0.0047078849747776985
acc_val: 0.7700
Epoch 270, training loss: 0.0046348776668310165
acc_val: 0.7700
Epoch 280, training loss: 0.004663503263145685
acc_val: 0.7720
Epoch 290, training loss: 0.003882005112245679
acc_val: 0.7760
Epoch 300, training loss: 0.004282617941498756
acc_val: 0.7740
Epoch 310, training loss: 0.004823525436222553
acc_val: 0.7740
Epoch 320, training loss: 0.004183252342045307
acc_val: 0.7740
Epoch 330, training loss: 0.004031037911772728
acc_val: 0.7680
Epoch 340, training loss: 0.0029699027072638273
acc_val: 0.7720
Epoch 350, training loss: 0.0041115740314126015
acc_val: 0.7680
Epoch 360, training loss: 0.003744901856407523
acc_val: 0.7720
Epoch 370, training loss: 0.0035076728090643883
acc_val: 0.7740
Epoch 380, training loss: 0.0037654931657016277
acc_val: 0.7740
Epoch 390, training loss: 0.003246338339522481
acc_val: 0.7720
Epoch 400, training loss: 0.0034911436960101128
acc_val: 0.7740
Epoch 410, training loss: 0.0034556149039417505
acc_val: 0.7740
Epoch 420, training loss: 0.003067925339564681
acc_val: 0.7720
Epoch 430, training loss: 0.0024450444616377354
acc_val: 0.7740
Epoch 440, training loss: 0.0033837591763585806
acc_val: 0.7740
Epoch 450, training loss: 0.0031355165410786867
acc_val: 0.7680
Epoch 460, training loss: 0.0032298702280968428
acc_val: 0.7700
Epoch 470, training loss: 0.004266776610165834
acc_val: 0.7700
Epoch 480, training loss: 0.0032897689379751682
acc_val: 0.7720
Epoch 490, training loss: 0.002766353078186512
acc_val: 0.7760
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.762
=== training gcn model ===
Epoch 0, training loss: 1.0982152223587036
acc_val: 0.5460
Epoch 10, training loss: 0.7582136392593384
acc_val: 0.7440
Epoch 20, training loss: 0.34948280453681946
acc_val: 0.7560
Epoch 30, training loss: 0.14204125106334686
acc_val: 0.7680
Epoch 40, training loss: 0.06138341501355171
acc_val: 0.7800
Epoch 50, training loss: 0.02803885191679001
acc_val: 0.7800
Epoch 60, training loss: 0.015860509127378464
acc_val: 0.7720
Epoch 70, training loss: 0.01237651240080595
acc_val: 0.7700
Epoch 80, training loss: 0.00978653971105814
acc_val: 0.7720
Epoch 90, training loss: 0.007609662599861622
acc_val: 0.7660
Epoch 100, training loss: 0.005788943264633417
acc_val: 0.7700
Epoch 110, training loss: 0.005867479834705591
acc_val: 0.7700
Epoch 120, training loss: 0.005973885767161846
acc_val: 0.7700
Epoch 130, training loss: 0.00594917219132185
acc_val: 0.7760
Epoch 140, training loss: 0.005253645125776529
acc_val: 0.7720
Epoch 150, training loss: 0.004166065249592066
acc_val: 0.7700
Epoch 160, training loss: 0.006503092125058174
acc_val: 0.7740
Epoch 170, training loss: 0.005598891992121935
acc_val: 0.7700
Epoch 180, training loss: 0.0049497587606310844
acc_val: 0.7720
Epoch 190, training loss: 0.005324221216142178
acc_val: 0.7760
Epoch 200, training loss: 0.0058876811526715755
acc_val: 0.7680
Epoch 210, training loss: 0.005028493236750364
acc_val: 0.7680
Epoch 220, training loss: 0.0036466084420681
acc_val: 0.7700
Epoch 230, training loss: 0.004050550516694784
acc_val: 0.7720
Epoch 240, training loss: 0.003919854294508696
acc_val: 0.7680
Epoch 250, training loss: 0.0039803325198590755
acc_val: 0.7680
Epoch 260, training loss: 0.0039984723553061485
acc_val: 0.7700
Epoch 270, training loss: 0.003414100268855691
acc_val: 0.7680
Epoch 280, training loss: 0.0046507506631314754
acc_val: 0.7720
Epoch 290, training loss: 0.004245691001415253
acc_val: 0.7720
Epoch 300, training loss: 0.004019818734377623
acc_val: 0.7760
Epoch 310, training loss: 0.003508669091388583
acc_val: 0.7760
Epoch 320, training loss: 0.004445787984877825
acc_val: 0.7760
Epoch 330, training loss: 0.0038486334960907698
acc_val: 0.7700
Epoch 340, training loss: 0.0035913242027163506
acc_val: 0.7740
Epoch 350, training loss: 0.003911420237272978
acc_val: 0.7700
Epoch 360, training loss: 0.003550126915797591
acc_val: 0.7700
Epoch 370, training loss: 0.003631442319601774
acc_val: 0.7660
Epoch 380, training loss: 0.002786186756566167
acc_val: 0.7760
Epoch 390, training loss: 0.002581452252343297
acc_val: 0.7700
Epoch 400, training loss: 0.0029896870255470276
acc_val: 0.7720
Epoch 410, training loss: 0.0024688513949513435
acc_val: 0.7720
Epoch 420, training loss: 0.004455700516700745
acc_val: 0.7720
Epoch 430, training loss: 0.003107015509158373
acc_val: 0.7740
Epoch 440, training loss: 0.0026538039091974497
acc_val: 0.7700
Epoch 450, training loss: 0.003236247692257166
acc_val: 0.7700
Epoch 460, training loss: 0.002840876579284668
acc_val: 0.7720
Epoch 470, training loss: 0.0024316953495144844
acc_val: 0.7700
Epoch 480, training loss: 0.00269922218285501
acc_val: 0.7720
Epoch 490, training loss: 0.002492669504135847
acc_val: 0.7680
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.767
=== training gcn model ===
Epoch 0, training loss: 1.0997339487075806
acc_val: 0.3140
Epoch 10, training loss: 0.7723842263221741
acc_val: 0.7420
Epoch 20, training loss: 0.36712631583213806
acc_val: 0.7580
Epoch 30, training loss: 0.16568785905838013
acc_val: 0.7640
Epoch 40, training loss: 0.05867396667599678
acc_val: 0.7780
Epoch 50, training loss: 0.0341760478913784
acc_val: 0.7820
Epoch 60, training loss: 0.019221650436520576
acc_val: 0.7680
Epoch 70, training loss: 0.015022753737866879
acc_val: 0.7680
Epoch 80, training loss: 0.009097154252231121
acc_val: 0.7760
Epoch 90, training loss: 0.011192414909601212
acc_val: 0.7680
Epoch 100, training loss: 0.006978051271289587
acc_val: 0.7720
Epoch 110, training loss: 0.007060852367430925
acc_val: 0.7740
Epoch 120, training loss: 0.004872445948421955
acc_val: 0.7680
Epoch 130, training loss: 0.006445727311074734
acc_val: 0.7740
Epoch 140, training loss: 0.007675729691982269
acc_val: 0.7760
Epoch 150, training loss: 0.0058384365402162075
acc_val: 0.7740
Epoch 160, training loss: 0.006058524362742901
acc_val: 0.7740
Epoch 170, training loss: 0.004738249350339174
acc_val: 0.7740
Epoch 180, training loss: 0.004227911122143269
acc_val: 0.7720
Epoch 190, training loss: 0.006484425626695156
acc_val: 0.7720
Epoch 200, training loss: 0.004877718165516853
acc_val: 0.7740
Epoch 210, training loss: 0.00486676674336195
acc_val: 0.7700
Epoch 220, training loss: 0.005815406795591116
acc_val: 0.7720
Epoch 230, training loss: 0.004129006061702967
acc_val: 0.7660
Epoch 240, training loss: 0.004352843854576349
acc_val: 0.7700
Epoch 250, training loss: 0.004480405244976282
acc_val: 0.7700
Epoch 260, training loss: 0.004919901955872774
acc_val: 0.7740
Epoch 270, training loss: 0.0035873556043952703
acc_val: 0.7700
Epoch 280, training loss: 0.0032948798034340143
acc_val: 0.7720
Epoch 290, training loss: 0.004046745598316193
acc_val: 0.7620
Epoch 300, training loss: 0.0038745165802538395
acc_val: 0.7720
Epoch 310, training loss: 0.004731291905045509
acc_val: 0.7720
Epoch 320, training loss: 0.004247601144015789
acc_val: 0.7740
Epoch 330, training loss: 0.003968467004597187
acc_val: 0.7720
Epoch 340, training loss: 0.0036818375810980797
acc_val: 0.7720
Epoch 350, training loss: 0.0049337358213961124
acc_val: 0.7740
Epoch 360, training loss: 0.004826867487281561
acc_val: 0.7700
Epoch 370, training loss: 0.0031291197519749403
acc_val: 0.7740
Epoch 380, training loss: 0.003972782287746668
acc_val: 0.7720
Epoch 390, training loss: 0.0035961754620075226
acc_val: 0.7700
Epoch 400, training loss: 0.0034788441844284534
acc_val: 0.7700
Epoch 410, training loss: 0.00417822040617466
acc_val: 0.7700
Epoch 420, training loss: 0.0042840889655053616
acc_val: 0.7680
Epoch 430, training loss: 0.0034976452589035034
acc_val: 0.7720
Epoch 440, training loss: 0.003561619436368346
acc_val: 0.7680
Epoch 450, training loss: 0.0024747871793806553
acc_val: 0.7680
Epoch 460, training loss: 0.004906756803393364
acc_val: 0.7740
Epoch 470, training loss: 0.003195511642843485
acc_val: 0.7700
Epoch 480, training loss: 0.003963190130889416
acc_val: 0.7700
Epoch 490, training loss: 0.003275785595178604
acc_val: 0.7720
=== picking the best model according to the performance on validation ===
none
Accuracy: 0.764
